{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stacked Model"
   ]
  },
  {
   "attachments": {
    "stacked.JPG": {
     "image/jpeg": "/9j/4AAQSkZJRgABAQEAkACQAAD/4RDaRXhpZgAATU0AKgAAAAgABAE7AAIAAAAFAAAISodpAAQAAAABAAAIUJydAAEAAAAKAAAQyOocAAcAAAgMAAAAPgAAAAAc6gAAAAgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAFVzZXIAAAAFkAMAAgAAABQAABCekAQAAgAAABQAABCykpEAAgAAAAMyMQAAkpIAAgAAAAMyMQAA6hwABwAACAwAAAiSAAAAABzqAAAACAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMjAyMjoxMjoxMSAyMzo0OToyMgAyMDIyOjEyOjExIDIzOjQ5OjIyAAAAVQBzAGUAcgAAAP/hCxdodHRwOi8vbnMuYWRvYmUuY29tL3hhcC8xLjAvADw/eHBhY2tldCBiZWdpbj0n77u/JyBpZD0nVzVNME1wQ2VoaUh6cmVTek5UY3prYzlkJz8+DQo8eDp4bXBtZXRhIHhtbG5zOng9ImFkb2JlOm5zOm1ldGEvIj48cmRmOlJERiB4bWxuczpyZGY9Imh0dHA6Ly93d3cudzMub3JnLzE5OTkvMDIvMjItcmRmLXN5bnRheC1ucyMiPjxyZGY6RGVzY3JpcHRpb24gcmRmOmFib3V0PSJ1dWlkOmZhZjViZGQ1LWJhM2QtMTFkYS1hZDMxLWQzM2Q3NTE4MmYxYiIgeG1sbnM6ZGM9Imh0dHA6Ly9wdXJsLm9yZy9kYy9lbGVtZW50cy8xLjEvIi8+PHJkZjpEZXNjcmlwdGlvbiByZGY6YWJvdXQ9InV1aWQ6ZmFmNWJkZDUtYmEzZC0xMWRhLWFkMzEtZDMzZDc1MTgyZjFiIiB4bWxuczp4bXA9Imh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC8iPjx4bXA6Q3JlYXRlRGF0ZT4yMDIyLTEyLTExVDIzOjQ5OjIyLjIxNDwveG1wOkNyZWF0ZURhdGU+PC9yZGY6RGVzY3JpcHRpb24+PHJkZjpEZXNjcmlwdGlvbiByZGY6YWJvdXQ9InV1aWQ6ZmFmNWJkZDUtYmEzZC0xMWRhLWFkMzEtZDMzZDc1MTgyZjFiIiB4bWxuczpkYz0iaHR0cDovL3B1cmwub3JnL2RjL2VsZW1lbnRzLzEuMS8iPjxkYzpjcmVhdG9yPjxyZGY6U2VxIHhtbG5zOnJkZj0iaHR0cDovL3d3dy53My5vcmcvMTk5OS8wMi8yMi1yZGYtc3ludGF4LW5zIyI+PHJkZjpsaT5Vc2VyPC9yZGY6bGk+PC9yZGY6U2VxPg0KCQkJPC9kYzpjcmVhdG9yPjwvcmRmOkRlc2NyaXB0aW9uPjwvcmRmOlJERj48L3g6eG1wbWV0YT4NCiAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAKICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgIAogICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgCiAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAKICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgIAogICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgCiAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAKICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgIAogICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgCiAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAKICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgIAogICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgCiAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAKICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgIAogICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgCiAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAKICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgIAogICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgCiAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAKICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgIAogICAgICAgICAgICAgICAgICAgICAgICAgICAgPD94cGFja2V0IGVuZD0ndyc/Pv/bAEMABwUFBgUEBwYFBggHBwgKEQsKCQkKFQ8QDBEYFRoZGBUYFxseJyEbHSUdFxgiLiIlKCkrLCsaIC8zLyoyJyorKv/bAEMBBwgICgkKFAsLFCocGBwqKioqKioqKioqKioqKioqKioqKioqKioqKioqKioqKioqKioqKioqKioqKioqKioqKv/AABEIAg0ENgMBIgACEQEDEQH/xAAfAAABBQEBAQEBAQAAAAAAAAAAAQIDBAUGBwgJCgv/xAC1EAACAQMDAgQDBQUEBAAAAX0BAgMABBEFEiExQQYTUWEHInEUMoGRoQgjQrHBFVLR8CQzYnKCCQoWFxgZGiUmJygpKjQ1Njc4OTpDREVGR0hJSlNUVVZXWFlaY2RlZmdoaWpzdHV2d3h5eoOEhYaHiImKkpOUlZaXmJmaoqOkpaanqKmqsrO0tba3uLm6wsPExcbHyMnK0tPU1dbX2Nna4eLj5OXm5+jp6vHy8/T19vf4+fr/xAAfAQADAQEBAQEBAQEBAAAAAAAAAQIDBAUGBwgJCgv/xAC1EQACAQIEBAMEBwUEBAABAncAAQIDEQQFITEGEkFRB2FxEyIygQgUQpGhscEJIzNS8BVictEKFiQ04SXxFxgZGiYnKCkqNTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqCg4SFhoeIiYqSk5SVlpeYmZqio6Slpqeoqaqys7S1tre4ubrCw8TFxsfIycrS09TV1tfY2dri4+Tl5ufo6ery8/T19vf4+fr/2gAMAwEAAhEDEQA/APpGiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKxNT8UW1nenTtPgm1XVAATZ2mCYwejSMSFjX/eOT2BoA26o6lrel6NEJNX1G0sUPQ3Eyx5+mTzWQNJ17WPn1zVTpsB6WOkvtOPR5yN5P+4E/Gr+meGNE0eUy6fplvFcN964Zd8z+7SNlmP1JoAp/8JvpkvGn22q357G20ycofo5UJ/49R/wlN63+q8I69IPpbJ/6FMK6H/P1ooA57/hK7hP9f4W16Idz5MMmP++JGNA8d6BHj7fcXGmeralZzWqj/gcihf1rof8AP1oIzwRn2oAitbu2vrdZ7K4iuIW+7JE4dT+I4qasC68GaHcXDXVvaf2deHrd6c5tpWPuUxu+jZHtUJHifQuVK+JLMfwtsgvEHsRiOT6Hy/qaAOlorN0jX9P1yOT7DMfOhO2e2lUxzQN6Oh5H8j2zWlQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFI7rHGzyMERQSzMcAD1NLXIMJPHOoOjjHhi2kKkZ/5CcinBz/0xUj/gZH90fMAPXUL/AMZZGh3EmnaHuw2ooMTXg7+Rn7if9NOp/hHRq39L0mw0WxFnpVrHbW4JYqg+8x6sT1Zj3JyTVtVVFCqAqgYAApf5/wAqAD+f8qP8/Wud8WePfDXgi087xHqkNqxGUgB3Syf7qDk/XpXzx45/ae1jVPMtPBVoNJtjkfa5wHnYeoH3U/U+9AH0X4p8beHfBdj9q8SapBZgjKRE7pJP91Byfyr5/wDGH7U2oz3Bg8EabHa26tzdXy75JB7IDhfxJ/CvBNQ1G91W+kvNTu5ru5lOXmnkLs31JqtQB9ReB/2odOvvLtPHNl/Z8x4+22ql4T7snLL+G78K900vVtP1vT473SL2C9tZBlZoJA6n8R/KvzprZ8NeL9e8IagLzw5qlxYy5+YRtlJPZlPDD6igD9Cf8/Sj+X86+efA/wC1HaXPl2fjyx+yydPt9mpaM+7R9R+GfoK940fW9M8Qael9ol/b31s/SWCQMB7HHQ+xoAr6z4dtNYeO5y9pqUCkW2oW+Fmgz2Bxgqe6tlT3FU9P1+5stUh0XxQscV3NxaXsQKwX2Owz9yTHJQk55KkjOOi/l/Oqmp6ZZ6xp8tjqMCzwSj5lPY9QQeoIPII5BGRQBcorm9D1G+07VP8AhHtfkM02wvYX7YH22IdQ3pKvG4fxD5h3C9JQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRSO6xrudgqjuTigBaKjM452I749Bj9TgGkLTZ+WJMf7UmD+gNOwrktFMDNjkL+DZ/pTS85Pyxxkf9dD/hRYLktFRmUhsGNsAZLDBH+P6UqSo5AB+YjO0jBx64PNFguPooopDCiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooqvf31vpmm3N/eyCO2tYmmlc/wAKKCSfyFAGF4jmk1jUYvC1jM8fnx+dqU0TYaC2yQFB7NIQVB6gByOQK6C3gitbaO3to1ihiQJHGgwFUDAAHoBWJ4WtJbXSZtV1ZfKv9Tc3l0G6xAj5IvoiBV+oY96+bPiB+0pr+s3FxY+EANI08MUW6HzXEq+ueiZ9ufegD6L8X/EXwx4GtjJ4i1SKGYrlLWP55n+iDn8Tge9fO3jj9pvXdY8y08H2/wDYtocj7S+HuHHr/dT8Mn3rxK5up7y5e4vJ5J55DueWVyzMfUk8moqAJ7y9utRu5LvULmW6uJTl5ZnLsx9yeTUFFFABRRRQAUUUUAFa3h7xRrfhTUBe+HtTuLCfuYnwHHoy9GHsQayaKAPpXwP+1JG/l2nj2w8tun9oWS5H1ePqPqv5V75oniDSPEmnLfaDqFvf2rfxwOGwfQjqD7HmvzurS0LxFrHhnUVvtA1G4sLlf44HI3D0I6EexyKAPv7XtFj13TDbPK9vMjia2uY/v28q8q6/TuOhBIPBNR+G9YfV9NYXkawajaSG3voFORHKAM4/2WBDKe6sK8c+Dnx9vPF2vW/hnxVawi9nVvs97ANolZQW2unQEgHkce1eqat/xI/FljrK/LbagU06+x0DFv8AR5P++2Mfv5i+lAHTUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFIzqi5Y4FNkl2YVRuc9Fzj8T6CsvW9a07w7p7X+s3SoqjgnqT6KKYjSzJJ9390vqeW/wH6/SsDXPGXhvw4x/tHUIvtA6RKfMk+mByP0FePeLfi5q2uNJbaOzafZdMr/AKxx7nt+Fc3oHgzX/FEu/T7KSRGPzXM3Cj3yev4UXCx6Pqnx5jVmTRtHZ1/hlupNv/joz/OuZuPjV4rmY+SbO3HYRwZx/wB9E11GkfAmEIG13VJHY9Y7YAAe249fyrq7T4S+D7VVzpnnOo+9LKzZ/XFIZ5B/wtzxn5mf7VUj+79mix/Krtv8afFcRxL9iuRnkSQkfqpFew/8K88KMMHQ7THqE5/Os+8+EvhG8UhdOaBuzxTMMfhnFAHK6T8drZ5AmsaRJD/t2sm8f98nH8zXoOh+MPD/AIlTZp2oQzuesEnyv/3yea871f4EqFL6BqrBscR3S5z/AMCHT8q831vwnr3haYNqNnNBtOY7mPlc+u4dKAPqfYyf6p84/hc5z+PX+f0pVkBba3yt6Hv9PWvAvCHxg1PR3S117fqNngDzSf3qfj/F9K9v0jWNP8Qaat3p1wlxA/dTyD6H0IpiNGio9xjOJDlOzen1/wAf8mSkMKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAK5vxd/p8mk6EOU1K8BuB/0wiHmuPoxVEPs9dJXOJ/pfxMnY8rpulRqh9GnlYt+OLdPzoA6EgMCGAIIwQemK+bviB+zDM9xcal4Cu0ZZGL/2bdHbtzziN+mPQNj619Jf5+tH8/5UAfndregat4b1F7DXtPuLC5XrHOhXPuD0I9xxWdX6H694c0fxPpzWOv6db39s3RJkyQfUHqp9xg14F44/ZbB8y88BX+O/9n3rfokn9G/OgD5torU1/wANa14W1A2PiDTbiwuB0WZMBh6qejD3BNZdABRRRQAUUUUAFFFdX4O+Gvinx1OBoGmSPb7sPeTfJCn1c9foMn2oA5Sum8IfDzxP45uvK8O6XLPGDh7l/khj+rnj8Bk+1fR/gf8AZn8O6F5d34smOuXg58jBS3Q/Tq/48e1e0Wtrb2VqltZwx28EY2pHEgVUHoAOBQB5J8KPgJZ+AdSj1zV77+0dYRCsYjXbDb7hgkZ5Y4JGTjr0r1DXdKXW9AvNNdzH9oiZEkHWN+quPdWwR7itD/OKP8k0AZnhrVH1rwzp+oTII5poVMyD+CQcOv4MCPwrUrwjV/E/iPwx4u17RtM1aS3tIL9poohBEwUTKs5wWQn70jd6r/8ACxPF/wD0HZP/AAFg/wDjdQ6kE7N/meNWznC0ajpzvdeR7/RXgH/CxPF//Qdk/wDAWD/43R/wsTxf/wBB2T/wFg/+N0va0+/5mX9v4Pz+49/orwD/AIWJ4v8A+g7J/wCAsH/xuj/hYni//oOyf+AsH/xuj2tPv+Yf2/g/P7j3+ivAP+FieL/+g7J/4Cwf/G6P+FieL/8AoOyf+AsH/wAbo9rT7/mH9v4Pz+49/orwD/hYni//AKDsn/gLB/8AG6P+FieL/wDoOyf+AsH/AMbo9rT7/mH9v4Pz+49/orwD/hYni/8A6Dsn/gLB/wDG6P8AhYni/wD6Dsn/AICwf/G6Pa0+/wCYf2/g/P7j3+ivAP8AhYni/wD6Dsn/AICwf/G6P+FieL/+g7J/4Cwf/G6Pa0+/5h/b+D8/uPf6K8A/4WJ4v/6Dsn/gLB/8bo/4WJ4v/wCg7J/4Cwf/ABuj2tPv+Yf2/g/P7j3+ivAP+FieL/8AoOyf+AsH/wAbo/4WJ4v/AOg7J/4Cwf8Axuj2tPv+Yf2/g/P7j3+ivAP+FieL/wDoOyf+AsH/AMbo/wCFieL/APoOyf8AgLB/8bo9rT7/AJh/b+D8/uPf6K8A/wCFieL/APoOyf8AgLB/8bo/4WJ4v/6Dsn/gLB/8bo9rT7/mH9v4Pz+49/orwD/hYni//oOyf+AsH/xuj/hYni//AKDsn/gLB/8AG6Pa0+/5h/b+D8/uPf6K8A/4WJ4v/wCg7J/4Cwf/ABuj/hYni/8A6Dsn/gLB/wDG6Pa0+/5h/b+D8/uPf6K8A/4WJ4v/AOg7J/4Cwf8Axuj/AIWJ4v8A+g7J/wCAsH/xuj2tPv8AmH9v4Pz+49/orwD/AIWJ4v8A+g7J/wCAsH/xuj/hYni//oOyf+AsH/xuj2tPv+Yf2/g/P7j3+ivAP+FieL/+g7J/4Cwf/G6P+FieL/8AoOyf+AsH/wAbo9rT7/mH9v4Pz+49/orwD/hYni//AKDsn/gLB/8AG6P+FieL/wDoOyf+AsH/AMbo9rT7/mH9v4Pz+49/orwD/hYni/8A6Dsn/gLB/wDG6P8AhYni/wD6Dsn/AICwf/G6Pa0+/wCYf2/g/P7j3+ivAP8AhYni/wD6Dsn/AICwf/G66Dw18V9Qgvo4PExjuLSRgpulQI8P+0wHBX1wBjrzVRnCTsma0c6wdWagm1fuj1+igEMoKnIPII70VR7IUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFMkk2YCjc7cKv8AntTmYKpZjgAZJPaqd5ew6dYz6hfP5ccaF2LfwKO31/rTEZnijxLYeENGe/v3Du3CRj70reg9q+dNc17V/GmvLLcb5ZJG2wW6chB6Af1qXxf4nu/GHiJ7llcx7vLtYBzgZ449T1r2P4a/D2Hw5YpqGpxK+pzLnnnyQew96QzI8EfB63tVi1DxQomn+8tqPup/vepr1WCGO3iEUKLGijCoowAKccAZ7dye1edeNPi1YaE0lno6re3q8M2fkjPue9AHoskscMZeV1RR1LHArAvvHfhnT8i51e23DqEbcR+VfO+r+Kdf8UXO27uriYseIIshfwAq1p/w18U6kplj0xokYZ3ynb/9egD2w/FfweCB/anX/pm1atj438N6kyra6tbszfdDPtJ/Ovly2tpbnUIrSEDzZJRCvPVicD9a6DUvhz4o0kM82lyug6PD838qAPqBHWRdyMrKe6nIplxbw3UTRXMaSxuMMjqCD+FfLmjeM/EHhm4CWV7MoU/Pbz5K/TB6V7P4K+Kmm+I3js78LY6geNjH5ZD7GgDnvHHwfR45L/wqmxhlnsieD/uHt9K848M+JdV8Fa0Z7UuoVttxaScB/Yjsa+pvcV5z8Svh5HrVrLq2jwKNSiXdJGBgTqP/AGagDsPDPiXT/FWjpqGnPlW4kjP3o29DWop8khT9xjhT6H0/w/L0r5i8FeLbjwd4hFyQ32SU7LuH1XPXHqK9P8ZfF6HRtVjstJtkv42iWWSUtgEMMgD3xzTEep0Vl+HNaj8QaBaajCrKJ4w+1sZHb+YI/CtSkMKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigArndB+fxb4pkPJW6gh/K2jbH/kT9a6Kuc0D5PFXitOm69gl/O1hX/wBkoA6EkKCWIAAySe1fN/xA/aekiuLjTfAdmmI2KHUrobtxHGUj/kW/Kvo90WSNkcZRgQV9Qa+TPiD+zd4g0S5ub7wiBrGnFi626cXES+m3o+Pbk+lAHmF1458U3mt/2vceINRa/DblnFwylfpg4A9hxXr3gb9p/VdO8uz8b2f9p24wPtluAk6j1Zfuv/46frXg9xbT2lw8F1DJBNGdrxyKVZT6EHpUdAH3lp2ueB/ixoTQwSWOtWzDMlrOg8yL3KH5lPuPwNeS+Of2XIJvMvPAd/5D8n+z71iVPsknUfRs/Wvm+xv7vTLyO7066mtbmI5SaFyjKfYjmvbfA/7Tut6T5dp4ytv7YtRx9qiwlwo9/wCF/wBD70AeReI/Cmu+EtQNl4i0y4sJs/L5q/K/urDhh9DWPX3ho/inwP8AFXRXtraay1aF1zLY3SDzE+qNyPqPwNeZ+L/2WtL1C6Nz4P1RtL3Nl7W5Uyxj/db7w+hzQB8t12Hgv4W+LPHkqnQ9NcWhOGvbj93Cv/Aj976Lk19JeB/2cvCvhny7vXs6/frz+/TbAh9o+/8AwIn6Vt+M/jP4M8AwtZm6W9vohtXT9PwxTHZiPlQe3X2oA53wN+zZ4Z8PeXdeJXOvXy87JF226H2Tq3/AuPaun8YfF3wV8O7f7FNdRzXUK7Y9N09VZk9AcfKg+uPpXzf45+P/AIu8X+ZbWU/9iaa2R5FmxDuP9qTqfwwPavLiSzEsSSTkk96APWPHP7Q3i3xX5lrpUn9hac2R5dq581x/tSdf++cVyPhb4meLfB199o0bWbgKxzJBOxlik+qt/MYPvXKVo6J4f1bxJqK2Og6dcX9y3SOBC2B6k9APc8UAfWXwo+PVl4/1GPRNWsf7N1l0LRmNt0M+0ZIXPKnGTg56da9f/wAgV4J8GvgHfeEtftvE3iu4iF7ArfZ7GA7vLZgV3O/QkAngZHvXvf8AkmgDwP4nQiD4pX5H/Lextpj7nMif+yVzNdR8UZRL8UrwD/ljp9tF/wCPSt/7PXL159X42fnGb2+vVLeX5IKKKKyPLCiirlno2p6jCZdP067uo1baXggZwD1xkDryPzp7jjGUnaKuU6KdLFJBM8UyNHJGxV0cYKkcEEdjRLFJBM8UyNHJGxV0cYKkcEEdjQKzG0UUUgCip7OwvNRmMWn2s91Iq7ikEZcgdM4HbkfnUFMdmlcKKKKQgoqezsLzUZjFp9rPdSKu4pBGXIHTOB25H51BTHZpXCirkejanNYm9i067ktApYzrAxjAGcndjGBg5+lNstL1DUt/9nWNzd+Xjf5ELPtz0zgcdD+VFmV7Od0rPUq0U6WKSCZ4pkaOSNiro4wVI4II7Gm0EbBRRU95YXmnTCLULWe1kZdwSeMoSOmcHtwfyoHZtXIKKKnuLC8tIYZbq1ngjuF3QvJGVEg4OVJ6jkdPUUAk2rogooopCCiiigAooooAKKKKACiiigAooooAKQjIIPQ0tFMD6N8JyvP4M0WWU7nk0+BmJ7kxqTWtWN4O/wCRF0H/ALBtv/6KWtmvWn8TP1mOyCiiipKCiiigAooooAKKKKACiiigAooooAKKKKAIZTukWPsPmb6dh+f8jXkfxv8AFDIkHh61kx5g8262nnH8K/pn8q9ZaRY4ZriU7VUkkn+ELx+XBP418sa1fzeK/Fl1eIGeW+uNsSH+6ThR+WBTYkd38G/B66hfya/qEe+3tW2W4I4Z+5/CvcxkGszw1pEOg+HbTTrcALDGAT6t3P51kfEXxSvhfwrLPG2Lqf8AdQDvk9/wpDOK+KfxGe3eTQtDm2t925uEPI/2RXB+DPAeo+MbvegaCxVv3tw46/T1NVPCXhy78Y+KI7TcxVm8y5lPZe5+pr33X761+H/gWSXTrZdlqoWKPszdMmgCz4c8F6J4ZtVTT7RDKBzPINzt+Nb/ALYyK8S8M/Gq+OsLF4kjjNnM2N8QwYvf3Fe1WtxFdWqT28iyRSDKOpyCKAOUt/hl4ct/EA1iK1bzg/mLGW+RW9QK64DFO69KUUAcx4m8BaJ4nt2W7tlhuP4biJQGB/rXgnizwPqvhDUQsytJATuhuo+hx6nsa+oSwFZ+q6Xba5ps9jeruikUr05U+o96APN/hZ8R31Yx6DrkoN0o/wBHnY/60eh/2q2Pih45vfCEVlFpkKNNdFmMkg+VQO31rxLxBo194Q8USWjuyT2snmQzLxuXqrCvd9Ek0j4neCLWbWLdZ2T5JlzgxyDg4NAHz7q+pnWdUmvnt4reWf5pViGFLd2A7ZqtbQSXt1DbwjdLLIsajrySAP6V7HrfwLgkLyaBqDRN1EVwMr9Miq3gX4UatpXi631HXBCttZN5iKjbjI4Hyn6A8/hQB6vpenR6Lo1lZW+PLs4Uiz0yAME/mM1o01VGCMcEd6SEkxDO7KkrlupwcZ/Gn0F1H0UUUhhRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFADZZFhheRwxVFLEIhYkD0A5J9hzWb/wkVj3jvx9dOuB/wCyVqUUtSJKb+Fr7v8Agoy/+Ek0wfemlT/rpbSL/NaVPEmiOwUatZhj/C06qfyJzWnTXRZFKyKrKeoYZFGpFqvdfc/8xIpop03QSJIvqjAj9KfWdL4e0iZ97adbLJ/z0jjCP/30uDVW60+60u1ludL1CcCFC5trpjNG4Azjc3zj67sD0NF2JzqRV5R08n/nb8zboqO2mFzaxTgbRKiuAe2RmpKZsndXQUUUUDCiiigAooooAK5y3/0X4lX8Z4W/0yCZB6tFJIrn8pIq6Oub8Tn7Bq2ha10jtro2lw392K4ATP080Qk+wNAHR/5Jo/zij/IFeI+P/wBpXRfDtxcad4Vtv7Yv4mKPO5226MODg9XwfTA96APRfGPw38LeOrcp4h0uOWcDCXcXyTJ9HHJ+hyPavnbxx+zN4g0XzLvwjONbsxz5DYS4QfTo/wCGD7Vx918cfiFda4NTHiO4gdWytvCAsAHp5eMEfXJr13wN+1FZ3Xl2fjux+xynAN/ZqWjPuydV/DP0FAHzRd2lzYXUlrfW8ttPGdrxTIUZT6EHkVDX3hq/hnwP8VtES4uIbLV4HXEV7auPMj+jryPofxFeC+OP2Yta0kSXngy6/ti1XJ+yy4S4Uex+6/6H2oA8Ptbu4sbqO5sp5beeM7o5YnKsp9QRyK9n8FftM+I9DjW18UW669bKuFlLeXOvplsYb8Rn3rxq+sLzS72Sz1K1mtLmI4eGeMoyn3B5qvQB6X44+PHjDxn5lsl1/ZGnPx9lsmKlh6O/3m+nA9q80orY8OeE9d8W6gLPw7plxfzfxeUvyp7sx4UfU0AY9amgeGda8U6itj4e024v7g9VhTIUerHoo9zivoXwP+y5bw+XeePL77Q/X+z7JiEHs8nU/RcfWvWNT17wN8J9DWCeWx0a3Vcx2lug8yX6IPmY+5/E0AeQ+Bv2W1Hl3nj2/wB3f+z7Jv0eT+i/nXvmg+HNH8Mactj4f023sLdf4IUxuPqx6sfc5NfNXjn9p/V9T8yz8E2g0q2OR9snAedh6hfup+p9xXJeFfj9458N3u+61JtatnOZLfUGL5/3X+8p/T2oA+1f8k0f5Arzr4b/ABp8O/EWQWNssmn6uqFzZT87gOpRhwwH4H2ruNZ1W30PQ77Vbw4gs4Hnk55IUE4HucYFAHz94uuxqHxE8RXSHKi8Fup/65RpGf8Ax9XrLqC0882yyXh3XMxaac+sjks5/wC+ianrzZu8mz8uxlX22InUXVsKKKKg5Qr26a+1TxJY2Uvw+1jT7O2iixNayxgSRHoqkbW2gbSAMAcZBYEY8WtZ/st5DceVHN5Uiv5cy7kfBzhh3B7ivRdR0PwZ4qaPUdJ1y00MsoWa2lRUG7A6IWXBGcErlSRxzknam3Z2Payyc4xmoPV205uV/J/mi/bXrat8T9Ii8TaG1jqdvbNtKyCSOZgu5WweAo/eEEEndgE/LXI+IYNBn8e33mXd3bWiSyvdmRA0kkodtyRbRgA8AFsY5J9D1l34r0c+PfDkEWoefaaXHLFLfzOW3u6FPmbAB5VSXHB3Z4ArKsH0XSvitNd6teWV5bXUklxbTwSiSOCR5CULnoCAD6gEqfcXKz08zuxHJVXJzJ+/q3bst7W9L9bFU+ENI1bwvfar4e/ta3+xx+du1JEEc6ANuCFByRtP44HfIit/C2haXoem6h4tvb2J9Uw0ENoi/uk7uxO7IwUOBgjOMHnHTWepMula/Z654s0/UdRv7JhBHFcAQoNjKAHO1FZiRlRg8ZOc8ZFwdM8aeF9AtzrVlpdzpcYguIrt9vyEBdyk4DHEYO0f3sEjuOMem5nKhQspQinO2idkm+bte1+Xpcu/D7S4dH+It7a2t/BqMA08slzAykOC8eeFY4IORgnPGe4rmb3wtb6B4XS98RG5j1G+z9is4sLsAHLSkg46j5Rg9B3O3e8E3Xh3SPH94dO1DZpwsSiXN7KE8xyyE4yq47jH+yT9KTaxD4t8A3kOt3sCavpsrXFvLO6oZ1bLMgzyT94bVAHEY7Uvd5beonGhLDKGnMuflV7rpf10+H9SC38LaFpeh6bqHi29vYn1TDQQ2iL+6Tu7E7sjBQ4GCM4wecH/AArm7/4Tj/hH/tX7ryPtH2vyx/q8Y3bN39/5cZz36V0mm+Jn1Pwvo9vpHiWy0O5so1gvIrsKdyAbQyl1wThM7R/ewSMDNKz8badbfEo3s1/PeaebL7KL2dACBnzM7EjU43fLjGec5xxT5YaDdDAWp82zcde+nvXd7776R5di/wDDyDwynim6Phy71B5I7Z0ZbxFxKm9PnQqBgDA4YAncPQ15NXqPgjTdK8K+I7m4u/E+kzpJA8cAinHzLvUlmJ4U8L8uTnJwflNeXVE/hRx466w9KMkk7y0Xy82e0eDJG/4QXw1bEK0F5c3EM8boGEibbhtpB7ZUVF4G0u58OafaQyNB5l5q88MzxDJdI4pRtJIBwHiJHsfciuei1uwsvhz4X33Mck1lqy3E1tHIplVFklbO3OehHXHUVv6hrmhR/EHw9HZXtsLa2+1zzXAuFMStMGON+7g7gTj/AGhitotafI9ujWpKNKTesVBLX+blT+6zucxJ4Zs7/VfE2u65cz2+mWOoTIRboGkmcuflXP3Tlk6jB3dRgkUNV8M6ZL4VPiLwzc3ctpDKIbiC8RRJEc/e3DAI+ZOAD97OeoG5BqumapZeKvDs2o21m99qUlzaXUr5il+fdgsOFH7sc5538A4waWoXNh4d+HNx4ej1O01K+vrlZn+xuXjiTI53Ywx/dDjg/N6DJzajb+tzzKlLDuEpWVrSd76813Zb+mlttfMiv/Cvh7w7Da2niS/1CPU7uISn7PEhjtQePnGSXAYN905IXoOM9F428OS+KPiXZ6fFL5CDTRJLNtDeWod+cZGeSo49c9qzfE66X43mstai17T7BY7ZYru3uHYSREfOdi4BkPzkcAAleDzxs6l4u0jTvijb3xvIJ7KXS/s8lxBJ5giPmM/8IOT8oGP9rNVaOq6aHVGnhkpU5WVNyhZ33Wu+v3vTr8uUuPC2hapoepah4Svb2V9Ly08N2i/vU7OpG3AwHODknGMDjNr4gf8AIoeDf+vE/wDouKtLWtduLLw7qUWp+MYNVnuFaG1t9PSHDoflJkYRnacNnbkdCAxzxi+OL+zu/C3hOK1uoJ5Ley2zJHIGMZ2RDDAdDwevoamVlF2/rU568aMKFVQ0birrT+bsnK2nn59TiqKKK5z50KKKKACiiigAooooAKKKKACiiigAooooA+ivB3/Ii6D/ANg23/8ARS1s1jeDv+RF0H/sG2//AKKWtmvYn8TP1mOyCiiioKCiiigAooooAKKKKACiiigAooooAKbI4jiZ26KpJ/CnUyZd8EiddykfpQgZzHxEv/7G+G+qSKxDfZxArDrlyEz+ua8R+Fel/wBp/EGwDjMdsDcMPTaOP1Ir1X41zmL4f+WP+W11Gn82/pXGfAq2DeKdRuD1jtQv/fTD/CgD3Nt2flrwL41az9s8WRaej/urKLkZ/jbn+Ve/55r5X8c3LXfjrV5G/wCflk6enFAHsHwa0FdM8KHUpkxPfNnJHIUdK7nV9Jtdc0mfT79PMgnXa3t7iuQ+HnjbRtW0+00Wx82K4tYApWVAA2OpUgmu+X2oA+XfGngq98Haq0UytLaSHMNxjhh6H3re+G/xIk8O3K6bqztJpkhwrZ5gPr9K9z1zRLLxBpklhqUIlikH4qfUH1r5s8ZeDb/wdqpguFMlpISYJwOHHoff2oA+oLeeK4t0mgkWSOQbldTkMPWsbxF4t0vw7EWvLhTLtyIUILH/AA/GvDdA8Y63ofhl7G31EJAQGUPjzIhzwpPY1zV5c3Wr6j5Nv5l1NIQo2KS8pxjOOtAHotx8cbyPUo3isITY5/eJk7wueSD64r2m3nW4tY54+VkQOPoRXivg/wCDN1ctFeeKT5EQIYWaHLP/ALx7fQV7ZEghjRFACIAoHoKAPMPjf4fS78P2+tRJ++s32SMByY29fof51zvwM1o2/iC80h2Pl3UXmRqT/GvX9K6z4m+OtBtNN1Dw3cmWW8ng2sIkBWMnkZOeteU/DW7Np8RtHZfvSTeUcejDFAH08p4OadTc9a8t+LXjjWfDeo2Fhoz/AGcTxNI82wMWIIAAzx35/CgD1Soo8LPKozk4c59xj/2Wua+HHiG88T+DLfUdSA+0F2jZ1XAk2nG4D9PqDXUBMSs/cqB+Wf8AGmIdRRRSGFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAVV1T/kD3n/XB/wD0E1aqrqn/ACB7z/rg/wD6CaT2IqfAw0v/AJA9n/1wT/0EVaqrpf8AyB7P/rgn/oIq1Qtgp/AgoooplhRRRQAUUUUAFUtY0yHWtFvNMuiwiu4WiZlOGXIxkHsR1B9RV2igDD8OahLrGgNFqXy39szWd+q8YlXgkegYEOPZxXyJ8Qfgb4r8GXNzdQWb6ppAcsl3aguyJnjzF6qfU8j3r6v1vHhrXV8SLldPuFWDVh2QDiO4x/sk7WP90gn7ldMCGXIOQe/rQB+b1Ffbnjj4HeD/ABt5lw9n/ZepPz9ssVCFj6un3W/n7184+OfgL4v8G+ZcwW/9s6auT9pslJZR/tx9R9Rke9AHEeHfFWueE9QF74d1O4sJ+/lP8rj0ZejD2INfQHgb9qSGXy7Px7YeS3A/tCyXK/V4+o+q5+lfNBBBIPBHWigD7x1DRfA3xZ0FZpo7HWrUjCXULDzIj6Bh8yn2P4ivD/F/7LOp29153grUory2Y/8AHvfN5ckY/wB4DDfkK8R0LxHrHhjUFvvD+pXFhcL/ABwvjd7EdGHscive/BX7UzRxLa+O9NaUheL6wUBm/wB6MnH4gj6UAaXgf9l2ws/LvPHV99ulHP2G0YrEPZn4Zvwx+Nen6z4r8D/CnRUtrmaz0qJFzDYWqDzH9wi8n/eP4mvn3xz+0v4i13zLTwpD/YVkePOyHuHH+90T8OR614vdXVxe3UlzeTyXE8h3PLK5ZmPqSeTQB7f44/ab1zV/MtPB1t/Y1qePtMmHuHHt/Cn4ZPvXiV7fXWpXkl3qFzNdXEp3STTOXZj7k8moKntLO51C7jtbC3lubiQ7UihQuzH0AHJoAgqW2tp7y5S3tIZJ5pDtSOJCzMfQAcmvbPA/7Muva15d34vuP7FtG5+zph7hh9Pup+OT7V9E+D/hz4X8DWwTw9pccMuMPdSfPNJ9XPP4DA9qAPEvgZ8E/EWj+LLPxX4ni/s2G1VmgtGb99IzKV+YD7owTwefavQvjRrw+y2Xhi3b57tlu7sD+GBGyq/8CkA/BGHevQtf12x8NaFdavq0vlW1sm5sclj0Cgd2JIAHqa+bLvWJNZ1W71jVZ4vtt8+91EgIiUcJGPZVwPc5Pes6nNy+6jyM2xToYdxh8UtF+rHUVF9pg/57x/8AfYo+0wf894/++xXF7Kp/Kz8/9lU/lf3EtFRfaYP+e8f/AH2KPtMH/PeP/vsUeyqfysPZVP5X9xLRUX2mD/nvH/32KPtMH/PeP/vsUeyqfysPZVP5X9xLRUX2mD/nvH/32KPtMH/PeP8A77FHsqn8rD2VT+V/cS0VF9pg/wCe8f8A32KPtMH/AD3j/wC+xR7Kp/Kw9lU/lf3EtFRfaYP+e8f/AH2KPtMH/PeP/vsUeyqfysPZVP5X9xLRUX2mD/nvH/32KPtMH/PeP/vsUeyqfysPZVP5X9xLRUX2mD/nvH/32KPtMH/PeP8A77FHsqn8rD2VT+V/cS0VF9pg/wCe8f8A32KPtMH/AD3j/wC+xR7Kp/Kw9lU/lf3EtFRfaYP+e8f/AH2KPtMH/PeP/vsUeyqfysPZVP5X9xLRUX2mD/nvH/32KPtMH/PeP/vsUeyqfysPZVP5X9xLRUX2mD/nvH/32KPtMH/PeP8A77FHsqn8rD2VT+V/cS0VF9pg/wCe8f8A32KPtMH/AD3j/wC+xR7Kp/Kw9lU/lf3EtFRfaYP+e8f/AH2KPtMH/PeP/vsUeyqfysPZVP5X9xLRUX2mD/nvH/32KPtMH/PeP/vsUeyqfysPZVP5X9xLRUX2mD/nvH/32KPtMH/PeP8A77FHsqn8rD2VT+V/cS0VF9pg/wCe8f8A32KPtMH/AD3j/wC+xR7Kp/Kw9lU/lf3EtFRfaYP+e8f/AH2KPtMH/PeP/vsUeyqfysPZVP5X9xLRUX2mD/nvH/32K3/DfhLUvFN7HFawSR2hI867ZcIid9pP3m9APx4qo0ZydrGtHC1q01CMXqe4eDxjwNoQPB/s23/9FLWzUdtbx2lrFbwLtihQRoPQAYFSV6Endtn6itFYKKKKQwooooAKKKKACiiigAooooAKKKKACo522W0r/wB1Cf0qSkZQ6Mrchhg0IGed/G6Jn8BIy/8ALO8jb6cMP61x/wACJdviPU0JGZLZWx7Bv/r16J8TrJ9T+GWpDG2SOJZ8D+EowY/oDXkHwf1EWHxDt1c4W7ieDPocbv8A2WgD6Ox3r5U8ZwtbeNtXjkJybt2HHYnNfVhr52+MWkNYeOnuQpEd7EHB7ZHBFAHb/DX4bjRpoNen1AXTSwBoUSPaE3evJya9SXO3muG+EmuDV/A0ETPmazYwuPQdq7qgArM17QrLxDpcthqMYkikHXup9R6GtGnUAeHj4Ias2p+RJq0f9mK2VbaS+P8Ad6A+9eneGfBWj+FbcJplqplI+a4kGZG/H+ldFRQAg78UEZIpaM4oA8i+Jvw3S6kv/E8GoC3CReZPE6FgxHHByMV5x8PLeS5+I2iBT9y5EhPqADXr3xp1xdO8GjT0b99qEgTA/uDlv6VwnwT0mS78YSajsyljAwDdtzcY/LmgD3/p0rz74k+JvC2nNa2HiPTf7TmceasQUful6ZyemfTvivQOo/pXnPj/AOHdp4x8QwXFtrEFnqKxCKSF8OWQEsCFyCCMn86AOz8L3mmah4bs7nQUWKwdP3UaqF2YJBGO2CDXnvxp1vUdNutIi0zUbuyLJK0n2ado9/KgZ2kZxg/ma9B8LaDB4Z8N2mk2rtIlupzI3V2JJJ/MmvGvjTfi58cJbKQRaWqIQOzMS38iK9LLKaqYlXV0rnmZpVdPDNxdm2jk/wDhLPEf/Qw6t/4Hy/8AxVH/AAlniP8A6GHVv/A+X/4qsiivrPYUv5V9yPkfrNf+d/ezX/4SzxH/ANDDq3/gfL/8VR/wlniP/oYdW/8AA+X/AOKrIoo9hS/lX3IPrNf+d/ezX/4SzxH/ANDDq3/gfL/8VR/wlniP/oYdW/8AA+X/AOKrIoo9hS/lX3IPrNf+d/ezX/4SzxH/ANDDq3/gfL/8VR/wlniP/oYdW/8AA+X/AOKrIoo9hS/lX3IPrNf+d/ezX/4SzxH/ANDDq3/gfL/8VR/wlniP/oYdW/8AA+X/AOKq7pXw/wDE2t6ZFqGl6Z59rNny5PtES5wxU8MwPUGq2u+Dte8NQRTa1pz20UzFEkDo67sZwSpODjpnrg46GsV9VcuRct+2lzZyxijztyt31sR/8JZ4j/6GHVv/AAPl/wDiqP8AhLPEf/Qw6t/4Hy//ABVNfwzrEfhuPX2snOmSNtW4VlYA7ivIByBuBGSAM49RTIPD+p3Hh641yG23adbSCKWfzFG1jt4253H769B3quTDdo726b9vUn2uK/mltfrt39CX/hLPEf8A0MOrf+B8v/xVH/CWeI/+hh1b/wAD5f8A4qmv4Z1iPw3Hr7WTnTJG2rcKysAdxXkA5A3AjJAGceopkHh/U7jw9ca5DbbtOtpBFLP5ijax28bc7j99eg70cmG7R3t037eoe1xX80tr9du/oS/8JZ4j/wChh1b/AMD5f/iqP+Es8R/9DDq3/gfL/wDFVkUVp7Cl/KvuRn9Zr/zv72a//CWeI/8AoYdW/wDA+X/4qj/hLPEf/Qw6t/4Hy/8AxVZFFHsKX8q+5B9Zr/zv72a//CWeI/8AoYdW/wDA+X/4qj/hLPEf/Qw6t/4Hy/8AxVZFFHsKX8q+5B9Zr/zv72a//CWeI/8AoYdW/wDA+X/4qj/hLPEf/Qw6t/4Hy/8AxVZFFHsKX8q+5B9Zr/zv72a//CWeI/8AoYdW/wDA+X/4qj/hLPEf/Qw6t/4Hy/8AxVZFFHsKX8q+5B9Zr/zv72a//CWeI/8AoYdW/wDA+X/4qj/hLPEf/Qw6t/4Hy/8AxVZFFHsKX8q+5B9Zr/zv72a//CWeI/8AoYdW/wDA+X/4qj/hLPEf/Qw6t/4Hy/8AxVZFFHsKX8q+5B9Zr/zv72a//CWeJP8AoYdW/wDA6X/4qu18B/FLVLXWLfT/ABDdNeWVw4j8+XmSFjwDnuM4zn6+x8zpGJVSRwRyDWNbCUalNxcUdGHxleFRPmb9WfYFFFFfDn3IUUUUAFFFFABVXVP+QPef9cH/APQTVqquqf8AIHvP+uD/APoJpPYip8DDS/8AkD2f/XBP/QRVqqul/wDIHs/+uCf+girVC2Cn8CCiiimWFFFFABRRRQAUUUUANkjSWNo5UV0cFWVhkMD1BFcrp883hHUotG1Fi+jXD7NLu2P+oJ6W0hP5I3cfKeQN3WVBfWNrqVjNZ38EdxbTKUkikXKsKAJqK5OO5v8AwWvlam9xqWhKcRX2DJNZr/dmHV0HaQZIH3u7V1EE8VzbpNbSpLDIoZJI2DK4PQgjqKAOD8cfBbwf45Ek93ZfYNRb/l+sgEcn/aHR/wARn3r5x8cfs++LvCPmXNhD/bmnLz51mh8xB/tR9R+GRX2d/P8AlR/n60Afm8ylWKsCGBwQR0pK+6PG/wAHvCPjtXl1HTxa6gw4vrPEcmfVuzfiDXzt4w/Zv8YaBcF9BRdfsmbCtb4SVf8AeQn9QT+FAHkFWLDT7zVb2Oz0y1mu7mU4SGCMuzH2Ar3bwP8Asvanf+Xd+OL0abAefsVsQ8zD0ZuVX8N34V9C+FvA/hzwXZfZvDelw2YIw8oG6WT/AHnPJ/OgD5z8D/sxazqnl3njS6/si2OD9khIedh6E/dT9T7V9EeEvAPhrwRaeR4c0uG2cjD3BG+WT/ec8n6dPauj/n/Kj+X86AD+X86juLiK1t5Li5lSGGJC7yOwCooGSSewqrq2sWOh2JutSm8tM7UVVLPIx6IijlmPYAE1ixaTfeJ7yK+8RxG202Ih7XSGIJdgciS4xwSOojBKr1JY42gCaVFc+KNWi1zUImh0u2O7S7SRSGkYjH2mQHoSCQinkAknk4XqqKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKAKlzbRXVndWU6gxTIysuc5Vgc5/HNfKrLdeFfFm0EifTbr8yrdfxx+tfWEw24k7Lw3Pb1/D+Wa8O+NvhhrTWINet0/c3a+XPgcCQdD+I/lTEj2vS9Qh1TSra+t2BjuI1kU/UVxnxb8Lt4g8Km5tl3XVifMQDqy9xXPfBTxcJbWTw3eyfvIsyWpY9V7r+Br1ttu3DgHIxg9KQz5r+G/i4+E/Eqm4LfYrn93OB29G/CvpSCVJoElicOjjcrKeCDXgfxT8CNod2dW0q2P2KdyZQvSIn27A0fD34nyeHlTTNb3zabn5JRy0Gf5rQB7/S1V0+/tNStFudPuI7iFxlXjbINWSORQAtFZsevaXLqR0+PULZrtesIkG7/APXWivTrmgBagu7mGztpLm6lWKCJS8jv0UDvUGq6rYaNZPeancx20KDlnOM+w9a8D+IXxLm8VMbDTA9vpaNk54aYjoT7e1AGP498VyeLfEsl0u77JH+6to++wHr9Sefxr274YeGP+EY8HxefGVvLw+fNnqM/dX8BXnfwn+H0up30Wv6zDixhO62icf61x/Ef9kdvWvdh1x+tAFLWdTh0XRbvUbp9sVtE0hPrgdK+YtGudV1vxxZXEcrjULu9Vw+4naS38hzx6CvRfjZ4tEhi8M2MmSpE14VPT+6h/Hn8KrfBDw29zqFx4huIx5Vv+5tiR1cj5j+A4/4FQB7a0iRRPI7BUQFmY9AOua+VfEWqtrniO/1Jz/x8zM657LnCj8AAK9t+LXiUaN4UbT4XxdakPKAHVY/42/HO38T6V4BX02T0HGDqvroj5fOq6lONFdNX/X9bhRRRXunz4UUUUAFFFFABRRRQB7ZoNp9s+C+iR/8ACTf8I3i4kb7X5uzf+8l/d53r1znr/D0qh45uT4U8CXPhfUtbuNb1PUJknElwHDRQ5BzklgRuiIxuH3s4455jVPEGmXHwc0bQ4bndqNtetLLB5bDapM3O7G0/fXoe9XL/AMU6Z4p+F8dlr9/t8QadITbSSoztOoxwXCHGVO3BPLIrMa8ONCoqnPJPl53pbz0e17HvSxFN0+SLXNyLW+m2q3tc7bwZf2Vr8KvD1jqkfmWur3E2nSfMwx5jTYHy88kBe2N2c8Vgz6LN4d+Dni3Srk7nttVVQ+AN6k25VsAnGVIOM8ZxXN6p4g0y4+DmjaHDc7tRtr1pZYPLYbVJm53Y2n769D3rodc+JGneI/hPcafeTPHrbLFG8TRkiZlkQmQMo2gEAnBxg5HoTPsKsanMk7Oevylo/S36F+3pSp8smrqGnzjqvW/6nQ+DL+ytfhV4esdUj8y11e4m06T5mGPMabA+XnkgL2xuznisGfRZvDvwc8W6Vcnc9tqqqHwBvUm3KtgE4ypBxnjOK5vVPEGmXHwc0bQ4bndqNtetLLB5bDapM3O7G0/fXoe9dDrnxI07xH8J7jT7yZ49bZYo3iaMkTMsiEyBlG0AgE4OMHI9CT2FWNTmSdnPX5S0fpb9A9vSlT5ZNXUNPnHVet/1PKKKKK94+eCiiigAooooAKKKKACiiigAooooAKKKKACkf7jfSlpH+430pS2ZdP40fYFFFFfnp+ihRRRQAUUUUAFVdU/5A95/1wf/ANBNWqq6p/yB7z/rg/8A6CaT2IqfAw0v/kD2f/XBP/QRVqqul/8AIHs/+uCf+girVC2Cn8CCiiimWFFFFABRRRQAUUUUAFFFFABXNy+FZNOme68IXS6XK7F5LN032kxJySYwRsY/3kI9SGrpKKAOaHi06Z+78WafNpLDrdJme0f381R8g/66BK3rW7t763S4sriK5hcZSWFw6kexHBqesK68FaBc3D3MdgLK5c5a40+V7WRj6loipb8c0Abn8v50fz/lXPf8I3qtv/x4eLdTUDpHdRQTqPxMYc/99Uf2b4uT/V+I9Lb/AK66O7f+g3C0AdD/AC/nR/n6Vz39l+K5P9b4msk97fSdpH03StSf8InPccar4m1q8Q/ejSZLVfpmBEb/AMeoA09U1vS9EhEurX9vaIxwnmyAGQ+ijqx9hWSdb1rWsr4b0w2sB4/tHVo2jUe6QcSP/wAC2D0JrR0vwxoujTNPpum28Nwww1yV3TMPeRssfxNatAGLpfhi1sL0ajezS6nqu0qb66wWQHqsaj5Y19lAz3J61tUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABWPruiW+vaLc6RejMU0ZCNnJU9iPcH+lbFNkQSLg8Ecg+h9aYj5gTSdT8I+KybjMVzYvlGT+LHf6EV734O8YWHi7S/PtXxcR/LNER8yn1+lZ3j7wQvi7Sybdhb6rbr+6k6Bx/dPqD29K8Gsb7WfBniQyQl7S+tn2yRuPvD0I7ikM+qbiCK6haG5jWWNxtZGXIYV4v41+Dk9vJJf8AhNDNEcs9kx+Zf9z1+ld34K+I2k+K7dI2dbTUgP3ls5+8fVfUV2XXGP8A9VAHyfputa14UvyLCe5sJ1PzxOCM/VTXdWHxy1mGMR6np1rcnBBkjYo2fp0r2LWPDWja/GU1fToLof3mXDD/AIEOa4q++B3hy4kL2Vze2ZPRQ4cD8CKAPDrPUpLXXYtUyxmiuBcHnlyGyRn35Fehah8b9cvAYdKsrWy7ByTI35Hit3/hQtju/wCQ9c4zyBbrn+dath8EfDVqwa6lvLz1VpNqn6gf40AeK3l9rninVFFxPc6ndOcJGuXx9AOBXpfgr4Nurx3/AIvUbQQyWCHIJ/2z/QV6rpWg6VoUIi0mwgtVxg+WoyfqeprQHX1P0oAbDGkMaxxIERRhVUYAHsK5X4geN7bwdo5ZWEmozKRbQ+/94+wrpUu7eaZoobiGSROqK4JX6ivmTXNP8R6346ubS9t7i41OSdkVSpwq5+XHYKBQBT0jS9T8ZeJltYmaW8upN88z87QeWc/h2r6Zs7bTPBvhVIt6wWFhD8zt3x1J9ST+prF8DeCrLwLojvO6NeSLvu7puAAOcA9lFeX/ABK8ft4mvP7O0uRl0qBuvT7Q394+w7D8fp2YPCyxNTlW3VnFjMXHC0+Z79Ec54u8ST+KvEc+pTgqh+SGP/nnGOg/qfcmsSiivtYQjCKjHZHw85ynJyluwoooqiAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKR/uN9KWnxQSXU0dvCu6SVgiAdyTgVMtIsunrNep9eUUUV+fH6KFFFFABRRRQAVV1T/kD3n/AFwf/wBBNWqq6p/yB7z/AK4P/wCgmk9iKnwMNL/5A9n/ANcE/wDQRVqqul/8gez/AOuCf+girVC2Cn8CCiiimWFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFNlfy4nfaz7VJ2oMlvYe9ADqK4G3+L+i3erTaTZ6XrVxqkClprGO0BljA65G73qzb/Fbw6dZh0rVReaJezsFhi1OEQmQk4AHJ6mgDtaKAcjIooAKKK5i/wDHulaf8QrDwdPHdHUb+3NxG6xgxBRu4LZ6/Ke3p60AdPRRXOeOPG2m+AfD66xrMVzLbtOkAW2jDtubOOCRxwaAOjoqO2nS6tYp4s7JUDrkYOCKkoAKKKKACiszxBrsPh3S31C6tbq4giBaT7NGHKKOrEZHArlrL4u6LqWmf2lpml61eafnBu4bQGMYODzu7GgDvKKhtLqO9s4bmHPlzIHXcMHBqagAooooAKKKKACiqllqtjqMtxHY3UVw9s2yYRtnY3oat0AFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUANdA45yCOjDqK5Dxp4D0zxdbD7YottQUfubtB1PofUe35ZrsaQgMpDAEEYIPemI+V/EfhHXPCV+o1GF0RW/dXcJOxvcMMYPt1rpfDHxk1vR1S31aMaparxuZtsqj/e6N+P5171d2Ud1bvDNHHcQuMNDOu5T/n8fwrznxD8GdEvjJLpU0ukS8ttYb4ev6fn+FFgubWj/FjwnqoUNqC2EjfwXg8vB/3vun86662vrW7hWW2uYZkbo0bgg/lXztqnwi8V6e7G3tYdQjH8VrKCfrtODn8K5qfw9rWmyHzdG1G1ZertbOv64pDPrQOv94fnVa81OysYzJeXkFugGS0sgUfrXyh5mrfc82/Oe3mP/LNTW/hbXtRkBt9F1C4P977M5/XFAHvWsfFzwrpQKw3p1GUDiOyXeD/wL7v615h4m+L+u64HtrDGl2bcfuWJlYe744/D86bpXwe8V6lIrXcEOmxHvczAkj2VMn8Dj616BoXwe8P6TIkmrSvq1yvzCMrtj/74Ukn/AIESPagDz34VaDrN340s9VsI5ks4JCbq5fgOuOVz/ETX0S0qx9eSfuqByajghEUKw20KWsKjCqqgYHso4H+eKmSNY845J6sTkmmI8/8AHXhjxl4sY2lndaZZ6UDkQmeTfKfV8R4/AcfWuI/4Uh4m/wCfzSf+/wDL/wDG695orupY+vRjyQsl6HDVy/D1pc9RXfqzwb/hSHib/n80n/v/AC//ABuj/hSHib/n80n/AL/y/wDxuveaK0/tXFd/wRl/ZWE/l/Fng3/CkPE3/P5pP/f+X/43R/wpDxN/z+aT/wB/5f8A43XvNFH9q4rv+CD+ysJ/L+LPBv8AhSHib/n80n/v/L/8bo/4Uh4m/wCfzSf+/wDL/wDG695oo/tXFd/wQf2VhP5fxZ4N/wAKQ8Tf8/mk/wDf+X/43R/wpDxN/wA/mk/9/wCX/wCN17zRR/auK7/gg/srCfy/izwb/hSHib/n80n/AL/y/wDxuj/hSHib/n80n/v/AC//ABuveaKP7VxXf8EH9lYT+X8WeDf8KQ8Tf8/mk/8Af+X/AON0f8KQ8Tf8/mk/9/5f/jde80Uf2riu/wCCD+ysJ/L+LPBv+FIeJv8An80n/v8Ay/8Axuj/AIUh4m/5/NJ/7/y//G695oo/tXFd/wAEH9lYT+X8WeDf8KQ8Tf8AP5pP/f8Al/8AjdH/AApDxN/z+aT/AN/5f/jde80Uf2riu/4IP7Kwn8v4s8G/4Uh4m/5/NJ/7/wAv/wAbo/4Uh4m/5/NJ/wC/8v8A8br3mij+1cV3/BB/ZWE/l/Fng3/CkPE3/P5pP/f+X/43R/wpDxN/z+aT/wB/5f8A43XvNFH9q4rv+CD+ysJ/L+LPBv8AhSHib/n80n/v/L/8bo/4Uh4m/wCfzSf+/wDL/wDG695oo/tXFd/wQf2VhP5fxZ4N/wAKQ8Tf8/mk/wDf+X/43R/wpDxN/wA/mk/9/wCX/wCN17zRR/auK7/gg/srCfy/izwb/hSHib/n80n/AL/y/wDxuj/hSHib/n80n/v/AC//ABuveaKP7VxXf8EH9lYT+X8WeDf8KQ8Tf8/mk/8Af+X/AON0f8KQ8Tf8/mk/9/5f/jde80Uf2riu/wCCD+ysJ/L+LPBv+FIeJv8An80n/v8Ay/8Axuj/AIUh4m/5/NJ/7/y//G695oo/tXFd/wAEH9lYT+X8WeD/APCkPE3/AD+aT/3+l/8Ajddj4I+E0Ph3UY9U1i5S8vYTmGONf3UZx97nlj6dMfXp6PRWdXMMRVjyyloa0svw1KXPGOoUUUVwHeFFFFABRRRQAVV1T/kD3n/XB/8A0E1aqrqn/IHvP+uD/wDoJpPYip8DDS/+QPZ/9cE/9BFWqq6X/wAgez/64J/6CKtULYKfwIKKKKZYUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAeF+BAP+GofFfH/Lqf8A0IVr/tK6fa3Hwlmu5kj+0WtzEYZSPmXLYIB96oaT4e8X+HvjJrni1fDM17ZXyNDFFFdRK/3hhvmYDHH15rc8Q+EvEfxPvbG38TQR6L4atpBNNp4kD3F046BmUlQox2weTQBVk+I9xoHhXwfpMsttbatrFuM3V822K2RQfnYcZyBgDI5qTwX8Tr+8+IeteFtbvNN1WKxtPtkWqaaNsZXCkoRubn5uoPY0vxU8A6tqF/oHiHwdaQXV9oZEYsZyNssP90buM8nrXQaANR1y3vIdU8HJ4bSS2MTOzxM8jEdjGThR7+1AHPWfi/xx4z0OfxN4M/s+10pJGW3sru2aWe5Ver7gw257DFT6j4y12y+OWh+GJY7A2Oo2jXHmeQfOjwrZTdn1U846Gsn4caf47+G9rN4VuPDR1jTkuC1pqVvcxoArddyswOBgcAZq34h8P+Jrz47aN4ptdCeXTdMtjbORcRhpC27LgE9Bv788GgB2sfEy4f4i6v4bi13SfDy6ZEojbUkybqRlDAglgABnGOp61J8R/GXiXwr8KdP16L+yru7by47pWiLxOzD76fN04Pr1qHxpoN14j1PV7XWvh42sxlVGnX8VxFGRlAPmO4NlWJ69hWP4j+GvidfgfpngrT4W1O+81Z57lplCQ452fMQT14x6UAdX4/8AiFfeGNL8OWemRQvq/iCeO3hklXMUJYqCxUEEj5umao33jbxN4L+JOjaH4mms9R0vWU2pcQQGJ4JeeDljuBx+tRePfBeu+KND8Laxp2nmDV/D1yk/9nyyoTMFKnaGB2g/L696dqHh3xF4++Iug6prGiNomlaKDLItxMjyXEpBwE2EgAEjrjpQBFP458bS/GTU/BGmrpkghsTcQ3DxMPK3bSrMN3zABsEDGc5rR+FnjzX/ABH4h8SeHvFcVp9v0KZY2ntFKpICWHQk/wB39ao6d4d8SR/tCXvi+bQ5E0u7tBYhvtEZZMbR5hGfu/J0681N4D8La/4d+LnjHVL/AExv7O1u5329ysyEKqliCVznnd+lAHceNf8AkQ9d/wCwfP8A+gGvG/hL4h1fSPgPa/YtCFxAs8g+1PIGT5psHKYycZx1r2Hxsl/ceEdQs9K097+4vLd4FRJFTbuUjcSxHAzXK/BjQdb8K+CIfDXiLSDAbZpJPtHmo8cm592AAc8Z7jtQAuv+NNSPxMsPAHhQW9pOLf7TdXNxEXVIsDCoARz71B4c8da8nxL1LwL4ke0kvBAZ9PvIISquuD95Mnpj1qLxX4R13TPi/Y+PvDtk2rK1v9ku7JJFR1T+8pYgH6U/QPCmr33xP1Dx/reltYyQ2htrDTzKjStwcliCVGc4HNAGH4e8f/EvxTfa1p+k6fpUkul6gkDzsdi+XkbhtLcnGTn8MVpX/wAUrnV/EGv6f4f1rRtETQ28ln1YZN3LznYNy4AKkd+oqX4VaB4j8OeIvEEutaJJbwaxeG5SUTxsIhj7rAHJP0rIg8H+JfAnxI1vUNM8MxeKNE1yY3Mi74llgkJJwPMI4+Y0ATr8bbi6+Een+I44IrS8ur8afNcSoWgt2yN0pAPKgNnGexrpvDmvazq13qYh1zRPEOmLY7oZbAhHSc8FHG5uMc9vSpdXj1abwxZf8UfDcQTSn7XoyNECqHGDknaWHPQ1z/gH4dyaV481TXLHRH8M6ZLafZo9PecSGWQ8mT5WIA5xjrxQBQ/Z+XVxZauzLbrZtqU/m933h24Bz0r2qvLfhLoHirwpf61pWs6ZFFp0l7Jc296JVbzQzE42g5HXuK9SoAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigCM28RyQm0sckodpJ9yOtDRMWys0ij0G0/wAxmpKKd2KyADA5Ofc1G0TseJ5F+gX+oqSikMjMKscuWbjByxwfw6U9UVFCooUDoAMUtFFwCiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACquqf8ge8/64P/6CatVV1T/kD3n/AFwf/wBBNJ7EVPgYaX/yB7P/AK4J/wCgirVVdL/5A9n/ANcE/wDQRVqhbBT+BBRRRTLCiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKAGTTxW8e+eRY06bmOBT681+N18lv4RtbfeBJLeI23uVAOf1xXfaRfR6lo1pewMGjniV1I7giso1E6jh2sehVwUqeDp4rpNyX3W/PX7i5RRRWp54UUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAVV1T/kD3n/XB/8A0E1aqrqn/IHvP+uD/wDoJpPYip8DDS/+QPZ/9cE/9BFWqq6X/wAgez/64J/6CKtULYKfwIKKKKZYUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFNllSGJpJWCIgyzMcACuCufiHf6tfyWfgbR21Pym2yXkp2Qj3B6nms51Iw3OzDYOtir+zWi3bdkvVvQ7+iuDEXxMk+YT6NFn+A7jj/AMdo+zfEz/n80X8m/wDiaj2391/cdP8AZq/5/wAP/Av+Ad5RXB/ZviZ/z+aL+Tf/ABNH2b4mf8/mi/k3/wATR7b+6/uD+zV/z/h/4E/8jvKK4P7N8TP+fzRfyb/4mj7N8TP+fzRfyb/4mj2391/cH9mr/n/D/wACf+R3lFcH9m+Jn/P5ov5N/wDE0fZviZ/z+aL+Tf8AxNHtv7r+4P7NX/P+H/gT/wAjvKK4P7N8TP8An80X8m/+Jo+zfEz/AJ/NF/Jv/iaPbf3X9wf2av8An/D/AMCf+R3lFcH9m+Jn/P5ov5N/8TR9m+Jn/P5ov5N/8TR7b+6/uD+zV/z/AIf+BP8AyO8org/s3xM/5/NF/Jv/AImj7N8TP+fzRfyb/wCJo9t/df3B/Zq/5/w/8Cf+R3lFcH9m+Jn/AD+aL+Tf/E0fZviZ/wA/mi/k3/xNHtv7r+4P7NX/AD/h/wCBP/I7yiuD+zfEz/n80X8m/wDiaPs3xM/5/NF/Jv8A4mj2391/cH9mr/n/AA/8Cf8Akd5Ve+vrXTbKW7v50ggiUs8jtgAVxTWvxNZSBfaMpP8AFhjj/wAdpsHw81DWbiO48da0+phDn7HAPLhPpkDGaTqzekYv5lRwGHpvmr148vaN236aJfeylo9o/wARvFUviDULbbodpG0Gnxyqcyk9ZMenH61J4N1aTwdqsng7xFIY0Vy2m3Up+WaPsuegx6e9eiQQRW0CQ28axRIMKiDAArN8Q+GtM8T6eLXVrcSBTujkUlXjb1BHIqfYyj70X735nR/adKs3QqxtRaSSW8bbNd3q+bvd+RrUV57H4U8b6Hsh8PeJYbmyTpFqCZb6bgpP61N9m+Jn/P5ov5N/8TVe2fWDOd5dTesMRBrzbT+aaO8org/s3xM/5/NF/Jv/AImj7N8TP+fzRfyb/wCJp+2/uv7if7NX/P8Ah/4E/wDI7yiuD+zfEz/n80X8m/8AiaPs3xM/5/NF/Jv/AImj2391/cH9mr/n/D/wJ/5HeUVwf2b4mf8AP5ov5N/8TR9m+Jn/AD+aL+Tf/E0e2/uv7g/s1f8AP+H/AIE/8jvKK4P7N8TP+fzRfyb/AOJo+zfEz/n80X8m/wDiaPbf3X9wf2av+f8AD/wJ/wCR3lFcH9m+Jn/P5ov5N/8AE0fZviZ/z+aL+Tf/ABNHtv7r+4P7NX/P+H/gT/yO8org/s3xM/5/NF/Jv/iaPs3xM/5/NF/Jv/iaPbf3X9wf2av+f8P/AAJ/5HeUVwf2b4mf8/mi/k3/AMTR9m+Jn/P5ov5N/wDE0e2/uv7g/s1f8/4f+BP/ACO8org/s3xM/wCfzRfyb/4mj7N8TP8An80X8m/+Jo9t/df3B/Zq/wCf8P8AwJ/5HeUVwf2b4mf8/mi/k3/xNMkuPiVp0bTPbaXqe3nyYmKsfpwKPbd4v7hrLL6RrQb/AMX+asd/RXJ+GvHtnrd42mX8EmmatHw9rcDG499p7iusrSE4zV4s4cRhquGn7OrGz/rVd0FFFFWc4UUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFVdU/5A95/1wf/ANBNWqZLEs0LxSDKOpVh6g8UEyV4tEGl/wDIHs/+uCf+girVY8MWsaXCkMSwajbRgKmX8qYKOgPBVj7/AC0/+3PL/wCPzS9Rtz3xb+cP/IRapT7mMasYxSlp/XfY1aKy/wDhJdIH+tvBD/13Rosf99AU5fEeiP8Ac1nT2+l0n+NPmRft6X8y+80qKof29pH/AEFbH/wJT/Gr9O5cZxl8LuFFFFBQUUUUAFFFFABRRRQAUUUUAFFFFAHnvjG4uvFXiq38HadM0VqE8/UpozyEzwntnH612+maZZ6Pp0Njp0CwW8K4VFGPx+p9a5HwFp858QeJNYvbWWCe6vPLUyoVLIAMEZ7V3Nc9FXvUe7/I9jMqns1DCU37sEr+cmrtv8l5IKKKK6DxwooooAKKKKACiiigAooooAKKKKACiiigAopCQqkscADJJ7Vj3ni3Q7Fts+owk9wjBsflQBs0EgDJ4FcvL8RfDscTOLtnIHCiM5Ncm/ia28TTu+u6q9hYZwlnADucerNQB3d54t0OxYpPqEO9Tyitkiqf/CwPD/8Az9t/3zWTY614E05R9mEYbu5iJJ+tX/8AhNPCf/PWP/vz/wDWoAn/AOFgeH/+ftv++aP+FgeH/wDn7b/vmoP+E08J/wDPWP8A78//AFqP+E08J/8APWP/AL8//WoAn/4WB4f/AOftv++aP+FgeH/+ftv++ag/4TTwn/z1j/78/wD1qP8AhNPCf/PWP/vz/wDWoAn/AOFgeH/+ftv++aP+FgeH/wDn7b/vmoP+E08J/wDPWP8A78//AFqP+E08J/8APWP/AL8//WoAn/4WB4f/AOftv++aP+FgeH/+ftv++ag/4TTwn/z1j/78/wD1qP8AhNPCf/PWP/vz/wDWoAn/AOFgeH/+ftv++aP+FgeH/wDn7b/vmoP+E08J/wDPWP8A78//AFqP+E08J/8APWP/AL8//WoAn/4WB4f/AOftv++aP+FgeH/+ftv++ag/4TTwn/z1j/78/wD1qP8AhNPCf/PWP/vz/wDWoAn/AOFgeH/+ftv++aP+FgeH/wDn7b/vmoP+E08J/wDPWP8A78//AFqP+E08J/8APWP/AL8//WoAn/4WB4f/AOftv++aP+FgeH/+ftv++ag/4TTwn/z1j/78/wD1qP8AhNfCf/PWP/vz/wDWoAn/AOFgeH/+ftv++aP+FgeH/wDn7b/vmrdjq/h7USBaT2bseiHaGP4VqfYrb/n3i/74FAGAPH/h/P8Ax9n/AL5rRsfEuj6k4Szv4XkPRN3zflV02NqwwbeIj/cFZmoeENF1FT51kiORxJF8rD6GgDaoriXbWPBLq0kj6loucEtzJAO31FdhZ3kF/aR3NpIJIpBlWFAHPeNvCMXiXTfOtv3Gq2o8y0uVGGVhyBn0JpfAfiR/Enh0Pd4W/tHNvdoDnDqcfqBmumrg/DFvd6f8U/EtstpLFp06JPHKYyEZ8KDg9CeT+Vc8lyVFJddGezQn9YwVSjU3p+9Hy1Sa+d727o7yiiiug8YKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAoorl9V8XfvZrXQRbSvC2y41C7k2Wdq3dWfOXcf3F/ErQB0V3eW2n2r3N/cQ21vGMvLM4RFHuTwKwR4v+38eG9Iv9XX/n4VBBb/AFEkhXePdA1R6P4e0u+kj1S/1JfEl5G2UuZXV4oT/wBMo1+SPg4yBu9WNdRQBzuzxlectPoulKf4FilvGA/3t0Qz+B/Gj+wdef8A1vjC8Q9/s9lbKPw3I1dFRQBzv/CP64n+r8Zag/8A12s7Vv8A0GJaPs/jG15i1HR9SUdEntJLZj9XV3H/AI5XRUUAc2fFN3p//Iw+H76yj73Npi8hH/fH7wD3KAe9bOm6rYaxaC50q9gvICceZBIHAPocdD7VbrA1vw5pEskmrNO2jXqL82p2sghcAdN5PyyKM9HDD2oA36K860n4raVDqy6RrWq2V1uO2LVLXKRP7SKfuN7gsnfK9K9EBDKGUggjII70ALRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFMllWGF5ZDhEUsx9AOafVXVP+QPef9cH/wDQTQTJ2i2UYZdY1SFJomg062kAZMp5sxU9CeQqn2+an/2H5n/H5qmo3B74uPJH/kILVvS/+QPZ/wDXBP8A0EVaqUu5jGlGUU5a/wBdtjL/AOEa0g/62zE3/Xd2lz/30TTl8OaIn3NG09fpap/hWlRT5UX7Cl/KvuKH9g6R/wBAqx/8Bk/wq/RRTsXGEY/CrBRRRQUFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUjMFXLEAepNc5rfio297/Zei25vtSYcqv3Yh6saqReEtT1MibxHrEzM33re2YpGPyoA6g39mDg3UA/7aCqep+INN0uwkup7qJlQcKjglj6CsofDzw8OttKx9WmY0v/AArvw4eto3/f00AZUUV74tZbrWdSj0/Tz80VpDMAzD1Y57+lb9jpHhrTl22sVkPUu4Yn8zVX/hXvh0/8uj/9/Wo/4V54d/59H/7+tQBrbdF9LD8ko26L6WH5JWT/AMK88O/8+j/9/Wo/4V54d/59H/7+tQBrbdF9LD8ko26L6WH5JWT/AMK88O/8+j/9/Wo/4V54d/59H/7+tQBrbdF9LD8ko26L6WH5JWT/AMK88O/8+j/9/Wo/4V54d/59H/7+tQBrbdF9LD8ko26L6WH5JWT/AMK88O/8+j/9/Wo/4V54d/59H/7+tQBrbdF9LD8ko26L6WH5JWT/AMK88O/8+j/9/Wo/4V54d/59H/7+tQBrbdF9LD8ko26L6WH5JWT/AMK88O/8+j/9/Wo/4V54d/59H/7+tQBrbdF9LD8ko26L6WH5JWT/AMK88O/8+j/9/Wo/4V54d/59H/7+tQBrbdF9LD8ko26L6WH5JWT/AMK88O/8+j/9/Wo/4V54d/59H/7+tQBsxwaTKcRRWbn0VUNS/wBnWP8Az52//fpf8K55/h9pCKTYvdWknZ4p24/DNVZD4j8KYkaU6zpq/f3DEqD196AOr/s6x/587f8A79L/AIUf2bY/8+Vv/wB+l/wqPStWtNZsUu7CTfG3UHgqfQjsau0AYeoeD9F1EEvZrFL/AAywkoyn1GKxWn1jwTIv2uV9T0Ynb5hGZIPr6121MlijnhaKZFeNxhlYZBFADba5hvLZLi2kEkUgyrDuKlrjdB3+G/FE3h+RmayuAZ7Msfueq5/KuyoAbJGksbRyqHRhhlIyCK47RQ3hjxZLojE/YLzM1oWPCHug/MV2dcl47QW6aVqY4ktbxAD7Mef5UAdbRSI25Fb1GaWgAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiuX1iWTxLq7+HrCZo7K3wdXnjOCQwyturDozA5YjkLgdXBAAkk8/jKZ7exlkttAjYpPdxOVe+YHBSJhysYPBcct0Xj5q8E+IuptdeLbrTIEW203SpDaWdnENscSpwSFHGSQTmvqGGGO3gSGCNYoo1CIiLhVUDAAA6CvIfiP8JL/AFfXJta8NGKR7k7ri1kfYd+MblJ457g45qotJ6iZ5r4B8QXnh3xjYTWcjCKedIbiIH5ZEZgpyPUZyPpX1XXhfgz4YSaFr1lqvje7s9PjilBtrV7hd00o+7znGAecDJPFe6U5WuCCiiioGFFFFABXgHxH1jVPG/xDXwrpTH7Pbz+QkW7CvKB87t7Lz9AD617/AF85z6hH4J+O91fXv7y3jvZHkKHcQkqnn6gP09quImdY3wAs/wCzMLrdx9u2/fMS+Vu9NvXH41h+BfHOpeA9ck8K+JEkmsYJDFhMu1qRzlPVMc7R25HofZm8VaCul/2idYsvsm3d5vnLjH88+3WvDdFuG8cfHePU7CJlt1uxc5IwViiAAJ9M4X/vqhXe4H0LDNHcQRzW8iyxSKHR0bKspGQQR1BFPrlE/wCKN1pIdwTw/qMoSIHpY3LHhB6RyE8Dor8dGAHV1AwooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKq6p/wAge8/64P8A+gmrVVdU/wCQPef9cH/9BNJ7EVPgYaX/AMgez/64J/6CKtVV0v8A5A9n/wBcE/8AQRVqhbBT+BBRRRTLCiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiqeparZaRam41G4SGMf3jyfoO9AFyiuQ/4S7VdT3Dw9ockyg8S3J2Kw9RnFPF344YZNhpqe24n+tAHUXFxDaW7z3MixRRjLO5wAK5NvFGq65I0fhSwzEpwby5GEP0Hes7WNI8X67JCL+K08iI7vs6OQjn/AGuc1pQv4yt4Vig0/S441GFVSQAPzoAP+Eb8S3J8y58TSQsescCYA/WlPhPWyP8Aka738v8A69P+0+N/+fPTf++j/jR9p8b/APPnpv8A30f8aAKdp4BvrB5XsvENxC8x3SMi8ufU81a/4RPW/wDoa738v/r077T43/589N/76P8AjR9p8b/8+em/99H/ABoAb/wiet/9DXe/l/8AXo/4RPW/+hrvfy/+vTvtPjf/AJ89N/76P+NH2nxv/wA+em/99H/GgBv/AAiet/8AQ13v5f8A16P+ET1v/oa738v/AK9O+0+N/wDnz03/AL6P+NH2nxv/AM+em/8AfR/xoAb/AMInrf8A0Nd7+X/16P8AhE9b/wChrvfy/wDr077T43/589N/76P+NH2nxv8A8+em/wDfR/xoAb/wiet/9DXe/l/9ej/hE9b/AOhrvfy/+vTvtPjf/nz03/vo/wCNH2nxv/z56b/30f8AGgBv/CJ63/0Nd7+X/wBej/hE9b/6Gu9/L/69O+0+N/8Anz03/vo/40fafG//AD56b/30f8aAG/8ACJ63/wBDXe/l/wDXo/4RPW/+hrvfy/8Ar077T43/AOfPTf8Avo/40fafG/8Az56b/wB9H/GgBv8Awiet/wDQ13v5f/Xo/wCET1v/AKGu9/L/AOvSm58b/wDPlpv/AH0f8aYda8XWRL6hocE0C8k20nzfkTQA7/hE9b/6Gu9/L/69H/CJ63/0Nd7+X/160NH8Xadq0v2cl7S7A5t7gbW/XrW7QByB8Ka+pzH4rus+jrkfzprXXi3QvnuoYtXtF+8YRtl+uOa7GigDM0XxBY67bmSyk+dOJInGGQ+hFadcn4l8Py2839u+Hx5N/B80ka/dnXuCPWtzQ9Xh1zSIb234DjDp/cbuKANCgjIwelFFAHE6vbt4P16PWbEFdOunCXsK9FJ6OB69a7VHWSNXQ5VhkEd6o63YLqeiXdowz5sZA9jWd4HvTeeE7XeSzwgxMT3IoA6CiiigDkvG8fk3Wi6ivDW94qnHcMRx+ldYp3KCO4zXL+Pv+QRaf9fkX866eL/Up/uigB1cp8RP+Rai/wCvyL+Zrq65T4if8i1F/wBfkX8zQB1EP+pT/dH8qfTIf9Sn+6P5U+gAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKAMrxHq8mjaO01rEs97M629nAxwJZnOEBPZe5PZQT2p+g6Omh6PFZiQzy5MlxcMPmnlY5eQ+5JP0GB2rMjH9s/ECWQnda6BEI0HY3Uy5Y/VYioH/AF2auloAKKKKAPKPjt4clv8ARLTW7fcw08lJk7BHI+b8CB+ftXSfCzxNJ4m8EwSXRZrqzb7LM5/jKgYb8VIz75rr54Irq3kguYklhkUq8brlWB6giuE1Lxz4b8Aa/Z+GIdNNrBIFeSSBQscO84BI6npyewqt1YR39FAORkciipGFFFcT8R/iDb+DdN8m1KTatcL+4iPIjH/PRvb0Hc/jT3Ap/E74jx+FLM6bpTrJrE6cdxbKf4j7+g/H6+P+CfBGpePdYmZpnitUYtdXrjcdx5wM/eY9ai8K+F9W+IXiaQNLIwZ/Nvb6TnYD/Nj2H9BX0xoui2Ph/SINN0uEQ28K4A7se7E9ye5q37qshbnjQ/Z/1H7Xg63aeRn7/kNvx9M4/WvUPBvgfS/BVg8OnhpbibHn3UuN8mO3sPYV0lFQ5NjK2o6fbarptxYX0Ykt7iMxyKe4I7eh9D2rL8LX91JbXGlas/malpTiCaQ/8t0IzHN/wNeT6MGHat2ua14f2T4m0nXE+WKZxpl76FJD+5Y+6ykKPaZqQHS0UUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFVdU/wCQPef9cH/9BNWqq6p/yB7z/rg//oJpPYip8DDS/wDkD2f/AFwT/wBBFWqq6X/yB7P/AK4J/wCgirVC2Cn8CCiiimWFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRXO+JfEMthJFpukx+fqd1xGvaMf3jQBparrunaNGG1C5SMn7qdWY+gFYI8bXF4M6PoV7cL2Z1Cg/rVrRfB9taP9t1Zv7Q1GT5nlm+YKfRQfSuk6dKAOSPiXxJg48LT57Zcf41zscGv3WsPqWu+Hbi+kz+5hZh5cQ+mcGvT6KAORXxH4hRQqeFZlUDAAZQB+tL/AMJL4j/6Faf/AL7H+NdbRQByX/CS+I/+hWn/AO+x/jR/wkviP/oVp/8Avsf411tFAHJf8JL4j/6Faf8A77H+NH/CS+I/+hWn/wC+x/jXW0UAcl/wkviP/oVp/wDvsf40f8JL4j/6Faf/AL7H+NdbRQByX/CS+I/+hWn/AO+x/jR/wkviP/oVp/8Avsf411tFAHJf8JL4j/6Faf8A77H+NH/CS+I/+hWn/wC+x/jXW0UAcl/wkviP/oVp/wDvsf40f8JL4j/6Faf/AL7H+NdbRQByX/CS+I/+hWn/AO+x/jR/wkviP/oVp/8Avsf411tFAHJf8JL4j/6Faf8A77H+NH/CTeIV5fwvcBe+GH+NdbRQBysHj2xWcQ6rbXOnP3adPl/MV00FxFcwrLbyLJGwyGU5Bpt1aW97AYbuFJoz1V1yK4+90m98GytqXh8vNp+c3FgxyAO5WgDtqKq6bqVtq2nxXlk++KQZHqPY+9WqAMfXfDVjrkJ8xBFdLzHcxjDofr3rO8N61dwag+ga8f8ATYRmGbtMnr9eldTXK+OrFxpsWsWnyXemuJVf/Z7igDqqKgsbtL6whuojlJUDCp6AAjIwelcfoCjRvG+qaSpxDcKLmFB0XOc4rsK5K6G34qWTDq1m4P6UAdbRRRQAjfdP0rk/hv8A8i1N/wBfcn9K6xvun6Vyfw4/5Fub/r7k/pQB1tFFFAHLePv+QTaf9fkX866eL/Up/uiuY8ff8gm0/wCvyL+ddPF/qU/3RQA6uU+In/ItRf8AX5F/M11dcp8RP+Rai/6/Iv5mgDqIf9Sn+6P5U+mQ/wCpT/dH8qfQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFNd1ijaSRgqKCzMegA706sHxzM8PgLWvJO2WWzkhiPo8g2L+rCgBngaNm8KQX8ykTao76hJu6/vmLqD/uoUX6KK6GmQQpbW8cEI2xxIEUegAwKfQAUUUUAFeZfGPwPceItNt9V0e1a41C0/dyRRjLSxH0Hcg849Ca9NrnvGvi+18GeH3v7lfNmc+XbwA4Mr4/QDqTTV76AN8CLqlv4E01PEamG9ii2OJD8wUEhd3vtxmt+K4hnz5M0cmOuxgcV8r6jrvijx5q3lyyXV/K5JS0tlOxB7IOAPc/iahu/DfifwqFvrnTr7TApGLhMqFP+8p4/Gr5RXPofx746s/BWj+Y22bUJwRa22fvH+83oo/XpXz/pGk638RvFzr5jTXM7eZc3Tj5YU9T6AdAv4VUi/tfxt4otoLm8Nzf3jLCstw+AABx+AHYdfqa+mPCHhKw8HaGlhYLukbDT3DD5pn9T7eg7UfCg3LHhrw3p/hXRYtN0uPbGnLufvSt3Zj6mtaiisxhRRRQAVm+ItL/trw3qGnKdslxAyxP/AHJMZRh7hsH8K0qKAM7w/qY1rw3p2p42m7to5WX+6xUEj8DkfhWjXO+Cv3OkXtl/z56neRAeimZnQf8AfDrXRUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFVdU/5A95/wBcH/8AQTVqquqf8ge8/wCuD/8AoJpPYip8DDS/+QPZ/wDXBP8A0EVaqrpf/IHs/wDrgn/oIq1Qtgp/AgoooplhRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQBHczra2stxJ9yJC7fQDNct4KtWvXuvEV4N0985ERP8MYOAP0q/42na28H37ocEpt/Pir2gwLb+H7GNBgCBD+YBoAxtL8dWWpeJNT0lba7VrCQR+Z9ncqx5zzjA6Vb0/xpoeqTWkdheec13uEW1DjK9QT2Psa5vw/qsemfEzxPo2oLJDPdeVcWh8pisybW3YYDAxkDBOeah+H2nfafhVcW9pb+RfMJ0VnjKMJGGN2SM+nNAHX23izRrvUI7OC7BeZmSGQqRHMy53Kj9GIwcgHjBpb3xXo+nXptru68soQJJCp8uInpvfov4mvOvCL6Nq39jaNqEt+uraTM0o01rTy/s7gsC3mBQpBBJ4Y8NVC3g0+2XXfCXjK8vkm1XUp5RaR2xkW7ieUvGFkCnGBjqRigD1zXP7TbRbldB8oag6FYHm+4jHoxHcD0riLS88Valrmu6bpurQu2mW6Ro7JwbsgEq3+zgjA616Cmy1s13FgkScluTgCuJ+FWbvTdZ1qSOWKbVtTkuJI5UKsmFVAOfZAfxoA7SwFyNNthqBU3fkp55T7u/A3Y9s5qxRRQAUUUUAFFFFABSHO07euOKo32s2VhGzTTBnB2iNBuZm7DA/n0qj9j1DW8nUy1lZEgi1jbEjj/bYdOf7pqHLotzohQbXPP3Y/1suv9XZW8MeJ7jxBfX1u1uIjp1zJa3OVI+dTxtz1B55rpqjighgLGGJELnLFVALH1PrUlWc4UUUUAFFFFABRRRQAUjKGUqwyCMEHvS0UAcdooPh7xpdaMufsd4v2i3B6Ie6j867GuR8WDyvFXhudeD9pMbY7g4rrqACqGuRLNoV5G4yrRMCKv1U1b/kEXX/XI/yoAzPBDl/Bun5/hj21vVz3gb/kTrH/AHa6GgArkrv/AJKlY/8AXo/9K62uSu/+SpWP/Xo/9KAOtooooARvun6Vyfw4/wCRbm/6+5P6V1jfdP0rk/hx/wAi3N/19yf0oA62iiigDlvH3/IJtP8Ar8i/nXTxf6lP90VzHj7/AJBNp/1+Rfzrp4v9Sn+6KAHVynxE/wCRai/6/Iv5murrlPiJ/wAi1F/1+RfzNAHUQ/6lP90fyp9Mh/1Kf7o/lT6ACiiigAooooAKKKKACiiigAooooAKKKKACiiigArnfHXPhcJ/z0v7GM/8Cu4l/rXRVzvjv5fB9xL2gntpyfQJPG5P5LQB0VFFFABRRRQAV8/fHbUZLjxpbWJY+VaWgZVzxuckk/kB+Ve9Xl9aadatc6hcw20C/ekmcIo/E14b8ctLEmq6b4hs2WeyvIBCZo23LuUkryOOQeP901UdxM9D+FPh210TwLY3EUa/atQiW4nlxy27lVz6AEcfWuzngiuYHhuI1likUq6OMhgeoIrzD4S/EDTbnw7baFql1Ha31mvlReawVZo/4cE8ZA4x7V3mueKNH8O6e93qt9DEijKoGBeQ+ir1Jod7gfNPjLSx4Q8fX1rpzFFs51mtiDygIDqM+2cfhX1LYXP2zTra5xjzolkx6ZAP9a+V76e88fePneKIifVLoKidfLToM/RRyfY19PabqWlPIdLsL+2nnslEckMcqs6YGOQOlVLZAjRooorMYUUUUAFFFFAHn1n438PeGvEvifT9ZvzbzjVBIqC3kfKtawHOVUjqTWj/AMLW8Gf9Bdv/AADn/wDiK8O8ZXH2r4i+JJgcg6gyZ/3ERP8A2SsitVGNtT6zC5BCtRjUc2rq+x9Ef8LW8Gf9Bdv/AADn/wDiKP8Aha3gz/oLt/4Bz/8AxFfO9FPlh/X/AAx0f6t0/wDn4/uPoj/ha3gz/oLt/wCAc/8A8RR/wtbwZ/0F2/8AAOf/AOIr53oo5Yf1/wAMH+rdP/n4/uPoj/ha3gz/AKC7f+Ac/wD8RR/wtbwZ/wBBdv8AwDn/APiK+d6KOWH9f8MH+rdP/n4/uPoj/ha3gz/oLt/4Bz//ABFH/C1vBn/QXb/wDn/+Ir53oo5Yf1/wwf6t0/8An4/uPoj/AIWt4M/6C7f+Ac//AMRR/wALW8Gf9Bdv/AOf/wCIr53oo5Yf1/wwf6t0/wDn4/uPoj/ha3gz/oLt/wCAc/8A8RR/wtbwZ/0F2/8AAOf/AOIr53oo5Yf1/wAMH+rdP/n4/uPoj/ha3gz/AKC7f+Ac/wD8RR/wtbwZ/wBBdv8AwDn/APiK+d6KOWH9f8MH+rdP/n4/uPoj/ha3gz/oLt/4Bz//ABFH/C1vBn/QXb/wDn/+Ir53oo5Yf1/wwf6t0/8An4/uPoj/AIWt4M/6C7f+Ac//AMRR/wALW8Gf9Bdv/AOf/wCIr53oo5Yf1/wwf6t0/wDn4/uPoj/ha3gz/oLt/wCAc/8A8RR/wtbwZ/0F2/8AAOf/AOIr53oo5Yf1/wAMH+rdP/n4/uPoj/ha3gz/AKC7f+Ac/wD8RR/wtbwZ/wBBdv8AwDn/APiK+d6KOWH9f8MH+rdP/n4/uPoj/ha3gz/oLt/4Bz//ABFH/C1vBn/QXb/wDn/+Ir53oo5Yf1/wwf6t0/8An4/uPoj/AIWt4M/6C7f+Ac//AMRR/wALW8Gf9Bdv/AOf/wCIr53oo5Yf1/wwf6t0/wDn4/uPoj/ha3gz/oLt/wCAc/8A8RR/wtbwZ/0F2/8AAOf/AOIr53oo5Yf1/wAMH+rdP/n4/uPoj/ha3gw/8xdv/AOf/wCIrodI13TNet2n0e9hu41OGMbcqfcdR+NfK1anhvXbjw34gttTtXK+WwEq9njP3lP4fkcGnyReiOXFcP8AsqMqlOd2tbNH1JRRRWB8qFFFFABRRRQAVV1T/kD3n/XB/wD0E1aqrqn/ACB7z/rg/wD6CaT2IqfAw0v/AJA9n/1wT/0EVaqrpf8AyB7P/rgn/oIq1Qtgp/AgoooplhRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQBzfj//AJEq++i/zFbOk/8AIFsv+veP/wBBFY3j/wD5Eq++i/zFbOk/8gWy/wCveP8A9BFAFuiiigAooooAKKKKACiimySxwxmSZ1RB1ZjgCgB1FZb+IbHIFsZLzPGbVDKAfcjpTDc6zd5WCzisl6rLM/mZH+6MEVfI+uhPMuhrnivO9U8Q6odTvGjuvs/2aVkjTsuP7w71139jT3BD6jqNxIcYaKE7Im/4Dyf1preE9Dd9x06H3GOG+tXBwg9dTGrCpUSUXYo+EfDltpkR1ASSzXF0u92nbeyk9QD2HtXTVjHw1axKq6dcXWnIpz5drJtU/UEGjytetZCyz215Co+WIoUc/V84/SuVe4rJaHrVX9YlzyqXfnp/mvxNmisX+35rZF/tTSrq3kY/dgUzgfUqOKu2+s6dczCGG8hM2M+VvG8fVetUpxZhLD1Yq7WnlqvvRdoooqjAKKKKACiiigAooooA5Lxh/wAh7w5/1+j+ldbXJeMP+Q94c/6/R/SutoAKqat/yCLr/rkf5Vbqpq3/ACCLr/rkf5UAZPgb/kTrH/droa57wN/yJ1j/ALtdDQAVyV3/AMlSsf8Ar0f+ldbXJXf/ACVKx/69H/pQB1tFFFACN90/SuT+HH/Itzf9fcn9K6xvun6Vyfw4/wCRbm/6+5P6UAdbRRRQBy3j7/kE2n/X5F/Ouni/1Kf7ormPH3/IJtP+vyL+ddPF/qU/3RQA6uU+In/ItRf9fkX8zXV1ynxE/wCRai/6/Iv5mgDqIf8AUp/uj+VPpkP+pT/dH8qfQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFZfibTm1jwnq2mx/6y7spoU9mZCAfzNalFAFDQ9SXWPD+n6lH928to5x7blBx+tW7m5hs7WW5upFihhQvI7HAVQMkmsDwgfsQ1TQn4bTLx/K94JT5sZHsNzJ/2zNRfEq0ur34cazBYhmmMAbavVlVgzD/AL5BoA4XUPj9bxagU0zRHuLRWx5ss/ls49Qu04/GvQvDXi+z8XeHZNS0RSZUBVraXhkkAyFPseOa+UM56V7P+z/aXQOtXZDC0fyolJ6M43E4+gI/OtJRSQjAHhXx/wDEfWmfXlntIonIZrtDHFD6hE7/AFHXua9is/A2lw+A4vCt7uvLNIypd+G3Eltw/ukE8eldLRUuTYHzp4j+C/iLS7hzpEa6tZ5+QowWQD0ZT1P0z+FcJqWm3mkXz2mp2sltdRgFopRhgCMj9K+xq8G+PWlfZ/Emnami4W7tzE59WQ/4MPyqoybdmFjuPhf8P9P8OabDrLTLe397ArrMFwsSMAdqj37n+VcV4u+E2uaHqkut+ELia5XzWmCRMVuISTn5SPvjntz7Gu/+EOq/2n8N7FWOZLNmtm/4Cfl/8dIrt6m7TA5X4e6jrt94NjufFsLQXauwDSp5bPGMYZl7Hr6dM10lpe2t/AJ7G5iuYicCSFw65+oqtrmlJrmg3ulyyvCl3C0RkTquRjNeB3Phnxz8MNV+06M01xbuwAltUMkcvoHj7H/INCVwPouisO68TQaJ4Qg1rxMPsLGFGmhAywkYfcUdznIxXCWvx80eXUBFdaTd29qWx5+9XKj1Kj+hNKzYz1ekZgqlmICgZJJ6VHa3UF7aRXVpKs0EyB45EOQykZBFcp8Vdc/sP4cam0bbbm9T7Db+u+X5cj3VSzf8BpFQi5yUVuz53N6dTubrUiMfb7qa7wewkkZx+jCimoixxqiDCqAAPQU6tz9Yo01SpxguiS+4KKKKDUKKKKACiiigAooooAKK6Dwz4K1nxY7HS4FW3jbZJczNtjRsZx3JPToDjIzgGtHXvhf4i0DT2vZUt7y3jUvM1pIWMSjHJDAEjnPAOACTgUro5JYzDxqeylNc3a5x1FdHo3gfWNe8N3Ws6WsU8dtIY2twx85yApO1cYPDdM5ODgE4zW0Twve69peq39nLbpFpUPnTCVmDMu1j8uAcn5D1x2ouW8TRXN7y912fk3sYtFdHo3gfWNe8N3Ws6WsU8dtIY2twx85yApO1cYPDdM5ODgE4zW0Twve69peq39nLbpFpUPnTCVmDMu1j8uAcn5D1x2ouDxNFc3vL3XZ+Texi0UUUzoCiiigAooooAKKKKACiiigAooooAKKKKACmyf6p/wDdNOpsn+qf/dNVD4kc+J/gT9H+R9dUUUVzH5QFFFFABRRRQAVV1T/kD3n/AFwf/wBBNWqq6p/yB7z/AK4P/wCgmk9iKnwMNL/5A9n/ANcE/wDQRVqqul/8gez/AOuCf+girVC2Cn8CCiiimWFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFAHN+P/APkSr76L/MVs6T/yBbL/AK94/wD0EVjeP/8AkSr76L/MVs6T/wAgWy/694//AEEUAW6KKKACiiigCC9u47Cxmup8+XChdsegrl4fHEkk6qdPZlmYLHtYArnoWyf5Vp6ncHWEn0nT13iQGO4uD92EHg49W9BWVF4KubV0livlnaAhkSSMASY6biOn4V0QjBL39zmqOq5L2e3U2mtdau9y3F7DZp/CbVcv+O7IqSPQbMSrPc+Zc3AGDJI5+b/gI4/SpNP1WO8ZoJUa3u4x+8gfqPceo9Kv1m5SWmxslF6jIoYoFxDGkY9EUCn0UVmWFFFFABRRRQAVVuNLsrpWWa2jO7qQu1j+I5q1RSaT3KjKUXeLsYv/AAji26qmk391p6A5KxsHDf8AfeaztcuvFunQRnTLa21EiRfkQ7HZe+4sQuPpzXV1k6lqxWZrDTYlu75hyjHCRg93PYfTNZyjFLR29DuoV6s6i5oqf+L9Xo/xMS28eefcQs1i0dtIQpJYbk5xk84xXYKwZQynIIyDXFR+AZ4kVF1UsqfMMxD5jnO0+1dFYapiVbDUEFteKPlXPySD1U9x9cc11zjBpOB5FN1FJqp30tt/XrqalFFFYm4UUUUAcl4w/wCQ94c/6/R/SutrkvGH/Ie8Of8AX6P6V1tABVTVv+QRdf8AXI/yq3VTVv8AkEXX/XI/yoAyfA3/ACJ1j/u10Nc94G/5E6x/3a6GgArkrv8A5KlY/wDXo/8ASutrkrv/AJKlY/8AXo/9KAOtooooARvun6Vyfw4/5Fub/r7k/pXWN90/SuT+HH/Itzf9fcn9KAOtooooA5bx9/yCbT/r8i/nXTxf6lP90VzHj7/kE2n/AF+Rfzrp4v8AUp/uigB1cp8RP+Rai/6/Iv5murrlPiJ/yLUX/X5F/M0AdRD/AKlP90fyp9Mh/wBSn+6P5U+gAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKAOa13/AIkviXT9fB220wXTtQPYIzZhkP8AuyMV9hKx7V0tQX1lbalp89lfQrNbXEbRSxsOHUjBH5Vi+GL64habw/q8jPqGnAbJ5Ot5bnhJh6nja3owPYjIBl6j8JPCGpai15LpzQu7bnSCZo0Y/wC6OB+GK6vTdNstI0+Ky0y2jtraIYSOMYA/+v71aop3YBRRRSAK85+N2l/bvAP2tVy9hcJLn0VvkP8A6EPyr0aub+IN5plr4F1NdanWGC4gaFMjJZyDtAHc55/CmtwPOfgDqmJtX0l2+8EuYx/463/ste1V8meDvFU/g7xDHqtvCs5EbRvCz7Q4b3+oBr6A8E/EzSfGbm1RGstRVdxtpWB3juUb+LH4H2qpJ3uJHZ0UUVAzyH4/x3LaTo0iBjarPIJMdA5Ubc/gGrw6vsTVNKsta02Ww1S3S5tphh43HX39j71w1r8EfCdtqAuHF5cRq24W80wKfQ4AJH41pGSSFYv/AAijuYvhlpou9w3GRog3aMuStecfGPxGNa8Yw6PbPutNFBMu08PcuvPt8iHH1dh2r0/x/wCLoPA/hQyWqRm/nH2fTrYYAL464/uIOT7ADqRXzlGrKCZZGmldi8srnLSOxyzH3JJP40oq7ufSZDgnVre3kvdj+f8AwB1FFFaH3gUUUUAFFFFABRRRQAUUUUAel+OPtOm/C/wnZ6f5sWnXNuJLpVyVeQqkgDH3ZpGC5xx0+UYt+CvB8jWXmeHfHcVtdX1mrXVpbxI7xggZBHmZBUtjdgEE8YzWB4X8dWVloQ8P+KdKXU9JVmaIqq+ZBuDZwDjJyxwcgrk8ngDRTx/4Z8NJJJ4F8OtDeTrsknvnLBFBBwBvYkHnOCvIU84qNdj5qpSxcKTw9OLvdu9otSu7+9fa3pfQ1Ph5rf8Awjnwp1HVSnmJb6ovmLjJKMYFbAyOdpOOcZxWpH4ej0Ox8dTWAVtM1HTRdWjxYMe1o5iVUgBcAngDOFK+tedaf4osrT4Yap4ckiuDeXl0s0bqq+WFBiPJznPyHt6Vr6L8So7b4f3vh3VoLiWU2stvaTxkN8rqwAfceAuQBjPGBgY5LMivgq7lUqU18U9fOPutP5NP72bXw81v/hHPhTqOqlPMS31RfMXGSUYwK2Bkc7Scc4zitSPw9Hodj46msAraZqOmi6tHiwY9rRzEqpAC4BPAGcKV9a860/xRZWnww1Tw5JFcG8vLpZo3VV8sKDEeTnOfkPb0rX0X4lR23w/vfDurQXEsptZbe0njIb5XVgA+48BcgDGeMDAxyWYV8FXcqlSmvinr5x91p/Jp/ezz2iiirPqAooooAKKKKACiiigAooooAKKKKACiiigApsn+qf8A3TTqbJ/qn/3TVQ+JHPif4E/R/kfXVFFFcx+UBRRRQAUUUUAFVdU/5A95/wBcH/8AQTVqquqf8ge8/wCuD/8AoJpPYip8DDS/+QPZ/wDXBP8A0EVaqrpf/IHs/wDrgn/oIq1Qtgp/AgoooplhRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQBzfj/wD5Eq++i/zFbOk/8gWy/wCveP8A9BFY3j//AJEq++i/zFbOk/8AIFsv+veP/wBBFAFuiimy7/KfysB9p256ZoAY1zAjsjyorKu5gW6D1rJae515tli722n5+e5HDTD0T0B/vV5e1jfT6sIXt7prlroE5Dc/NnOfTFe0xrtjVSACBjCjApxklrbU4sPiHiOa8WrMZa2sFlbJb2sSxRIMKqjAFS0UUtztKeoaZBqKL5m6OaPmKaM4eM+oNVINRuLGZLXWgoLnbFdqMJIfQ/3T6DvWvVDXUZ9BvAgXf5Tbd5wAcevari7+6yWraotpcQyTPEkitIn3lB5WpK8n09nS+042gmib7QgBcMuAWG4HPr79e1esVVWn7N7mNCt7VN2sFFFFZHQFFFFABUb3EUcqxPIquwyqk8mpK8m1bzTdambpZ3mV2EjKDycZ+XHtjpWtOnzt6mFaq6STSvc7G28THxOZbTw84iaORo7i4frFhiPlHcn17Vu6bpltpVr5Fqp5O55HOXkbuzHuT61BoNtHBotoUijRnhUsUXGcjv71pVzxi1rJ3Z6NetF+5SXLHs9/n/WgVXvbG31C3MN1GHXqD3U9iD2NWKK0Tad0cu5ii8utEYR6ozT2WcJeY5jHbzP/AIqtUXMDSrEsqGRl3Kobkj1p0qh4XUgEEHgjivI9ksUTGNZVnjk3CTDbQ+eGz02+/St4QVXyZzVaro20vc9foqOAsbeMucsUGT6nFSVznScl4w/5D3hz/r9H9K62uS8Yf8h7w5/1+j+ldbQAVU1b/kEXX/XI/wAqt1U1b/kEXX/XI/yoAyfA3/InWP8Au10Nc94G/wCROsf92uhoAK5K7/5KlY/9ej/0rra5K7/5KlY/9ej/ANKAOtooooARvun6Vyfw4/5Fub/r7k/pXWN90/SuT+HH/Itzf9fcn9KAOtooooA5bx9/yCbT/r8i/nXTxf6lP90VzHj7/kE2n/X5F/Ouni/1Kf7ooAdXKfET/kWov+vyL+Zrq65T4if8i1F/1+RfzNAHUQ/6lP8AdH8qfTIf9Sn+6P5U+gAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACsfxBokmqJb3enzi11WxYyWc5BK5Iw0bgdUYcEewI5ArYooAzND1uPWbeQNE1re2zeXd2chy8D+nup6qw4YcitOsfWtDe9nj1HS51sdXt1KxXJXcsidTFKvG9Ce3UHkEHrHpHiRbq7Gl6zCNN1oKWNoz7lmA6vC/HmL+o/iAoA3KKKKACvA/jPe3OsfEKw0JH2RQpGiA9PMlblvy2j8K98rxj43+Frv7ZbeKNORmWJBFclBkxFTlJPpzgntgVUdxM9F0fwJ4d0bSEsIdKtZl24kknhV3lPcsSK8U+IeixfD74h2V54fJgjYLdwxg/6tgxDKP9k46ehIrrdH+PVkukout6bctfIgDNbbSkp9eSNufTmuQjOqfF/4jRzPbmG0jKiQLytvADnBPdjz9SfQVSTT1A+jIZRNBHKBgOoYD6in0iqFUKowAMAelLWYwrL8ReItN8LaJNqmsT+VBHwFAy8rnoiD+Jj2H9KbrPiK10iSO1VXvNTuFJttPgwZZe2fRVHd2wB69q5bUfhs/i+4i1Lxnql0LxARDZ2Eii3tFPVV3ISzernBPTAAAprV6lw5OZc97eW/6Hi/iLxBf+LPEEusar+7Zl8u3tg2VtYs5CA92PVm7n2AAzq9x/4Uj4d/6COrf9/Yv/jdH/CkfDv/AEEdW/7+xf8AxutfdXU+xoZ7gaFNU6dOSS8l/wDJHh1Fe4/8KR8O/wDQR1b/AL+xf/G6P+FI+Hf+gjq3/f2L/wCN07x7m3+smF/kl9y/+SPDqK9x/wCFI+Hf+gjq3/f2L/43R/wpHw7/ANBHVv8Av7F/8bovHuH+smF/kl9y/wDkjw6ivcf+FI+Hf+gjq3/f2L/43R/wpHw7/wBBHVv+/sX/AMbovHuH+smF/kl9y/8Akjw6ivcf+FI+Hf8AoI6t/wB/Yv8A43R/wpHw7/0EdW/7+xf/ABui8e4f6yYX+SX3L/5I8Oor3H/hSPh3/oI6t/39i/8AjdH/AApHw7/0EdW/7+xf/G6Lx7h/rJhf5Jfcv/kjw6ivcf8AhSPh3/oI6t/39i/+N0f8KR8O/wDQR1b/AL+xf/G6Lx7h/rJhf5Jfcv8A5I8Oor3H/hSPh3/oI6t/39i/+N0f8KR8O/8AQR1b/v7F/wDG6Lx7h/rJhf5Jfcv/AJI8Oor3H/hSPh3/AKCOrf8Af2L/AON0f8KR8O/9BHVv+/sX/wAbovHuH+smF/kl9y/+SPDqK9x/4Uj4d/6COrf9/Yv/AI3R/wAKR8O/9BHVv+/sX/xui8e4f6yYX+SX3L/5I8Oor3H/AIUj4d/6COrf9/Yv/jdH/CkfDv8A0EdW/wC/sX/xui8e4f6yYX+SX3L/AOSPDqK9x/4Uj4d/6COrf9/Yv/jdH/CkfDv/AEEdW/7+xf8Axui8e4f6yYX+SX3L/wCSPDqK9x/4Uj4d/wCgjq3/AH9i/wDjdH/CkfDv/QR1b/v7F/8AG6Lx7h/rJhf5Jfcv/kjw6ivcf+FI+Hf+gjq3/f2L/wCN0f8ACkfDv/QR1b/v7F/8bovHuH+smF/kl9y/+SPDqK9x/wCFI+Hf+gjq3/f2L/43R/wpHw7/ANBHVv8Av7F/8bovHuH+smF/kl9y/wDkjw6ivcf+FI+Hf+gjq3/f2L/43R/wpHw7/wBBHVv+/sX/AMbovHuH+smF/kl9y/8Akjw6rmk6XPresWumWiM8tzIEwOw/iP0Ayfwr2X/hSPh3/oIat/39i/8AjddR4b8FaJ4VVjpdsTO4w1xMd8hHpnsPYYo5ox1ucuL4gpVKMoUYO7Vtbfo2b9FFFYHx4UUUUAFFFFABVXVP+QPef9cH/wDQTVqquqf8ge8/64P/AOgmk9iKnwMNL/5A9n/1wT/0EVaqrpf/ACB7P/rgn/oIq1Qtgp/AgoooplhRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQBzfj/AP5Eq++i/wAxWzpP/IFsv+veP/0EVjeP/wDkSr76L/MVs6T/AMgWy/694/8A0EUAW6KKKAE2Lv37RuxjdjmloooAKKKKACsjXGN09vpSEZu2JlB7wj7/AD68itYsF+8QPqaydJDXl9eajIDtZ/KhB6BVz8w/3v6VcNPe7Ey10LOo6bHd6dLDGirIVBjcjo68qT9Dil0i8+3aXDM2d+Cj567lOCfzFXax4R/Z3iKWM8QXy+YrE8CQDG0D6DNC1i0D0dzYooBB6HNFQUFFFBIHU4oAp6peGw06WaNQ8uMRIf43PRfxpum6dHaaZDBIolZVO5nGSSeufzxVW4/4mPiGK24MFiBPIpHVz9wj6YP51sVb0jYlau5i6CzWk93pMxYm2cvE7nmRG+bI9gTt/Ctqua8U6hbaBdWetTsIwreRKcZLxnnaPfdg10FtOLm1imA2+YgbaeoyKwg0m49juxEJSjGvbSX5rf8Az+ZLRRQSB1OK0OMzdcupINP8q2IFzcuIYc9Nx9fbANWIdOtobBbNYlMKxeVtbnK+lUYCdQ8RyzdYLJPKQ9VdzyT9Vxj8a2KuWiSIWruZWiTSRLLptyxaa1bCs3WRDyG+nOPwrVrI1hGtLmDVYFJMPyTqo5eMnufRSd1aqSJKivGwZWAIIPUGiWvvdxx00OU8Yf8AIe8Of9fo/pXW1yXjD/kPeHP+v0f0rragoKqat/yCLr/rkf5Vbqpq3/IIuv8Arkf5UAZPgb/kTrH/AHa6Gue8Df8AInWP+7XQ0AFcld/8lSsf+vR/6V1tcld/8lSsf+vR/wClAHW0UUUAI33T9K5P4cf8i3N/19yf0rrG+6fpXJ/Dj/kW5v8Ar7k/pQB1tFFFAHLePv8AkE2n/X5F/Ouni/1Kf7orl/H3/IJsx3N5Fj866iL/AFKf7ooAdXKfET/kW4R3N5Fj8zXV1yPi5/t+uaNo8fz77gTTAfwquOf1oA6uL/Up/uj+VPoAwoA7UUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFU9U0iw1qzNrqlslxFuDKGyCjDoysOVYdiCCKuUUAcwtt4l8P8Wc3/CRWAP8Aqbl1jvIx/sycJJ6APtPqxqxbeNdFkuFtr+d9Ju2OBbamht2Y+ilvlf8A4AWFb9R3FtBdwNDdQxzxMMNHIgZT9QaAHghlBUggjII70MqupVwGVhggjIIrnj4F0GMk2FvcaYc5A028mtVB/wByNgv5ij/hFLlP9R4q16Idh5sMmP8AvuJv1oAqXfwt8G3t0biXRIVcnJETtGpP+6pArodL0jT9EsxaaTZw2kA52RIBk+p9T7msn/hFrxv9d4t16X/gVun/AKBCKP8AhBtGl/5CJv8AUs9VvtQnmRvrGX2f+O07sCe+8YaHY3Btftq3d6P+XOxU3E/4ogJA9zge9VGl8Ua8dtvEPDdkess2ya8cf7KAmOPtyxc+qit6y0+y0y3FvptpBaQr0jgiEaj8AMVYpAZuj6DYaHHJ9iiYzTHdPczOZJp2/vO55P06DoABWlRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUjKHQqc4YYOCQfzHSsz/hHbHvJfn66lcH/wBnpakSc18K/H/gM1Ka7rGpaRlVR1LHArN/4RvTD96GV/8ArpcyN/NqVPDeiIwYaTZlh/E0CsfzIzRqRer2X3v/ACHS+IdIhfY2o2zSf8845A7/APfK5NVbrULrVLWW20vT5yJkKG5ulMMaAjGdrfOfptwfUVsRQxQJtgjSNfRFAH6U+izE4VJK0paeS/zv+RHbQi2tYoAdwiRUBPfAxUlFFM2SsrIKKKKBhRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQBzfj/8A5Eq++i/zFbOk/wDIFsv+veP/ANBFY3j/AP5Eq++i/wAxWzpP/IFsv+veP/0EUAW6KKKACiiigAooqG7uBaWc1wwyI0LY9cDpRuB5p4jb7Rrl2uotmaM4Vd/CrjIx+Fd54ZLnwxp+/wD54Lt+mOM+9JpGnRNpSPdxrLLcZlZnQFgHOQv4A4o0FmhiuLCTCm0lKxr6RfwfoK6aklKPKuhy0qXJNzb3NauQ+I0VxJo1sYI2eNJ8zFRyq7Tz+eK6+kZVdSrqGU9QRkGuY2q0/aU3C9rnnXw3Fyuo3C2+/wCweX8xJJXfnjB+ma9GpkUMcC7YY0jX0RQBT6S0VjPD0fYUlTvewV538SRctfWizeZ9g8snjITfnufXrivRKZJFHMu2aNZFznDKCKb1Vh4ij7ek6d7XOT+HMM8Why70ZYDKTEXB3H169R6V19IqqihUUKoGAAMAUtBVKn7KmoXvYyvEqO/hu8EaK77MgMOOoz+lef8Ah50g13T2059pkmVJDu6oeoOf5V3fiA/a/s2koC32uQecUOGjjHO76ZAH41Nq2mLLpshsYIkuoz5kLBQMOOh4rSlUSbjb5l4jDtxhPmfV2/rvqaleY/EMXD67GLwOLVY8w4JCn15/ve3pXo1hdx39hDdQnckq5BxUssMUwAmjSQA5AdQcVnJdDDE0frFLkTtc57wDBPb+EoUuY2jYyOyhhyVLZB/KukoAAAAGAOgFFG5tTjyQUexW1JZH0q7WFd0jQuEX1O04rx3R1voNatvsaSLqIcK6c8euR2HWva6jW3hWUyrDGJD1cKMn8aPmc2Iw3tpRlzNcpy3jD/kPeHP+v0f0rra5Lxh/yHvDn/X6P6V1tB2BVTVv+QRdf9cj/KrdVNW/5BF1/wBcj/KgDJ8Df8idY/7tdDXPeBv+ROsf92uhoAK5K7/5KlY/9ej/ANK62uSu/wDkqVj/ANej/wBKAOtooooARvun6Vyfw3/5Fqb/AK+5P6V0epXa2Gl3F1JwsMZY1ieAbU23hG3ZuDcM035//qoA6WiiqGsaxaaJp73d64VVHyqOrn0FAHP+K2OoeJdF0mH5iJvtEy+iKRz/ADrrwMDArzLQfEttDqd3rGsW9097cNtjRYWIiT0HHvW6fGOpaiDHoOhXDyZxvuRsUe/WgDotX1e00XT5Lu+kCIo4Hdz6AdzWF4UsLm8vZ/EWrRmO4uhtgibrFF2H40un+FLi7v01LxRci9uF5jgXiKP8O5FdUBgYHAoAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKAOb8f/8AIlX30X+YrZ0n/kC2X/XvH/6CKxvH/wDyJV99F/mK2dJ/5Atl/wBe8f8A6CKALdFFFABRRRQAVkayDeXVppq52yv5kzKeUVfmH4EjFWr3WdN02RY7++gt3boskgUn3qno2L++utWyHST91bSKeGiHOf8AvrdVx097sQ2m+VGz06VkTD7F4mimVcJex+XK5/vL9wfqa16zNfhaTSzNGhkmtHFxEo7svQUQ3t3HLa5p0Vm2XiDSr+ZYLXULeWcjOxJASfXFaVRsNSUldBRRRQMKKKKACiiuW8UeLoNP0mcaPNFeahuWJLeJwz5Y4yAOTjOcUpPlTbNKUHVqRpp6ydlfzL2lf8TDW7zU8K0aD7NbSA9VGN+f+Bg1t1Q0OB7fRbZJYPIk27nTOfmPJP4nmr9TBaGmIknUaWy0XojI0j/QtQvNNJyFbz4gBwkbcBR9CD+da9Y+uH7HcWeqZwlvJslHQbHwCzH0XrVuw1nTdTkdNPvYbhkGWWNwSB6/Stpa+8ciaT5WXaKKKgsKKKKAOS8Yf8h7w5/1+j+ldbXJeMP+Q94c/wCv0f0rraACqmrf8gi6/wCuR/lVuqGtyrDoV5I5wqxMSaAM3wN/yJ1j/u10NYPgmMx+DtP3fxR7hW9QAVyLE3HxWTYMrbWR3Edi3/6q6XUL6DTbCW7unCRRLkk1x/g/UbASX2s6lf2sN1qEu4RPMMxoOg9utAHc0VjXXi7QbSMu+p2747RyBj+QrFn8Rat4jP2bwzZyQQP96/nUqAP9ketAFPx94it5JotDjkfYzhrt4hkqn938avQ/EHQra3jhggvNiKFVVg6frW3oHh610GzZIiZp5Tunnf70jf4e1au1fQflQByL+MNQ1EbPD+iXMpbjzbgbFX371Lp3hS4ub9dS8UXIvbleY4AP3UX0Hf8AKuqxjpRQA3Yn90flTqKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooA57x2hk8GXwH90H8jWro7h9DsWXkfZ0/9BFO1OzGoaXc2hx++iZBnsSOKw/At+ZtDNjOf9JsHMMgPsTg/lQB01FFFABRRRQB5t4x8P6nP4gku4rVruKVQEYEHH+zjt9a7Dwnp1xpXhu2tbwbZVBJjByEyegrZopWSbZy08LTp1pVlvIKq6pbSXulXNtBJ5cksZVX/ALpIq1RTOp6nk2l+FdYbWrRfsZtjBOskshIwoU5IyOufavWaKKSSSsjlw2FhhouMOoUUUUzqCiiigCG8he4spoYpPKeRCquP4Se9eV2nhPWTrECNYmNo51dpWYYADZzkda7218UQ3Ouf2eIJBmWeJZOwMWN2fTO4Y/GrOo69aabJILiRUit7c3NzK3SKIZ+Y4+hpNJ2ucuIwsMQ4ud9DUHAGefeiseHxNY3UqGykFxASivImf3e9N6E57FSOnqK2KZ1GL4t0261bw7Pa2DYmJVgpON4ByV/HpXH+EfDmqQ+I4LuS3NpBb7vMzgbyQRtwOuM5z0r0qilZXuctTCwqVY1Xe6CiiimdQUUUUAcj4vIPiPw3H/EbzI/DFddXHB/7d+IwMfz22kxkFh2lPb9K7GgArlfHN5JJYQ6LZfNd6i4jC+idyfTtWhrviex0SLDt590/EVvFyzGuftfB1/rczavrt7NaXsv3IoDjyV7DPrQB2dlax2FhDbR8RwoFGao6p4l0rSIi13dx7ugjQ7mJ9MCsceAlJ/e61qUi+hmbn9a0dO8H6NpsvnRWglm7yTEuc+vNAGLHY6h42vEuNXha00aJt0dqxw059W9q2f8AhCvDv/QKh/Nv8a3elFAGVa+GNFsnDW2nQIw74z/OtRUVF2ooUDsBilooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigArkNf0+70TWP+Ej0WJpQRtvbZf41/vD6V19HXrQBQ0jWrLXLIXOnyh1I+Zf4lPoRV+uZ1PwZDLdtf6LcyaZfEk74vuMT3K1XEnjey/diCx1BR/wAtN2wn8zQB11Fcl/afjT/oB2v/AH/H+NH9p+NP+gFa/wDf8f40AdbRXJf2n40/6AVr/wB/x/jR/afjT/oBWv8A3/H+NAHW0VyX9p+NP+gFa/8Af8f40f2n40/6AVr/AN/x/jQB1tFcl/afjT/oBWv/AH/H+NH9p+NP+gFa/wDf8f40AdbRXJf2n40/6AVr/wB/x/jR/afjT/oBWv8A3/H+NAHW0HkHHFcl/afjT/oBWv8A3/H+NH9p+NP+gFa/9/x/jQBoz+HkTRby1tADPdO0jS/dJc980HQVTUFYRrLbT2X2K4jY9EGTn3zuIrO/tPxp/wBAK1/7/j/Gj+0/Gn/QCtf+/wCP8aALNr4UTTdLs9IsZJGsopjJJJM+6QjJIUH0GQB6AYrpK5L+0/Gn/QCtf+/4/wAaP7T8af8AQCtf+/4/xoA62iuS/tPxp/0ArX/v+P8AGj+0/Gn/AEArX/v+P8aAOtorkv7T8af9AK1/7/j/ABoOp+NSMLoloD6mcf40AdbXMeIvExik/snQwLrVJvlwvIhHq1Vn0rxZrQC6nfw6dAeHitRksPTOTW5ovh7T9BhKWUWZG+/M5y7/AFNAHMaT4d8V6NbPFZXlmDIxeR3j3MxPqautoXim/G2+18Wy9xbRYJ/HNddRQBiaN4T03RpTcRI0903LXEx3Nn2PatuiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKAP/Z"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![stacked.JPG](attachment:stacked.JPG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "J implementamos os modelos de GNN e RNN para prever o GDP per capita dos pases. Vamos agora analisar como esses dois modelos se comportam em conjunto.\n",
    "\n",
    "Para isso vamos utilizar um Stacked Model. O objetivo  usar as sadas dos dois modelos desenvolvidos como a entrada de um modelo novo, no caso um random forest.\n",
    "\n",
    "Para isso, vamos estabelecer o ano de previso do RNN como 2016, que corresponde ao ano dos dados do dataset com informaes dos pases utilizado no GNN. Tambm teremos que igualar a escala da varivel dependente. No caso, utilizaremos ela como o log do GDP per capita (sem ser normalizada)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No GPU was detected. LSTMs and CNNs can be very slow without a GPU.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "import plotly.express as px\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "from matplotlib.colors import ListedColormap\n",
    "import folium\n",
    "from folium.plugins import MarkerCluster,HeatMap,HeatMapWithTime\n",
    "import branca.colormap as colormap\n",
    "from collections import defaultdict\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, f1_score, confusion_matrix, classification_report\n",
    "\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "\n",
    "import sys\n",
    "assert sys.version_info >= (3, 5)\n",
    "import sklearn\n",
    "assert sklearn.__version__ >= \"0.20\"\n",
    "\n",
    "try:\n",
    "    # %tensorflow_version only exists in Colab.\n",
    "    %tensorflow_version 2.x\n",
    "    IS_COLAB = True\n",
    "except Exception:\n",
    "    IS_COLAB = False\n",
    "\n",
    "from tensorflow import keras\n",
    "assert tf.__version__ >= \"2.0\"\n",
    "\n",
    "if not tf.config.list_physical_devices('GPU'):\n",
    "    print(\"No GPU was detected. LSTMs and CNNs can be very slow without a GPU.\")\n",
    "    if IS_COLAB:\n",
    "        print(\"Go to Runtime > Change runtime and select a GPU hardware accelerator.\")\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_file_path = \"../GNN/nodes_and_links_countries.json\"\n",
    "\n",
    "with open(json_file_path, 'r') as j:\n",
    "     jdict = json.loads(j.read())\n",
    "     \n",
    "path = \"../GNN/countries of the world.csv\"\n",
    "df_gdp = pd.read_csv(path,decimal=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:4163: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().drop(\n"
     ]
    }
   ],
   "source": [
    "df_gdp['Country'] = df_gdp['Country'].map(lambda x: str(x)[:-1])\n",
    "\n",
    "correspondence = {\n",
    "   'Micronesia, Fed. St.':'Federated States of Micronesia',\n",
    "   'Antigua & Barbuda':'Antigua and Barbuda',\n",
    "   'Bahamas, The':'Bahamas',\n",
    "   'Saint Kitts & Nevis': 'Saint Kitts and Nevis',\n",
    "   'Trinidad & Tobago':'Trinidad and Tobago',\n",
    "   'Central African Rep.': 'Central African Republic',\n",
    "   'Congo, Dem. Rep.':'Democratic Republic of the Congo',\n",
    "   'Congo, Repub. of the':'Republic of the Congo',\n",
    "   \"Cote d'Ivoire\": \"Cte d'Ivoire\",\n",
    "   'Gambia, The': 'The Gambia',\n",
    "   'Sao Tome & Principe':'So Tom and Prncipe',\n",
    "   'Bosnia & Herzegovina': 'Bosnia and Herzegovina',\n",
    "   'Macedonia':'North Macedonia',\n",
    "   'China': \"People's Republic of China\",\n",
    "   'Korea, North':'North Korea',\n",
    "   'Korea, South':'South Korea',\n",
    "   'Burma':'Myanmar'\n",
    "    }\n",
    "\n",
    "df_gdp = df_gdp.replace({\"Country\": correspondence})\n",
    "\n",
    "countries_df = df_gdp['Country'].values\n",
    "countries_nodes = ([node['name'] for node in jdict['nodes']])\n",
    "\n",
    "mismatch = [i for i in countries_nodes if i not in countries_df]\n",
    "nodes = set(countries_nodes)-set(mismatch)\n",
    "nodes_df = [i for i in nodes]\n",
    "\n",
    "df = df_gdp[df_gdp['Country'].isin(nodes_df)]\n",
    "\n",
    "df.drop(['Region'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered = df.copy()\n",
    "df_filtered['Infant mortality (per 1000 births)'] = df['Infant mortality (per 1000 births)'].apply(np.log10)\n",
    "df_filtered['GDP ($ per capita)'] = df['GDP ($ per capita)'].apply(np.log10)\n",
    "df_filtered['Phones (per 1000)'] = df['Phones (per 1000)'].apply(np.log10)\n",
    "df_filtered['Pop. Density (per sq. mi.)'] = df['Pop. Density (per sq. mi.)'].apply(np.log10)\n",
    "df_filtered['Other (%)'] = df['Other (%)'].apply(np.sqrt)\n",
    "df_filtered['Literacy (%)'] = df['Literacy (%)'].apply(np.sqrt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = df_filtered.copy()\n",
    "\n",
    "class_values = sorted(df_test[\"Country\"].unique())\n",
    "class_idx = {name: id for id, name in enumerate(class_values)}\n",
    "\n",
    "df_test[\"Country ID\"] = df_test[\"Country\"].apply(lambda name: class_idx[name])\n",
    "\n",
    "df_test=df_test.dropna()\n",
    "\n",
    "df_test['GDP'] =df_test['GDP ($ per capita)']\n",
    "\n",
    "df_test.drop(['GDP ($ per capita)'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "existing_countries = df_test.Country.to_list()\n",
    "\n",
    "edges = []\n",
    "for n in jdict['links']:\n",
    "    if (n['source'] in existing_countries) and (n['target'] in existing_countries):\n",
    "        edges.append((n['source'], n['target']))\n",
    "        \n",
    "df_edges= pd.DataFrame.from_records(edges, columns =['source', 'target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_values = sorted(df_test[\"Country\"].unique())\n",
    "class_idx = {name: id for id, name in enumerate(class_values)}\n",
    "\n",
    "df_test[\"Country ID\"] = df_test[\"Country\"].apply(lambda name: class_idx[name])\n",
    "\n",
    "df_edges[\"source\"] = df_edges[\"source\"].apply(lambda name: class_idx[name])\n",
    "df_edges[\"target\"] = df_edges[\"target\"].apply(lambda name: class_idx[name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = set(df_test.columns) - {\"Country\", \"GDP\", 'Country ID'}\n",
    "num_features = len(feature_names)\n",
    "num_classes = num_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = [], []\n",
    "\n",
    "for _, group_data in df_test.groupby(\"GDP\"):\n",
    "    random_selection = np.random.rand(len(group_data.index)) <= 0.7\n",
    "    train_data.append(group_data[random_selection])\n",
    "    test_data.append(group_data[~random_selection])\n",
    "\n",
    "train_data = pd.concat(train_data).sample(frac=1)\n",
    "test_data = pd.concat(test_data).sample(frac=1)\n",
    "\n",
    "x_train = train_data[feature_names].to_numpy()\n",
    "x_test = test_data[feature_names].to_numpy()\n",
    "\n",
    "y_train = train_data[\"GDP\"]\n",
    "y_test = test_data[\"GDP\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "DROPOUT_RATE  =0.2\n",
    "\n",
    "def create_ffn(hidden_units, dropout_rate, name=None):\n",
    "    fnn_layers = []\n",
    "\n",
    "    for units in hidden_units:\n",
    "        fnn_layers.append(layers.BatchNormalization())\n",
    "        fnn_layers.append(layers.Dropout(dropout_rate))\n",
    "        fnn_layers.append(layers.Dense(units, activation=tf.nn.gelu))\n",
    "\n",
    "    return keras.Sequential(fnn_layers, name=name)\n",
    "\n",
    "def run_experiment(model, x_train, y_train):\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(1e-1),\n",
    "        loss='mse',\n",
    "    )\n",
    "    early_stopping = keras.callbacks.EarlyStopping(\n",
    "        monitor=\"loss\", patience=50, restore_best_weights=True\n",
    "    )\n",
    "\n",
    "    history = model.fit(\n",
    "        x=x_train,\n",
    "        y=y_train,\n",
    "        epochs=5000,\n",
    "        batch_size=2048,\n",
    "        validation_split=0.2,\n",
    "        callbacks=[early_stopping],\n",
    "\n",
    "    )\n",
    "\n",
    "    return history\n",
    "\n",
    "class GraphConvLayer(layers.Layer):\n",
    "    def __init__(\n",
    "        self,\n",
    "        hidden_units,\n",
    "        dropout_rate=DROPOUT_RATE,\n",
    "        aggregation_type=\"mean\",\n",
    "        combination_type=\"concat\",\n",
    "        normalize=False,\n",
    "        *args,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        super(GraphConvLayer, self).__init__(*args, **kwargs)\n",
    "        self.normalize = normalize\n",
    "\n",
    "        self.ffn_prepare = create_ffn(hidden_units, dropout_rate)\n",
    "        self.update_fn = create_ffn(hidden_units, dropout_rate)\n",
    "\n",
    "    def prepare(self, node_repesentations, weights=None):\n",
    "        messages = self.ffn_prepare(node_repesentations)\n",
    "        return messages\n",
    "\n",
    "    def aggregate(self, node_indices, neighbour_messages, node_repesentations):\n",
    "        num_nodes = node_repesentations.shape[0]\n",
    "        aggregated_message = tf.math.unsorted_segment_mean(\n",
    "            neighbour_messages, node_indices, num_segments=num_nodes\n",
    "        )\n",
    "        return aggregated_message\n",
    "\n",
    "    def update(self, node_repesentations, aggregated_messages):\n",
    "        h = tf.concat([node_repesentations, aggregated_messages], axis=1)\n",
    "        node_embeddings = self.update_fn(h)\n",
    "        if self.normalize:\n",
    "            node_embeddings = tf.nn.l2_normalize(node_embeddings, axis=-1)\n",
    "        return node_embeddings\n",
    "\n",
    "    def call(self, inputs):\n",
    "        node_repesentations, edges, edge_weights = inputs\n",
    "        node_indices, neighbour_indices = edges[0], edges[1]\n",
    "        neighbour_repesentations = tf.gather(node_repesentations, neighbour_indices)\n",
    "\n",
    "        neighbour_messages = self.prepare(neighbour_repesentations, edge_weights)\n",
    "        aggregated_messages = self.aggregate(\n",
    "            node_indices, neighbour_messages, node_repesentations\n",
    "        )\n",
    "        return self.update(node_repesentations, aggregated_messages)\n",
    "\n",
    "class GNNNodeClassifier(tf.keras.Model):\n",
    "    def __init__(\n",
    "        self,\n",
    "        graph_info,\n",
    "        num_classes,\n",
    "        hidden_units,\n",
    "        aggregation_type=\"sum\",\n",
    "        combination_type=\"concat\",\n",
    "        dropout_rate=DROPOUT_RATE,\n",
    "        normalize=True,\n",
    "        *args,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        super(GNNNodeClassifier, self).__init__(*args, **kwargs)\n",
    "\n",
    "        # Unpack graph_info to three elements: node_features, edges, and edge_weight.\n",
    "        node_features, edges, edge_weights = graph_info\n",
    "        self.node_features = node_features\n",
    "        self.edges = edges\n",
    "        self.edge_weights = edge_weights\n",
    "        # Set edge_weights to ones if not provided.\n",
    "        if self.edge_weights is None:\n",
    "            self.edge_weights = tf.ones(shape=edges.shape[1])\n",
    "        # Scale edge_weights to sum to 1.\n",
    "        self.edge_weights = self.edge_weights / tf.math.reduce_sum(self.edge_weights)\n",
    "\n",
    "        # Create a process layer.\n",
    "        self.preprocess = create_ffn(hidden_units, dropout_rate, name=\"preprocess\")\n",
    "        # Create the first GraphConv layer.\n",
    "        self.conv1 = GraphConvLayer(\n",
    "            hidden_units,\n",
    "            dropout_rate,\n",
    "            aggregation_type,\n",
    "            combination_type,\n",
    "            normalize,\n",
    "            name=\"graph_conv1\",\n",
    "        )\n",
    "        # Create the second GraphConv layer.\n",
    "        self.conv2 = GraphConvLayer(\n",
    "            hidden_units,\n",
    "            dropout_rate,\n",
    "            aggregation_type,\n",
    "            combination_type,\n",
    "            normalize,\n",
    "            name=\"graph_conv2\",\n",
    "        )\n",
    "        self.postprocess = create_ffn(hidden_units, dropout_rate, name=\"postprocess\")\n",
    "        self.compute_logits = layers.Dense(units=num_classes, name=\"logits\")\n",
    "\n",
    "    def call(self, input_node_indices):\n",
    "        x = self.preprocess(self.node_features)\n",
    "        x1 = self.conv1((x, self.edges, self.edge_weights))\n",
    "        x = x1 + x\n",
    "        x2 = self.conv2((x, self.edges, self.edge_weights))\n",
    "        x = x2 + x\n",
    "        x = self.postprocess(x)\n",
    "        node_embeddings = tf.gather(x, input_node_indices)\n",
    "        return self.compute_logits(node_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges = df_edges[[\"source\", \"target\"]].to_numpy().T\n",
    "edge_weights = tf.ones(shape=edges.shape[1])\n",
    "node_features = tf.cast(\n",
    "    df_test.sort_values(\"Country\")[feature_names].to_numpy(), dtype=tf.dtypes.float32\n",
    ")\n",
    "\n",
    "graph_info = (node_features, edges, edge_weights)\n",
    "\n",
    "gnn_model = GNNNodeClassifier(\n",
    "    graph_info=graph_info,\n",
    "    num_classes=num_classes,\n",
    "    hidden_units=[32, 32],\n",
    "    dropout_rate=DROPOUT_RATE,\n",
    "    name=\"gnn_model\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 17), dtype=float32, numpy=\n",
       "array([[ -90456.2   ,   15367.982 ,  140381.8   , -126503.61  ,\n",
       "         106124.484 ,   69924.34  ,  -69583.05  ,    5329.203 ,\n",
       "          23764.354 ,  -13083.637 , -136545.12  ,   12489.5625,\n",
       "        -167950.62  ,   78974.3   ,   19807.303 ,  196468.77  ,\n",
       "         155562.25  ],\n",
       "       [ -17929.793 ,    3019.1973,   27553.332 ,  -24822.809 ,\n",
       "          20719.135 ,   13609.305 ,  -13543.74  ,     876.0449,\n",
       "           4510.4507,   -2167.1455,  -26685.521 ,    2622.293 ,\n",
       "         -33213.055 ,   15798.305 ,    4161.3667,   38516.03  ,\n",
       "          30230.484 ]], dtype=float32)>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gnn_model([1,10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5000\n",
      "1/1 [==============================] - 3s 3s/step - loss: 14.1857 - val_loss: 18.1799\n",
      "Epoch 2/5000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 6.5012 - val_loss: 70.4363\n",
      "Epoch 3/5000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 7.7245 - val_loss: 151.7231\n",
      "Epoch 4/5000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 3.4731 - val_loss: 61.1736\n",
      "Epoch 5/5000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.8827 - val_loss: 120.5348\n",
      "Epoch 6/5000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 2.9608 - val_loss: 294.6615\n",
      "Epoch 7/5000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 2.1106 - val_loss: 557.9899\n",
      "Epoch 8/5000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.6084 - val_loss: 760.2928\n",
      "Epoch 9/5000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.0169 - val_loss: 1213.1632\n",
      "Epoch 10/5000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.9230 - val_loss: 1703.3528\n",
      "Epoch 11/5000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.1078 - val_loss: 2244.8015\n",
      "Epoch 12/5000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.9658 - val_loss: 2335.3313\n",
      "Epoch 13/5000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.0112 - val_loss: 1952.6606\n",
      "Epoch 14/5000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.0521 - val_loss: 1525.7764\n",
      "Epoch 15/5000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.6154 - val_loss: 1201.5817\n",
      "Epoch 16/5000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.4253 - val_loss: 961.8060\n",
      "Epoch 17/5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5952 - val_loss: 731.5282\n",
      "Epoch 18/5000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.7341 - val_loss: 542.1866\n",
      "Epoch 19/5000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.5210 - val_loss: 395.2531\n",
      "Epoch 20/5000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.4869 - val_loss: 306.8028\n",
      "Epoch 21/5000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.3877 - val_loss: 255.2444\n",
      "Epoch 22/5000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.3708 - val_loss: 217.0111\n",
      "Epoch 23/5000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.4236 - val_loss: 196.8632\n",
      "Epoch 24/5000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.3265 - val_loss: 160.5807\n",
      "Epoch 25/5000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.3263 - val_loss: 125.4504\n",
      "Epoch 26/5000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.3016 - val_loss: 101.0714\n",
      "Epoch 27/5000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.4110 - val_loss: 84.1052\n",
      "Epoch 28/5000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.2419 - val_loss: 75.6711\n",
      "Epoch 29/5000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.2211 - val_loss: 64.5917\n",
      "Epoch 30/5000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.2523 - val_loss: 50.4316\n",
      "Epoch 31/5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.2166 - val_loss: 36.3836\n",
      "Epoch 32/5000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.2544 - val_loss: 28.1607\n",
      "Epoch 33/5000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.2380 - val_loss: 21.4940\n",
      "Epoch 34/5000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.2091 - val_loss: 17.0826\n",
      "Epoch 35/5000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1549 - val_loss: 15.1054\n",
      "Epoch 36/5000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.2036 - val_loss: 12.7885\n",
      "Epoch 37/5000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.1654 - val_loss: 10.2508\n",
      "Epoch 38/5000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.1816 - val_loss: 8.0545\n",
      "Epoch 39/5000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.1454 - val_loss: 6.5783\n",
      "Epoch 40/5000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.2114 - val_loss: 5.5067\n",
      "Epoch 41/5000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.1527 - val_loss: 4.9057\n",
      "Epoch 42/5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1333 - val_loss: 4.3636\n",
      "Epoch 43/5000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.1549 - val_loss: 3.5875\n",
      "Epoch 44/5000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.1532 - val_loss: 3.0067\n",
      "Epoch 45/5000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.1368 - val_loss: 2.5983\n",
      "Epoch 46/5000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.1540 - val_loss: 2.3313\n",
      "Epoch 47/5000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.1126 - val_loss: 2.0945\n",
      "Epoch 48/5000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.1208 - val_loss: 1.8820\n",
      "Epoch 49/5000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.1402 - val_loss: 1.7262\n",
      "Epoch 50/5000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.1421 - val_loss: 1.6197\n",
      "Epoch 51/5000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.1213 - val_loss: 1.4994\n",
      "Epoch 52/5000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.1240 - val_loss: 1.3564\n",
      "Epoch 53/5000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.1071 - val_loss: 1.1979\n",
      "Epoch 54/5000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.1117 - val_loss: 1.0774\n",
      "Epoch 55/5000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.1233 - val_loss: 1.0128\n",
      "Epoch 56/5000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0886 - val_loss: 0.9725\n",
      "Epoch 57/5000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.1000 - val_loss: 0.9416\n",
      "Epoch 58/5000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.1480 - val_loss: 0.8925\n",
      "Epoch 59/5000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.1234 - val_loss: 0.8244\n",
      "Epoch 60/5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0742 - val_loss: 0.7734\n",
      "Epoch 61/5000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.1037 - val_loss: 0.7300\n",
      "Epoch 62/5000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0967 - val_loss: 0.6940\n",
      "Epoch 63/5000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.1022 - val_loss: 0.6672\n",
      "Epoch 64/5000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0941 - val_loss: 0.6373\n",
      "Epoch 65/5000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.1014 - val_loss: 0.5864\n",
      "Epoch 66/5000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1056 - val_loss: 0.5629\n",
      "Epoch 67/5000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0896 - val_loss: 0.5829\n",
      "Epoch 68/5000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.1006 - val_loss: 0.6094\n",
      "Epoch 69/5000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0905 - val_loss: 0.6404\n",
      "Epoch 70/5000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0858 - val_loss: 0.6297\n",
      "Epoch 71/5000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0908 - val_loss: 0.5856\n",
      "Epoch 72/5000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0747 - val_loss: 0.5369\n",
      "Epoch 73/5000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.1014 - val_loss: 0.5069\n",
      "Epoch 74/5000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0784 - val_loss: 0.4972\n",
      "Epoch 75/5000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0795 - val_loss: 0.5054\n",
      "Epoch 76/5000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0896 - val_loss: 0.4955\n",
      "Epoch 77/5000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0542 - val_loss: 0.4484\n",
      "Epoch 78/5000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0807 - val_loss: 0.3879\n",
      "Epoch 79/5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1014 - val_loss: 0.3345\n",
      "Epoch 80/5000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0718 - val_loss: 0.3172\n",
      "Epoch 81/5000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0711 - val_loss: 0.3202\n",
      "Epoch 82/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 29ms/step - loss: 0.1043 - val_loss: 0.3204\n",
      "Epoch 83/5000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0748 - val_loss: 0.2940\n",
      "Epoch 84/5000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0700 - val_loss: 0.2415\n",
      "Epoch 85/5000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0700 - val_loss: 0.2115\n",
      "Epoch 86/5000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0624 - val_loss: 0.1914\n",
      "Epoch 87/5000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0873 - val_loss: 0.1914\n",
      "Epoch 88/5000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0723 - val_loss: 0.2065\n",
      "Epoch 89/5000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0650 - val_loss: 0.2244\n",
      "Epoch 90/5000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0625 - val_loss: 0.2225\n",
      "Epoch 91/5000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0860 - val_loss: 0.1973\n",
      "Epoch 92/5000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0648 - val_loss: 0.1887\n",
      "Epoch 93/5000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0788 - val_loss: 0.2022\n",
      "Epoch 94/5000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0868 - val_loss: 0.2193\n",
      "Epoch 95/5000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0795 - val_loss: 0.2293\n",
      "Epoch 96/5000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0517 - val_loss: 0.2166\n",
      "Epoch 97/5000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0729 - val_loss: 0.1834\n",
      "Epoch 98/5000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0633 - val_loss: 0.1575\n",
      "Epoch 99/5000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0712 - val_loss: 0.1457\n",
      "Epoch 100/5000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0618 - val_loss: 0.1521\n",
      "Epoch 101/5000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0584 - val_loss: 0.1707\n",
      "Epoch 102/5000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0595 - val_loss: 0.1952\n",
      "Epoch 103/5000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0683 - val_loss: 0.1904\n",
      "Epoch 104/5000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0663 - val_loss: 0.1674\n",
      "Epoch 105/5000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0640 - val_loss: 0.1436\n",
      "Epoch 106/5000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0623 - val_loss: 0.1209\n",
      "Epoch 107/5000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0611 - val_loss: 0.1130\n",
      "Epoch 108/5000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0698 - val_loss: 0.1350\n",
      "Epoch 109/5000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0805 - val_loss: 0.1447\n",
      "Epoch 110/5000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0658 - val_loss: 0.1237\n",
      "Epoch 111/5000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0463 - val_loss: 0.1076\n",
      "Epoch 112/5000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0655 - val_loss: 0.1077\n",
      "Epoch 113/5000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0669 - val_loss: 0.1157\n",
      "Epoch 114/5000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0525 - val_loss: 0.1408\n",
      "Epoch 115/5000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0624 - val_loss: 0.1532\n",
      "Epoch 116/5000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0704 - val_loss: 0.1359\n",
      "Epoch 117/5000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0595 - val_loss: 0.1201\n",
      "Epoch 118/5000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0469 - val_loss: 0.1078\n",
      "Epoch 119/5000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0553 - val_loss: 0.1168\n",
      "Epoch 120/5000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0550 - val_loss: 0.1235\n",
      "Epoch 121/5000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0543 - val_loss: 0.1254\n",
      "Epoch 122/5000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0610 - val_loss: 0.1070\n",
      "Epoch 123/5000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0488 - val_loss: 0.0845\n",
      "Epoch 124/5000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0559 - val_loss: 0.0756\n",
      "Epoch 125/5000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0550 - val_loss: 0.0859\n",
      "Epoch 126/5000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0699 - val_loss: 0.0973\n",
      "Epoch 127/5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0396 - val_loss: 0.1025\n",
      "Epoch 128/5000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0552 - val_loss: 0.0919\n",
      "Epoch 129/5000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0528 - val_loss: 0.0800\n",
      "Epoch 130/5000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0715 - val_loss: 0.0863\n",
      "Epoch 131/5000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0528 - val_loss: 0.1101\n",
      "Epoch 132/5000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0486 - val_loss: 0.1240\n",
      "Epoch 133/5000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0541 - val_loss: 0.1181\n",
      "Epoch 134/5000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0512 - val_loss: 0.0966\n",
      "Epoch 135/5000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0738 - val_loss: 0.0826\n",
      "Epoch 136/5000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0629 - val_loss: 0.0893\n",
      "Epoch 137/5000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0437 - val_loss: 0.1080\n",
      "Epoch 138/5000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0712 - val_loss: 0.1069\n",
      "Epoch 139/5000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0612 - val_loss: 0.0813\n",
      "Epoch 140/5000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0450 - val_loss: 0.0660\n",
      "Epoch 141/5000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0498 - val_loss: 0.0664\n",
      "Epoch 142/5000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0525 - val_loss: 0.0821\n",
      "Epoch 143/5000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0589 - val_loss: 0.0958\n",
      "Epoch 144/5000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0543 - val_loss: 0.0928\n",
      "Epoch 145/5000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0537 - val_loss: 0.0897\n",
      "Epoch 146/5000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0456 - val_loss: 0.0869\n",
      "Epoch 147/5000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0609 - val_loss: 0.0780\n",
      "Epoch 148/5000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0590 - val_loss: 0.0752\n",
      "Epoch 149/5000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0517 - val_loss: 0.0698\n",
      "Epoch 150/5000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0508 - val_loss: 0.0656\n",
      "Epoch 151/5000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0466 - val_loss: 0.0703\n",
      "Epoch 152/5000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0601 - val_loss: 0.0693\n",
      "Epoch 153/5000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0460 - val_loss: 0.0746\n",
      "Epoch 154/5000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0563 - val_loss: 0.0724\n",
      "Epoch 155/5000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0411 - val_loss: 0.0753\n",
      "Epoch 156/5000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0412 - val_loss: 0.0683\n",
      "Epoch 157/5000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0509 - val_loss: 0.0645\n",
      "Epoch 158/5000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0475 - val_loss: 0.0699\n",
      "Epoch 159/5000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0461 - val_loss: 0.0782\n",
      "Epoch 160/5000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0531 - val_loss: 0.0795\n",
      "Epoch 161/5000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0563 - val_loss: 0.0697\n",
      "Epoch 162/5000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0478 - val_loss: 0.0601\n",
      "Epoch 163/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0540 - val_loss: 0.0608\n",
      "Epoch 164/5000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0477 - val_loss: 0.0671\n",
      "Epoch 165/5000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0525 - val_loss: 0.0796\n",
      "Epoch 166/5000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0558 - val_loss: 0.0744\n",
      "Epoch 167/5000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0496 - val_loss: 0.0604\n",
      "Epoch 168/5000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0505 - val_loss: 0.0581\n",
      "Epoch 169/5000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0463 - val_loss: 0.0826\n",
      "Epoch 170/5000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0525 - val_loss: 0.0877\n",
      "Epoch 171/5000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0470 - val_loss: 0.0618\n",
      "Epoch 172/5000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0581 - val_loss: 0.0523\n",
      "Epoch 173/5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0513 - val_loss: 0.0554\n",
      "Epoch 174/5000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0556 - val_loss: 0.0700\n",
      "Epoch 175/5000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0455 - val_loss: 0.0698\n",
      "Epoch 176/5000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0531 - val_loss: 0.0656\n",
      "Epoch 177/5000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0466 - val_loss: 0.0580\n"
     ]
    }
   ],
   "source": [
    "x_train = train_data['Country ID'].to_numpy()\n",
    "history = run_experiment(gnn_model, x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.31455360607926486 0.41181890366149565\n"
     ]
    }
   ],
   "source": [
    "x_test = test_data['Country ID'].to_numpy()\n",
    "\n",
    "mse_train = gnn_model.evaluate(x=x_train, y=y_train, verbose=0)\n",
    "mse_test = gnn_model.evaluate(x=x_test, y=y_test, verbose=0)\n",
    "\n",
    "print(np.sqrt(mse_train), np.sqrt(mse_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country</th>\n",
       "      <th>Population</th>\n",
       "      <th>Area (sq. mi.)</th>\n",
       "      <th>Pop. Density (per sq. mi.)</th>\n",
       "      <th>Coastline (coast/area ratio)</th>\n",
       "      <th>Net migration</th>\n",
       "      <th>Infant mortality (per 1000 births)</th>\n",
       "      <th>Literacy (%)</th>\n",
       "      <th>Phones (per 1000)</th>\n",
       "      <th>Arable (%)</th>\n",
       "      <th>Crops (%)</th>\n",
       "      <th>Other (%)</th>\n",
       "      <th>Climate</th>\n",
       "      <th>Birthrate</th>\n",
       "      <th>Deathrate</th>\n",
       "      <th>Agriculture</th>\n",
       "      <th>Industry</th>\n",
       "      <th>Service</th>\n",
       "      <th>Country ID</th>\n",
       "      <th>GDP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>Guinea</td>\n",
       "      <td>9690222</td>\n",
       "      <td>245857</td>\n",
       "      <td>1.595496</td>\n",
       "      <td>0.13</td>\n",
       "      <td>-3.06</td>\n",
       "      <td>1.956024</td>\n",
       "      <td>5.991661</td>\n",
       "      <td>0.431364</td>\n",
       "      <td>3.63</td>\n",
       "      <td>2.58</td>\n",
       "      <td>9.684524</td>\n",
       "      <td>2.0</td>\n",
       "      <td>41.76</td>\n",
       "      <td>15.48</td>\n",
       "      <td>0.237</td>\n",
       "      <td>0.362</td>\n",
       "      <td>0.401</td>\n",
       "      <td>60</td>\n",
       "      <td>3.322219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Brunei</td>\n",
       "      <td>379444</td>\n",
       "      <td>5770</td>\n",
       "      <td>1.818226</td>\n",
       "      <td>2.79</td>\n",
       "      <td>3.59</td>\n",
       "      <td>1.100715</td>\n",
       "      <td>9.690201</td>\n",
       "      <td>2.375115</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.76</td>\n",
       "      <td>9.933277</td>\n",
       "      <td>2.0</td>\n",
       "      <td>18.79</td>\n",
       "      <td>3.45</td>\n",
       "      <td>0.036</td>\n",
       "      <td>0.561</td>\n",
       "      <td>0.403</td>\n",
       "      <td>21</td>\n",
       "      <td>4.269513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>Greece</td>\n",
       "      <td>10688058</td>\n",
       "      <td>131940</td>\n",
       "      <td>1.908485</td>\n",
       "      <td>10.37</td>\n",
       "      <td>2.35</td>\n",
       "      <td>0.742725</td>\n",
       "      <td>9.874209</td>\n",
       "      <td>2.770631</td>\n",
       "      <td>21.10</td>\n",
       "      <td>8.78</td>\n",
       "      <td>8.373769</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.68</td>\n",
       "      <td>10.24</td>\n",
       "      <td>0.054</td>\n",
       "      <td>0.213</td>\n",
       "      <td>0.733</td>\n",
       "      <td>57</td>\n",
       "      <td>4.301030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>Palau</td>\n",
       "      <td>20579</td>\n",
       "      <td>458</td>\n",
       "      <td>1.652246</td>\n",
       "      <td>331.66</td>\n",
       "      <td>2.85</td>\n",
       "      <td>1.171434</td>\n",
       "      <td>9.591663</td>\n",
       "      <td>2.512684</td>\n",
       "      <td>8.70</td>\n",
       "      <td>4.35</td>\n",
       "      <td>9.324698</td>\n",
       "      <td>2.0</td>\n",
       "      <td>18.03</td>\n",
       "      <td>6.80</td>\n",
       "      <td>0.062</td>\n",
       "      <td>0.120</td>\n",
       "      <td>0.818</td>\n",
       "      <td>107</td>\n",
       "      <td>3.954243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>Ethiopia</td>\n",
       "      <td>74777981</td>\n",
       "      <td>1127127</td>\n",
       "      <td>1.821514</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.979184</td>\n",
       "      <td>6.534524</td>\n",
       "      <td>0.913814</td>\n",
       "      <td>10.71</td>\n",
       "      <td>0.75</td>\n",
       "      <td>9.409570</td>\n",
       "      <td>2.0</td>\n",
       "      <td>37.98</td>\n",
       "      <td>14.86</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.099</td>\n",
       "      <td>0.426</td>\n",
       "      <td>48</td>\n",
       "      <td>2.845098</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Country  Population  Area (sq. mi.)  Pop. Density (per sq. mi.)  \\\n",
       "86     Guinea     9690222          245857                    1.595496   \n",
       "29     Brunei      379444            5770                    1.818226   \n",
       "79     Greece    10688058          131940                    1.908485   \n",
       "157     Palau       20579             458                    1.652246   \n",
       "65   Ethiopia    74777981         1127127                    1.821514   \n",
       "\n",
       "     Coastline (coast/area ratio)  Net migration  \\\n",
       "86                           0.13          -3.06   \n",
       "29                           2.79           3.59   \n",
       "79                          10.37           2.35   \n",
       "157                        331.66           2.85   \n",
       "65                           0.00           0.00   \n",
       "\n",
       "     Infant mortality (per 1000 births)  Literacy (%)  Phones (per 1000)  \\\n",
       "86                             1.956024      5.991661           0.431364   \n",
       "29                             1.100715      9.690201           2.375115   \n",
       "79                             0.742725      9.874209           2.770631   \n",
       "157                            1.171434      9.591663           2.512684   \n",
       "65                             1.979184      6.534524           0.913814   \n",
       "\n",
       "     Arable (%)  Crops (%)  Other (%)  Climate  Birthrate  Deathrate  \\\n",
       "86         3.63       2.58   9.684524      2.0      41.76      15.48   \n",
       "29         0.57       0.76   9.933277      2.0      18.79       3.45   \n",
       "79        21.10       8.78   8.373769      3.0       9.68      10.24   \n",
       "157        8.70       4.35   9.324698      2.0      18.03       6.80   \n",
       "65        10.71       0.75   9.409570      2.0      37.98      14.86   \n",
       "\n",
       "     Agriculture  Industry  Service  Country ID       GDP  \n",
       "86         0.237     0.362    0.401          60  3.322219  \n",
       "29         0.036     0.561    0.403          21  4.269513  \n",
       "79         0.054     0.213    0.733          57  4.301030  \n",
       "157        0.062     0.120    0.818         107  3.954243  \n",
       "65         0.475     0.099    0.426          48  2.845098  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Criando um dataframe com as previses do modelo GNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country ID</th>\n",
       "      <th>GDP Prediction</th>\n",
       "      <th>Real GDP</th>\n",
       "      <th>Country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>60</td>\n",
       "      <td>2.990985</td>\n",
       "      <td>3.322219</td>\n",
       "      <td>Guinea</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21</td>\n",
       "      <td>3.960366</td>\n",
       "      <td>4.269513</td>\n",
       "      <td>Brunei</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>57</td>\n",
       "      <td>4.127713</td>\n",
       "      <td>4.301030</td>\n",
       "      <td>Greece</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>107</td>\n",
       "      <td>4.083888</td>\n",
       "      <td>3.954243</td>\n",
       "      <td>Palau</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>48</td>\n",
       "      <td>2.988960</td>\n",
       "      <td>2.845098</td>\n",
       "      <td>Ethiopia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>85</td>\n",
       "      <td>2.988428</td>\n",
       "      <td>2.903090</td>\n",
       "      <td>Madagascar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>145</td>\n",
       "      <td>3.519759</td>\n",
       "      <td>3.342423</td>\n",
       "      <td>Tonga</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>139</td>\n",
       "      <td>3.177833</td>\n",
       "      <td>3.518514</td>\n",
       "      <td>Syria</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>121</td>\n",
       "      <td>3.436107</td>\n",
       "      <td>3.732394</td>\n",
       "      <td>Saint Lucia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>49</td>\n",
       "      <td>3.707042</td>\n",
       "      <td>3.301030</td>\n",
       "      <td>Federated States of Micronesia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>8</td>\n",
       "      <td>3.105657</td>\n",
       "      <td>3.531479</td>\n",
       "      <td>Azerbaijan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>140</td>\n",
       "      <td>3.050080</td>\n",
       "      <td>3.079181</td>\n",
       "      <td>So Tom and Prncipe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>7</td>\n",
       "      <td>4.173307</td>\n",
       "      <td>4.477121</td>\n",
       "      <td>Austria</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>26</td>\n",
       "      <td>2.995289</td>\n",
       "      <td>3.255273</td>\n",
       "      <td>Cameroon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>144</td>\n",
       "      <td>2.988581</td>\n",
       "      <td>3.176091</td>\n",
       "      <td>Togo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>129</td>\n",
       "      <td>2.989638</td>\n",
       "      <td>2.698970</td>\n",
       "      <td>Somalia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>58</td>\n",
       "      <td>3.221403</td>\n",
       "      <td>3.698970</td>\n",
       "      <td>Grenada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>34</td>\n",
       "      <td>3.671046</td>\n",
       "      <td>3.462398</td>\n",
       "      <td>Cuba</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>130</td>\n",
       "      <td>3.129686</td>\n",
       "      <td>4.029384</td>\n",
       "      <td>South Africa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>81</td>\n",
       "      <td>3.846741</td>\n",
       "      <td>4.008600</td>\n",
       "      <td>Latvia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>24</td>\n",
       "      <td>2.955323</td>\n",
       "      <td>2.778151</td>\n",
       "      <td>Burundi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>123</td>\n",
       "      <td>3.200670</td>\n",
       "      <td>3.748188</td>\n",
       "      <td>Samoa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>56</td>\n",
       "      <td>3.025095</td>\n",
       "      <td>3.342423</td>\n",
       "      <td>Ghana</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>19</td>\n",
       "      <td>3.070642</td>\n",
       "      <td>3.954243</td>\n",
       "      <td>Botswana</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>72</td>\n",
       "      <td>3.962923</td>\n",
       "      <td>4.296665</td>\n",
       "      <td>Israel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>106</td>\n",
       "      <td>3.054095</td>\n",
       "      <td>3.322219</td>\n",
       "      <td>Pakistan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>70</td>\n",
       "      <td>3.083166</td>\n",
       "      <td>3.176091</td>\n",
       "      <td>Iraq</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>38</td>\n",
       "      <td>4.223488</td>\n",
       "      <td>4.492760</td>\n",
       "      <td>Denmark</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>136</td>\n",
       "      <td>3.022775</td>\n",
       "      <td>3.690196</td>\n",
       "      <td>Swaziland</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>88</td>\n",
       "      <td>3.358411</td>\n",
       "      <td>3.591065</td>\n",
       "      <td>Maldives</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>10</td>\n",
       "      <td>3.861908</td>\n",
       "      <td>4.227887</td>\n",
       "      <td>Bahrain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>63</td>\n",
       "      <td>3.012447</td>\n",
       "      <td>3.204120</td>\n",
       "      <td>Haiti</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>1</td>\n",
       "      <td>3.184648</td>\n",
       "      <td>3.653213</td>\n",
       "      <td>Albania</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>68</td>\n",
       "      <td>3.165643</td>\n",
       "      <td>3.505150</td>\n",
       "      <td>Indonesia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>117</td>\n",
       "      <td>2.978056</td>\n",
       "      <td>2.845098</td>\n",
       "      <td>Republic of the Congo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>124</td>\n",
       "      <td>3.303916</td>\n",
       "      <td>4.071882</td>\n",
       "      <td>Saudi Arabia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>43</td>\n",
       "      <td>3.252679</td>\n",
       "      <td>3.602060</td>\n",
       "      <td>Egypt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>97</td>\n",
       "      <td>3.072978</td>\n",
       "      <td>3.857332</td>\n",
       "      <td>Namibia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>73</td>\n",
       "      <td>3.233793</td>\n",
       "      <td>3.591065</td>\n",
       "      <td>Jamaica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>120</td>\n",
       "      <td>3.290537</td>\n",
       "      <td>3.944483</td>\n",
       "      <td>Saint Kitts and Nevis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>6</td>\n",
       "      <td>4.250161</td>\n",
       "      <td>4.462398</td>\n",
       "      <td>Australia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>147</td>\n",
       "      <td>3.423700</td>\n",
       "      <td>3.838849</td>\n",
       "      <td>Tunisia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>151</td>\n",
       "      <td>3.873496</td>\n",
       "      <td>3.732394</td>\n",
       "      <td>Ukraine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>62</td>\n",
       "      <td>3.123390</td>\n",
       "      <td>3.602060</td>\n",
       "      <td>Guyana</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>146</td>\n",
       "      <td>3.232352</td>\n",
       "      <td>3.977724</td>\n",
       "      <td>Trinidad and Tobago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>47</td>\n",
       "      <td>3.772504</td>\n",
       "      <td>4.089905</td>\n",
       "      <td>Estonia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>93</td>\n",
       "      <td>3.295478</td>\n",
       "      <td>3.954243</td>\n",
       "      <td>Mexico</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>101</td>\n",
       "      <td>3.011446</td>\n",
       "      <td>2.903090</td>\n",
       "      <td>Niger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>55</td>\n",
       "      <td>4.215853</td>\n",
       "      <td>4.440909</td>\n",
       "      <td>Germany</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Country ID  GDP Prediction  Real GDP                         Country\n",
       "0           60        2.990985  3.322219                          Guinea\n",
       "1           21        3.960366  4.269513                          Brunei\n",
       "2           57        4.127713  4.301030                          Greece\n",
       "3          107        4.083888  3.954243                           Palau\n",
       "4           48        2.988960  2.845098                        Ethiopia\n",
       "5           85        2.988428  2.903090                      Madagascar\n",
       "6          145        3.519759  3.342423                           Tonga\n",
       "7          139        3.177833  3.518514                           Syria\n",
       "8          121        3.436107  3.732394                     Saint Lucia\n",
       "9           49        3.707042  3.301030  Federated States of Micronesia\n",
       "10           8        3.105657  3.531479                      Azerbaijan\n",
       "11         140        3.050080  3.079181           So Tom and Prncipe\n",
       "12           7        4.173307  4.477121                         Austria\n",
       "13          26        2.995289  3.255273                        Cameroon\n",
       "14         144        2.988581  3.176091                            Togo\n",
       "15         129        2.989638  2.698970                         Somalia\n",
       "16          58        3.221403  3.698970                         Grenada\n",
       "17          34        3.671046  3.462398                            Cuba\n",
       "18         130        3.129686  4.029384                    South Africa\n",
       "19          81        3.846741  4.008600                          Latvia\n",
       "20          24        2.955323  2.778151                         Burundi\n",
       "21         123        3.200670  3.748188                           Samoa\n",
       "22          56        3.025095  3.342423                           Ghana\n",
       "23          19        3.070642  3.954243                        Botswana\n",
       "24          72        3.962923  4.296665                          Israel\n",
       "25         106        3.054095  3.322219                        Pakistan\n",
       "26          70        3.083166  3.176091                            Iraq\n",
       "27          38        4.223488  4.492760                         Denmark\n",
       "28         136        3.022775  3.690196                       Swaziland\n",
       "29          88        3.358411  3.591065                        Maldives\n",
       "30          10        3.861908  4.227887                         Bahrain\n",
       "31          63        3.012447  3.204120                           Haiti\n",
       "32           1        3.184648  3.653213                         Albania\n",
       "33          68        3.165643  3.505150                       Indonesia\n",
       "34         117        2.978056  2.845098           Republic of the Congo\n",
       "35         124        3.303916  4.071882                    Saudi Arabia\n",
       "36          43        3.252679  3.602060                           Egypt\n",
       "37          97        3.072978  3.857332                         Namibia\n",
       "38          73        3.233793  3.591065                         Jamaica\n",
       "39         120        3.290537  3.944483           Saint Kitts and Nevis\n",
       "40           6        4.250161  4.462398                       Australia\n",
       "41         147        3.423700  3.838849                         Tunisia\n",
       "42         151        3.873496  3.732394                         Ukraine\n",
       "43          62        3.123390  3.602060                          Guyana\n",
       "44         146        3.232352  3.977724             Trinidad and Tobago\n",
       "45          47        3.772504  4.089905                         Estonia\n",
       "46          93        3.295478  3.954243                          Mexico\n",
       "47         101        3.011446  2.903090                           Niger\n",
       "48          55        4.215853  4.440909                         Germany"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = pd.DataFrame(list(zip(x_test, gnn_model(x_test).numpy()[:,0], y_test))).rename(columns = {0 : \"Country ID\", 1: \"GDP Prediction\", 2: \"Real GDP\"})\n",
    "\n",
    "gnn_predictions_test = predictions.merge(test_data[[\"Country\", \"Country ID\"]], on = \"Country ID\", how = \"left\")\n",
    "\n",
    "gnn_predictions_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country ID</th>\n",
       "      <th>GDP Prediction</th>\n",
       "      <th>Real GDP</th>\n",
       "      <th>Country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>67</td>\n",
       "      <td>3.122303</td>\n",
       "      <td>3.462398</td>\n",
       "      <td>India</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>148</td>\n",
       "      <td>3.558721</td>\n",
       "      <td>3.826075</td>\n",
       "      <td>Turkey</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>71</td>\n",
       "      <td>4.218635</td>\n",
       "      <td>4.471292</td>\n",
       "      <td>Ireland</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>111</td>\n",
       "      <td>3.587428</td>\n",
       "      <td>3.698970</td>\n",
       "      <td>People's Republic of China</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>76</td>\n",
       "      <td>3.268962</td>\n",
       "      <td>3.799341</td>\n",
       "      <td>Kazakhstan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>108</td>\n",
       "      <td>3.481286</td>\n",
       "      <td>3.799341</td>\n",
       "      <td>Panama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>116</td>\n",
       "      <td>4.271238</td>\n",
       "      <td>4.332438</td>\n",
       "      <td>Qatar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>23</td>\n",
       "      <td>2.982444</td>\n",
       "      <td>3.041393</td>\n",
       "      <td>Burkina Faso</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>138</td>\n",
       "      <td>4.271989</td>\n",
       "      <td>4.514548</td>\n",
       "      <td>Switzerland</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>102</td>\n",
       "      <td>2.982530</td>\n",
       "      <td>2.954243</td>\n",
       "      <td>Nigeria</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>114 rows  4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Country ID  GDP Prediction  Real GDP                     Country\n",
       "0            67        3.122303  3.462398                       India\n",
       "1           148        3.558721  3.826075                      Turkey\n",
       "2            71        4.218635  4.471292                     Ireland\n",
       "3           111        3.587428  3.698970  People's Republic of China\n",
       "4            76        3.268962  3.799341                  Kazakhstan\n",
       "..          ...             ...       ...                         ...\n",
       "109         108        3.481286  3.799341                      Panama\n",
       "110         116        4.271238  4.332438                       Qatar\n",
       "111          23        2.982444  3.041393                Burkina Faso\n",
       "112         138        4.271989  4.514548                 Switzerland\n",
       "113         102        2.982530  2.954243                     Nigeria\n",
       "\n",
       "[114 rows x 4 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = pd.DataFrame(list(zip(x_train, gnn_model(x_train).numpy()[:,0], y_train))).rename(columns = {0 : \"Country ID\", 1: \"GDP Prediction\", 2: \"Real GDP\"})\n",
    "\n",
    "gnn_predictions_train = predictions.merge(train_data[[\"Country\", \"Country ID\"]], on = \"Country ID\", how = \"left\")\n",
    "\n",
    "gnn_predictions_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country ID</th>\n",
       "      <th>GDP Prediction</th>\n",
       "      <th>Real GDP</th>\n",
       "      <th>Country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>67</td>\n",
       "      <td>3.122303</td>\n",
       "      <td>3.462398</td>\n",
       "      <td>India</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>148</td>\n",
       "      <td>3.558721</td>\n",
       "      <td>3.826075</td>\n",
       "      <td>Turkey</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>71</td>\n",
       "      <td>4.218635</td>\n",
       "      <td>4.471292</td>\n",
       "      <td>Ireland</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>111</td>\n",
       "      <td>3.587428</td>\n",
       "      <td>3.698970</td>\n",
       "      <td>People's Republic of China</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>76</td>\n",
       "      <td>3.268962</td>\n",
       "      <td>3.799341</td>\n",
       "      <td>Kazakhstan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>146</td>\n",
       "      <td>3.232352</td>\n",
       "      <td>3.977724</td>\n",
       "      <td>Trinidad and Tobago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>47</td>\n",
       "      <td>3.772504</td>\n",
       "      <td>4.089905</td>\n",
       "      <td>Estonia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>93</td>\n",
       "      <td>3.295478</td>\n",
       "      <td>3.954243</td>\n",
       "      <td>Mexico</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>101</td>\n",
       "      <td>3.011446</td>\n",
       "      <td>2.903090</td>\n",
       "      <td>Niger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>55</td>\n",
       "      <td>4.215853</td>\n",
       "      <td>4.440909</td>\n",
       "      <td>Germany</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>163 rows  4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Country ID  GDP Prediction  Real GDP                     Country\n",
       "0           67        3.122303  3.462398                       India\n",
       "1          148        3.558721  3.826075                      Turkey\n",
       "2           71        4.218635  4.471292                     Ireland\n",
       "3          111        3.587428  3.698970  People's Republic of China\n",
       "4           76        3.268962  3.799341                  Kazakhstan\n",
       "..         ...             ...       ...                         ...\n",
       "44         146        3.232352  3.977724         Trinidad and Tobago\n",
       "45          47        3.772504  4.089905                     Estonia\n",
       "46          93        3.295478  3.954243                      Mexico\n",
       "47         101        3.011446  2.903090                       Niger\n",
       "48          55        4.215853  4.440909                     Germany\n",
       "\n",
       "[163 rows x 4 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gnn_predictions = gnn_predictions_train.append(gnn_predictions_test)\n",
    "\n",
    "gnn_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unique(list1):\n",
    "    unique_list = []\n",
    "    for x in list1:\n",
    "        if x not in unique_list:\n",
    "            unique_list.append(x)\n",
    "    return unique_list\n",
    "\n",
    "def plot_series(series, y=None, y_pred=None, x_label=\"$t$\", y_label=\"$x(t)$\"):\n",
    "    plt.plot(series, \".-\")\n",
    "    if y is not None:\n",
    "        plt.plot(n_steps, y, \"bx\", markersize=10)\n",
    "    if y_pred is not None:\n",
    "        plt.plot(n_steps, y_pred, \"ro\")\n",
    "    plt.grid(True)\n",
    "    if x_label:\n",
    "        plt.xlabel(x_label, fontsize=16)\n",
    "    if y_label:\n",
    "        plt.ylabel(y_label, fontsize=16, rotation=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_latlong = pd.read_csv('../RNN/countries.csv')\n",
    "df_latlong.drop(['Importance', 'Altitude'], axis=1, inplace=True)\n",
    "\n",
    "df_gdp = pd.read_csv('../RNN/gdp_per_capita.csv')\n",
    "df_gdp.drop(['Unnamed: 65', 'Code'], axis=1, inplace=True)\n",
    "\n",
    "countries_df_latlong = df_latlong['Country'].values\n",
    "countries_df_gdp = df_gdp['Country Name'].values\n",
    "\n",
    "mismatch = [i for i in countries_df_latlong if i not in countries_df_gdp]\n",
    "\n",
    "nodes = set(countries_df_latlong)-set(mismatch)\n",
    "nodes_df = [i for i in nodes]\n",
    "\n",
    "df = df_latlong[df_latlong['Country'].isin(nodes_df)]\n",
    "\n",
    "df = pd.merge(df_latlong,df_gdp,how='inner',left_on=['Country'],right_on=['Country Name'])\n",
    "\n",
    "df.drop(['Country Name'], axis=1, inplace=True)\n",
    "\n",
    "df = df.rename({'Latitude': 'Lat', 'Longitude': 'Lon'}, axis=1)\n",
    "\n",
    "GDP_years = list(set(df.columns) - {'Country', 'Lat', 'Lon'})\n",
    "\n",
    "for column in GDP_years:\n",
    "    df[column] = np.log10(df[column])\n",
    "\n",
    "df = df.melt(id_vars=['Country', 'Lat', 'Lon'], \n",
    "        var_name=\"Year\", \n",
    "        value_name=\"GDP\")\n",
    "\n",
    "data = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.3754 - val_loss: 0.1627\n",
      "Epoch 2/80\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.0640 - val_loss: 0.0153\n",
      "Epoch 3/80\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.0197 - val_loss: 0.0172\n",
      "Epoch 4/80\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.0245 - val_loss: 0.0126\n",
      "Epoch 5/80\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.0159 - val_loss: 0.0117\n",
      "Epoch 6/80\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.0143 - val_loss: 0.0129\n",
      "Epoch 7/80\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.0134 - val_loss: 0.0106\n",
      "Epoch 8/80\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.0122 - val_loss: 0.0094\n",
      "Epoch 9/80\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.0115 - val_loss: 0.0088\n",
      "Epoch 10/80\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.0107 - val_loss: 0.0085\n",
      "Epoch 11/80\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.0099 - val_loss: 0.0078\n",
      "Epoch 12/80\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.0092 - val_loss: 0.0073\n",
      "Epoch 13/80\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.0085 - val_loss: 0.0068\n",
      "Epoch 14/80\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.0079 - val_loss: 0.0063\n",
      "Epoch 15/80\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.0073 - val_loss: 0.0059\n",
      "Epoch 16/80\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.0068 - val_loss: 0.0055\n",
      "Epoch 17/80\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.0063 - val_loss: 0.0051\n",
      "Epoch 18/80\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.0059 - val_loss: 0.0048\n",
      "Epoch 19/80\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.0055 - val_loss: 0.0045\n",
      "Epoch 20/80\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.0051 - val_loss: 0.0043\n",
      "Epoch 21/80\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.0048 - val_loss: 0.0041\n",
      "Epoch 22/80\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.0045 - val_loss: 0.0038\n",
      "Epoch 23/80\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.0043 - val_loss: 0.0037\n",
      "Epoch 24/80\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.0041 - val_loss: 0.0035\n",
      "Epoch 25/80\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.0039 - val_loss: 0.0033\n",
      "Epoch 26/80\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.0037 - val_loss: 0.0032\n",
      "Epoch 27/80\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.0036 - val_loss: 0.0031\n",
      "Epoch 28/80\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.0034 - val_loss: 0.0030\n",
      "Epoch 29/80\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.0033 - val_loss: 0.0030\n",
      "Epoch 30/80\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.0032 - val_loss: 0.0029\n",
      "Epoch 31/80\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.0032 - val_loss: 0.0028\n",
      "Epoch 32/80\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.0031 - val_loss: 0.0028\n",
      "Epoch 33/80\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.0030 - val_loss: 0.0027\n",
      "Epoch 34/80\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.0030 - val_loss: 0.0027\n",
      "Epoch 35/80\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.0029 - val_loss: 0.0027\n",
      "Epoch 36/80\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.0029 - val_loss: 0.0026\n",
      "Epoch 37/80\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.0029 - val_loss: 0.0026\n",
      "Epoch 38/80\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.0028 - val_loss: 0.0026\n",
      "Epoch 39/80\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.0028 - val_loss: 0.0026\n",
      "Epoch 40/80\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.0028 - val_loss: 0.0025\n",
      "Epoch 41/80\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.0028 - val_loss: 0.0025\n",
      "Epoch 42/80\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.0028 - val_loss: 0.0025\n",
      "Epoch 43/80\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.0027 - val_loss: 0.0025\n",
      "Epoch 44/80\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.0027 - val_loss: 0.0025\n",
      "Epoch 45/80\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.0027 - val_loss: 0.0025\n",
      "Epoch 46/80\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.0027 - val_loss: 0.0025\n",
      "Epoch 47/80\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.0027 - val_loss: 0.0025\n",
      "Epoch 48/80\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.0027 - val_loss: 0.0025\n",
      "Epoch 49/80\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.0027 - val_loss: 0.0024\n",
      "Epoch 50/80\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.0027 - val_loss: 0.0024\n",
      "Epoch 51/80\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.0027 - val_loss: 0.0024\n",
      "Epoch 52/80\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.0027 - val_loss: 0.0024\n",
      "Epoch 53/80\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.0026 - val_loss: 0.0024\n",
      "Epoch 54/80\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.0026 - val_loss: 0.0024\n",
      "Epoch 55/80\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.0026 - val_loss: 0.0024\n",
      "Epoch 56/80\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.0026 - val_loss: 0.0024\n",
      "Epoch 57/80\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.0026 - val_loss: 0.0024\n",
      "Epoch 58/80\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.0026 - val_loss: 0.0024\n",
      "Epoch 59/80\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.0026 - val_loss: 0.0024\n",
      "Epoch 60/80\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.0026 - val_loss: 0.0024\n",
      "Epoch 61/80\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.0026 - val_loss: 0.0023\n",
      "Epoch 62/80\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.0026 - val_loss: 0.0023\n",
      "Epoch 63/80\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.0025 - val_loss: 0.0023\n",
      "Epoch 64/80\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.0025 - val_loss: 0.0023\n",
      "Epoch 65/80\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.0025 - val_loss: 0.0023\n",
      "Epoch 66/80\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.0025 - val_loss: 0.0023\n",
      "Epoch 67/80\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.0025 - val_loss: 0.0023\n",
      "Epoch 68/80\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.0025 - val_loss: 0.0023\n",
      "Epoch 69/80\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.0025 - val_loss: 0.0023\n",
      "Epoch 70/80\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.0025 - val_loss: 0.0023\n",
      "Epoch 71/80\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.0025 - val_loss: 0.0023\n",
      "Epoch 72/80\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.0025 - val_loss: 0.0022\n",
      "Epoch 73/80\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.0024 - val_loss: 0.0022\n",
      "Epoch 74/80\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.0024 - val_loss: 0.0022\n",
      "Epoch 75/80\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.0024 - val_loss: 0.0022\n",
      "Epoch 76/80\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.0024 - val_loss: 0.0022\n",
      "Epoch 77/80\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.0024 - val_loss: 0.0022\n",
      "Epoch 78/80\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.0024 - val_loss: 0.0022\n",
      "Epoch 79/80\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.0024 - val_loss: 0.0022\n",
      "Epoch 80/80\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.0024 - val_loss: 0.0022\n"
     ]
    }
   ],
   "source": [
    "lista_unica = unique(df['Country'].tolist())       \n",
    "\n",
    "dataset = []\n",
    "for pais in lista_unica:\n",
    "   data_pais = df[df[\"Country\"] == pais]\n",
    "   latitude_pais = data_pais.Lat\n",
    "   latitude_pais = latitude_pais.tolist()\n",
    "   latitude_pais = latitude_pais[0]\n",
    "   longitude_pais = data_pais.Lon\n",
    "   longitude_pais = longitude_pais.tolist()\n",
    "   longitude_pais = longitude_pais[0]\n",
    "   linha = 0\n",
    "   gdp =  data_pais.GDP\n",
    "   gdp = gdp.tolist()\n",
    " \n",
    "   while linha<len(gdp)-3: \n",
    "    #  dataset_array = []\n",
    "    \n",
    "     gdp_1 = gdp[linha]\n",
    "     gdp_2 = gdp[linha+1]\n",
    "     gdp_3 = gdp[linha+2]\n",
    "     gdp_4 = gdp[linha+3]\n",
    "     gdp_5 = gdp[linha+4]\n",
    "\n",
    "    #  print(\"gdp_1 {0}\".format(gdp_1))\n",
    "    #  print(\"gdp_2 {0}\".format(gdp_2))\n",
    "    #  print(\"gdp_3 {0}\".format(gdp_3))\n",
    "    #  print(\"gdp_4 {0}\".format(gdp_4))\n",
    "    #  print(\"gdp_5 {0}\".format(gdp_5))\n",
    "     if math.isnan(gdp_1) or math.isnan(gdp_2) or math.isnan(gdp_3) or math.isnan(gdp_4) or math.isnan(gdp_5):\n",
    "       nan = 0\n",
    "      #  print(gdp_1[0])\n",
    "      #  print(\"nan\")\n",
    "     else:\n",
    "       dataset.append([latitude_pais, longitude_pais, gdp_1, gdp_2, gdp_3, gdp_4, gdp_5])\n",
    "\n",
    "      \n",
    "      # dataset.append(dataset_array)\n",
    "     linha +=4\n",
    "\n",
    "my_array = np.array(dataset)\n",
    "dataset = my_array.astype('float32')\n",
    "# Normalizando os Valores\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "dataset = scaler.fit_transform(dataset)\n",
    "dataset\n",
    "\n",
    "n_steps = 6 #CADA LISTA DENTRO DA LISTA VAI TER 7 DADOS\n",
    "\n",
    "setenta_porc= int((70*len(dataset))/100)\n",
    "vint_poc = int((20*len(dataset))/100)\n",
    "nov_porc=setenta_porc+vint_poc\n",
    "\n",
    "X_train, y_train = dataset[:setenta_porc, :n_steps], dataset[:setenta_porc, -1]\n",
    "X_valid, y_valid = dataset[setenta_porc:nov_porc, :n_steps], dataset[setenta_porc:nov_porc, -1]\n",
    "X_test, y_test = dataset[nov_porc:, :n_steps], dataset[nov_porc:, -1]\n",
    "\n",
    "y_pred = X_valid[:, -1]\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    # keras.layers.Flatten(input_shape=[6, 1]),\n",
    "    keras.layers.Dense(1,input_shape=[6]),\n",
    "])\n",
    "\n",
    "optimizer = keras.optimizers.Adam(learning_rate=0.01)\n",
    "\n",
    "model.compile(loss=\"mse\", optimizer=optimizer)\n",
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=80, #20\n",
    "    batch_size=128, #128\n",
    "    validation_data=(X_valid, y_valid),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1332, 6), (1332,))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.1825 - val_loss: 0.0479\n",
      "Epoch 2/80\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.0216 - val_loss: 0.0164\n",
      "Epoch 3/80\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.0244 - val_loss: 0.0141\n",
      "Epoch 4/80\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.0147 - val_loss: 0.0107\n",
      "Epoch 5/80\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.0119 - val_loss: 0.0109\n",
      "Epoch 6/80\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.0101 - val_loss: 0.0077\n",
      "Epoch 7/80\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.0088 - val_loss: 0.0065\n",
      "Epoch 8/80\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.0076 - val_loss: 0.0060\n",
      "Epoch 9/80\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.0065 - val_loss: 0.0050\n",
      "Epoch 10/80\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.0055 - val_loss: 0.0042\n",
      "Epoch 11/80\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.0047 - val_loss: 0.0036\n",
      "Epoch 12/80\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.0040 - val_loss: 0.0031\n",
      "Epoch 13/80\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.0033 - val_loss: 0.0026\n",
      "Epoch 14/80\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.0028 - val_loss: 0.0022\n",
      "Epoch 15/80\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.0024 - val_loss: 0.0018\n",
      "Epoch 16/80\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.0020 - val_loss: 0.0016\n",
      "Epoch 17/80\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.0017 - val_loss: 0.0013\n",
      "Epoch 18/80\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.0014 - val_loss: 0.0012\n",
      "Epoch 19/80\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.0012 - val_loss: 0.0010\n",
      "Epoch 20/80\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.0010 - val_loss: 8.8471e-04\n",
      "Epoch 21/80\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 8.7139e-04 - val_loss: 7.8386e-04\n",
      "Epoch 22/80\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 7.5335e-04 - val_loss: 6.9485e-04\n",
      "Epoch 23/80\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 6.6183e-04 - val_loss: 6.4170e-04\n",
      "Epoch 24/80\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 5.8740e-04 - val_loss: 5.8121e-04\n",
      "Epoch 25/80\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 5.2979e-04 - val_loss: 5.3642e-04\n",
      "Epoch 26/80\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 4.8192e-04 - val_loss: 5.0620e-04\n",
      "Epoch 27/80\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 4.4681e-04 - val_loss: 4.7877e-04\n",
      "Epoch 28/80\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 4.1949e-04 - val_loss: 4.5842e-04\n",
      "Epoch 29/80\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 3.9908e-04 - val_loss: 4.4711e-04\n",
      "Epoch 30/80\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 3.8211e-04 - val_loss: 4.3063e-04\n",
      "Epoch 31/80\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 3.7101e-04 - val_loss: 4.2252e-04\n",
      "Epoch 32/80\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 3.6118e-04 - val_loss: 4.1485e-04\n",
      "Epoch 33/80\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 3.5421e-04 - val_loss: 4.0894e-04\n",
      "Epoch 34/80\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 3.4916e-04 - val_loss: 4.0516e-04\n",
      "Epoch 35/80\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 3.4472e-04 - val_loss: 4.0153e-04\n",
      "Epoch 36/80\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 3.4152e-04 - val_loss: 3.9879e-04\n",
      "Epoch 37/80\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 3.4139e-04 - val_loss: 3.9629e-04\n",
      "Epoch 38/80\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 3.4007e-04 - val_loss: 3.9462e-04\n",
      "Epoch 39/80\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 3.3708e-04 - val_loss: 3.9300e-04\n",
      "Epoch 40/80\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 3.3628e-04 - val_loss: 3.9176e-04\n",
      "Epoch 41/80\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 3.3417e-04 - val_loss: 3.9056e-04\n",
      "Epoch 42/80\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 3.3322e-04 - val_loss: 3.8979e-04\n",
      "Epoch 43/80\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 3.3258e-04 - val_loss: 3.8870e-04\n",
      "Epoch 44/80\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 3.3181e-04 - val_loss: 3.8790e-04\n",
      "Epoch 45/80\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 3.3121e-04 - val_loss: 3.8695e-04\n",
      "Epoch 46/80\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 3.3043e-04 - val_loss: 3.8682e-04\n",
      "Epoch 47/80\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 3.3125e-04 - val_loss: 3.8542e-04\n",
      "Epoch 48/80\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 3.3133e-04 - val_loss: 3.8480e-04\n",
      "Epoch 49/80\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 3.2946e-04 - val_loss: 3.8402e-04\n",
      "Epoch 50/80\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 3.2924e-04 - val_loss: 3.8315e-04\n",
      "Epoch 51/80\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 3.2762e-04 - val_loss: 3.8291e-04\n",
      "Epoch 52/80\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 3.2715e-04 - val_loss: 3.8240e-04\n",
      "Epoch 53/80\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 3.2655e-04 - val_loss: 3.8106e-04\n",
      "Epoch 54/80\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 3.2613e-04 - val_loss: 3.8179e-04\n",
      "Epoch 55/80\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 3.2541e-04 - val_loss: 3.8036e-04\n",
      "Epoch 56/80\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 3.2460e-04 - val_loss: 3.7905e-04\n",
      "Epoch 57/80\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 3.2394e-04 - val_loss: 3.7832e-04\n",
      "Epoch 58/80\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 3.2474e-04 - val_loss: 3.7758e-04\n",
      "Epoch 59/80\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 3.2382e-04 - val_loss: 3.7687e-04\n",
      "Epoch 60/80\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 3.2236e-04 - val_loss: 3.7671e-04\n",
      "Epoch 61/80\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 3.2201e-04 - val_loss: 3.7534e-04\n",
      "Epoch 62/80\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 3.2141e-04 - val_loss: 3.7557e-04\n",
      "Epoch 63/80\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 3.2092e-04 - val_loss: 3.7459e-04\n",
      "Epoch 64/80\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 3.1912e-04 - val_loss: 3.7322e-04\n",
      "Epoch 65/80\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 3.1867e-04 - val_loss: 3.7322e-04\n",
      "Epoch 66/80\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 3.1818e-04 - val_loss: 3.7219e-04\n",
      "Epoch 67/80\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 3.1922e-04 - val_loss: 3.7103e-04\n",
      "Epoch 68/80\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 3.1704e-04 - val_loss: 3.7051e-04\n",
      "Epoch 69/80\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 3.1646e-04 - val_loss: 3.7079e-04\n",
      "Epoch 70/80\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 3.1534e-04 - val_loss: 3.6875e-04\n",
      "Epoch 71/80\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 3.1458e-04 - val_loss: 3.6866e-04\n",
      "Epoch 72/80\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 3.1585e-04 - val_loss: 3.6890e-04\n",
      "Epoch 73/80\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 3.1425e-04 - val_loss: 3.6645e-04\n",
      "Epoch 74/80\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 3.1631e-04 - val_loss: 3.6633e-04\n",
      "Epoch 75/80\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 3.1427e-04 - val_loss: 3.7253e-04\n",
      "Epoch 76/80\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 3.1639e-04 - val_loss: 3.6589e-04\n",
      "Epoch 77/80\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 3.1189e-04 - val_loss: 3.6486e-04\n",
      "Epoch 78/80\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 3.0945e-04 - val_loss: 3.6316e-04\n",
      "Epoch 79/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 3ms/step - loss: 3.1047e-04 - val_loss: 3.6460e-04\n",
      "Epoch 80/80\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 3.0896e-04 - val_loss: 3.6149e-04\n"
     ]
    }
   ],
   "source": [
    "y_pred = X_valid[:, -1]\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    # keras.layers.Flatten(input_shape=[6, 1]),\n",
    "    keras.layers.Dense(1,input_shape=[6]),\n",
    "])\n",
    "\n",
    "optimizer = keras.optimizers.Adam(learning_rate=0.01)\n",
    "\n",
    "model.compile(loss=\"mse\", optimizer=optimizer)\n",
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=80, #20\n",
    "    batch_size=128, #128\n",
    "    validation_data=(X_valid, y_valid),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 0s 1ms/step - loss: 3.6149e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0003614910820033401"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_valid, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 6.75763329e-03],\n",
       "        [ 3.95451731e-04],\n",
       "        [-3.69428769e-02],\n",
       "        [ 3.32863897e-01],\n",
       "        [-1.12042524e-01],\n",
       "        [ 8.20243001e-01]], dtype=float32),\n",
       " array([-0.00659214], dtype=float32)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[0].get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 0s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "8/8 [==============================] - 1s 38ms/step - loss: 0.0088 - val_loss: 0.0064\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0059 - val_loss: 0.0047\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0042 - val_loss: 0.0034\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0031 - val_loss: 0.0030\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0027 - val_loss: 0.0027\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0024 - val_loss: 0.0025\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0022 - val_loss: 0.0023\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0020 - val_loss: 0.0021\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0019 - val_loss: 0.0020\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0018 - val_loss: 0.0019\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0017 - val_loss: 0.0018\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0017 - val_loss: 0.0018\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0016 - val_loss: 0.0018\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0016 - val_loss: 0.0017\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0016 - val_loss: 0.0017\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0016 - val_loss: 0.0018\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0016 - val_loss: 0.0017\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0015 - val_loss: 0.0017\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0015 - val_loss: 0.0017\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0015 - val_loss: 0.0017\n",
      "12/12 [==============================] - 0s 998us/step\n"
     ]
    }
   ],
   "source": [
    "X_train = X_train.reshape((1332,1,6))\n",
    "X_valid = X_valid.reshape((380,1,6))\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.SimpleRNN(1, input_shape=[None,6]),\n",
    "])\n",
    "\n",
    "optimizer = keras.optimizers.Adam(learning_rate=0.01)\n",
    "model.compile(loss=\"mse\", optimizer=optimizer)\n",
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=20, #20\n",
    "    batch_size=180, #180\n",
    "    validation_data=(X_valid, y_valid),\n",
    ")\n",
    "\n",
    "y_pred = model.predict(X_valid)\n",
    "\n",
    "X_valid = X_valid.reshape((380, 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n",
      "8/8 [==============================] - 1s 23ms/step - loss: 0.8088 - val_loss: 0.6072\n",
      "Epoch 2/80\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.3865 - val_loss: 0.2306\n",
      "Epoch 3/80\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.1242 - val_loss: 0.0598\n",
      "Epoch 4/80\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0306 - val_loss: 0.0156\n",
      "Epoch 5/80\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0131 - val_loss: 0.0100\n",
      "Epoch 6/80\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0133 - val_loss: 0.0105\n",
      "Epoch 7/80\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0145 - val_loss: 0.0105\n",
      "Epoch 8/80\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0140 - val_loss: 0.0099\n",
      "Epoch 9/80\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0128 - val_loss: 0.0095\n",
      "Epoch 10/80\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0119 - val_loss: 0.0094\n",
      "Epoch 11/80\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0113 - val_loss: 0.0095\n",
      "Epoch 12/80\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0110 - val_loss: 0.0096\n",
      "Epoch 13/80\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0108 - val_loss: 0.0096\n",
      "Epoch 14/80\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0105 - val_loss: 0.0093\n",
      "Epoch 15/80\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0103 - val_loss: 0.0091\n",
      "Epoch 16/80\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0101 - val_loss: 0.0089\n",
      "Epoch 17/80\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0099 - val_loss: 0.0087\n",
      "Epoch 18/80\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0096 - val_loss: 0.0085\n",
      "Epoch 19/80\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0094 - val_loss: 0.0083\n",
      "Epoch 20/80\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0092 - val_loss: 0.0081\n",
      "Epoch 21/80\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0089 - val_loss: 0.0080\n",
      "Epoch 22/80\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0087 - val_loss: 0.0077\n",
      "Epoch 23/80\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0085 - val_loss: 0.0075\n",
      "Epoch 24/80\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0083 - val_loss: 0.0074\n",
      "Epoch 25/80\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0080 - val_loss: 0.0072\n",
      "Epoch 26/80\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0078 - val_loss: 0.0070\n",
      "Epoch 27/80\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0076 - val_loss: 0.0069\n",
      "Epoch 28/80\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0074 - val_loss: 0.0067\n",
      "Epoch 29/80\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0072 - val_loss: 0.0065\n",
      "Epoch 30/80\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0070 - val_loss: 0.0064\n",
      "Epoch 31/80\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0068 - val_loss: 0.0062\n",
      "Epoch 32/80\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0066 - val_loss: 0.0060\n",
      "Epoch 33/80\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0064 - val_loss: 0.0059\n",
      "Epoch 34/80\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0062 - val_loss: 0.0058\n",
      "Epoch 35/80\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0060 - val_loss: 0.0056\n",
      "Epoch 36/80\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0058 - val_loss: 0.0054\n",
      "Epoch 37/80\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0056 - val_loss: 0.0053\n",
      "Epoch 38/80\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0055 - val_loss: 0.0052\n",
      "Epoch 39/80\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0053 - val_loss: 0.0050\n",
      "Epoch 40/80\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0051 - val_loss: 0.0049\n",
      "Epoch 41/80\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0050 - val_loss: 0.0048\n",
      "Epoch 42/80\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0048 - val_loss: 0.0046\n",
      "Epoch 43/80\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0047 - val_loss: 0.0045\n",
      "Epoch 44/80\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0046 - val_loss: 0.0044\n",
      "Epoch 45/80\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 46/80\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0043 - val_loss: 0.0042\n",
      "Epoch 47/80\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0042 - val_loss: 0.0040\n",
      "Epoch 48/80\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0040 - val_loss: 0.0039\n",
      "Epoch 49/80\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0039 - val_loss: 0.0038\n",
      "Epoch 50/80\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0038 - val_loss: 0.0037\n",
      "Epoch 51/80\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0037 - val_loss: 0.0037\n",
      "Epoch 52/80\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0036 - val_loss: 0.0036\n",
      "Epoch 53/80\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0035 - val_loss: 0.0034\n",
      "Epoch 54/80\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0033 - val_loss: 0.0034\n",
      "Epoch 55/80\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0032 - val_loss: 0.0033\n",
      "Epoch 56/80\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0031 - val_loss: 0.0032\n",
      "Epoch 57/80\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0031 - val_loss: 0.0031\n",
      "Epoch 58/80\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0030 - val_loss: 0.0030\n",
      "Epoch 59/80\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0029 - val_loss: 0.0030\n",
      "Epoch 60/80\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0028 - val_loss: 0.0029\n",
      "Epoch 61/80\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0027 - val_loss: 0.0028\n",
      "Epoch 62/80\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0026 - val_loss: 0.0027\n",
      "Epoch 63/80\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0026 - val_loss: 0.0027\n",
      "Epoch 64/80\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0025 - val_loss: 0.0026\n",
      "Epoch 65/80\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0024 - val_loss: 0.0026\n",
      "Epoch 66/80\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0024 - val_loss: 0.0025\n",
      "Epoch 67/80\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0023 - val_loss: 0.0024\n",
      "Epoch 68/80\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0022 - val_loss: 0.0024\n",
      "Epoch 69/80\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0022 - val_loss: 0.0024\n",
      "Epoch 70/80\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0021 - val_loss: 0.0023\n",
      "Epoch 71/80\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0021 - val_loss: 0.0022\n",
      "Epoch 72/80\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0020 - val_loss: 0.0022\n",
      "Epoch 73/80\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0020 - val_loss: 0.0022\n",
      "Epoch 74/80\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0019 - val_loss: 0.0021\n",
      "Epoch 75/80\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0019 - val_loss: 0.0021\n",
      "Epoch 76/80\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0018 - val_loss: 0.0020\n",
      "Epoch 77/80\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0018 - val_loss: 0.0020\n",
      "Epoch 78/80\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0018 - val_loss: 0.0020\n",
      "Epoch 79/80\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0017 - val_loss: 0.0019\n",
      "Epoch 80/80\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0017 - val_loss: 0.0019\n"
     ]
    }
   ],
   "source": [
    "X_train = X_train.reshape((1332,1,6))\n",
    "X_valid = X_valid.reshape((380,1,6))\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.SimpleRNN(1, input_shape=[None,6]),\n",
    "])\n",
    "\n",
    "optimizer = keras.optimizers.Adam(learning_rate=0.01)\n",
    "model.compile(loss=\"mse\", optimizer=optimizer)\n",
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=80, #20\n",
    "    batch_size=180, #180\n",
    "    validation_data=(X_valid, y_valid),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 0s 890us/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_valid)\n",
    "\n",
    "X_valid = X_valid.reshape((380, 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 997us/step\n"
     ]
    }
   ],
   "source": [
    "X_test = X_test.reshape((192,1,6))\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "X_test = X_test.reshape((192, 6))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculando previses com o RNN para o ano de 2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mX4-5cALc-KD",
    "outputId": "a8132e4a-dc11-40c1-f818-df10803798bf"
   },
   "outputs": [],
   "source": [
    "lista_unica = unique(df['Country'].tolist())\n",
    "\n",
    "dataset_2016 = []\n",
    "pais_lista=[]\n",
    "maximo=0\n",
    "for pais in lista_unica:\n",
    "   data_pais = df[df[\"Country\"] == pais]\n",
    "   latitude_pais = data_pais.Lat\n",
    "   latitude_pais = latitude_pais.tolist()\n",
    "   latitude_pais = latitude_pais[0]\n",
    "   longitude_pais = data_pais.Lon\n",
    "   longitude_pais = longitude_pais.tolist()\n",
    "   longitude_pais = longitude_pais[0]\n",
    "   gdp =  data_pais.GDP\n",
    "   gdp = gdp.tolist()\n",
    "   gdp_1 = gdp[52]\n",
    "   gdp_2 = gdp[53]\n",
    "   gdp_3 = gdp[54]\n",
    "   gdp_4 = gdp[55]\n",
    "   gdp_5 = gdp[56]\n",
    "   if math.isnan(gdp_1) or math.isnan(gdp_2) or math.isnan(gdp_3) or math.isnan(gdp_4) or math.isnan(gdp_5):\n",
    "     nan = 0\n",
    "      #  print(gdp_1[0])\n",
    "      #  print(\"nan\")\n",
    "   else:\n",
    "      if maximo < gdp_1 or maximo < gdp_2 or maximo < gdp_3 or maximo < gdp_4 or maximo < gdp_5:\n",
    "        maximo = max(gdp_1,gdp_2,gdp_3,gdp_4,gdp_5)\n",
    "      dataset_2016.append([latitude_pais, longitude_pais, gdp_1, gdp_2, gdp_3, gdp_4, gdp_5])\n",
    "      pais_lista.append(pais)\n",
    "      \n",
    "      # dataset.append(dataset_array)\n",
    "\n",
    "# print(dataset_2016)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_array = np.array(dataset_2016)\n",
    "dataset_2016 = my_array.astype('float32')\n",
    "# Normalizando os Valores\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "dataset_2016 = scaler.fit_transform(dataset_2016)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "dbSSQZ7deoAV"
   },
   "outputs": [],
   "source": [
    "n_steps = 6\n",
    "X_2016, y_2016 = dataset_2016[:, :n_steps], dataset_2016[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "r51pabbVgPeA",
    "outputId": "266b1465-a1b0-4ea9-a96c-d62e78590077"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(156,)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_2016.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4R9Vrz2IfDER",
    "outputId": "94ebb692-8512-43ac-8fb5-445cc5073c5c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(156, 6)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_2016.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "iSQ6EfTyfRq9"
   },
   "outputs": [],
   "source": [
    "X_2016 = X_2016.reshape((156,1,6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0024\n",
      "0.0023888552095741034\n"
     ]
    }
   ],
   "source": [
    "print(model.evaluate(X_2016, y_2016))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 321
    },
    "id": "6SLG_49afpO-",
    "outputId": "b467b098-c221-4ae1-c7f6-974e2518c0eb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYkAAAEfCAYAAAC04jrjAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAAqBElEQVR4nO3deXxddZ3/8dcn+9Z0bwpN2kJbdmxLgqKIbUBUGFmki0rF0XGowuiMOow6P34ooKI/dXCcEauMC4pIbYEi66BCipZF2wAFilDa0pWWrim9SZv18/vj3JTb9N42y8059ybv5+ORR5Lv+Z5zP19S8s73nHu+x9wdERGRZHKiLkBERDKXQkJERFJSSIiISEoKCRERSUkhISIiKSkkREQkJYWEiIikpJCQQcnM1pvZfjOLmdk2M7vNzMoStt9mZm5mb09om2xmnvD9UjM7YGZVCW3vNbP1KV5zjJndaWavm9leM3vCzN7Rpc/lZrbBzBrN7F4zG5Gwba6ZPWlmTWa2NMnxc83sG/Hj7zOzZ81sWC//E4kACgkZ3C5y9zJgGjAd+Pcu23cD3zjKMRqB67r5emXAcqAaGAH8EniwM5zM7FTgJ8AVQAXQBPyoSz3/CXw7xfFvAN4FvBMojx/nQDdrE0lKISGDnrtvAx4hCItEvwTeZmYzjrD7fwEfNbPJ3Xidde5+s7tvdfd2d78VKABOjHeZB9zv7n9y9xhB+FxmZkPi+//R3RcBr3c9tpkNBz4PXOnuGzzworsrJKRPFBIy6JlZJXABsKbLpibgJuCbR9h9C/A/wPW9eN1pBCHR+bqnAis7t7v7WqAFOKEbhzsdaANmx0+frTazf+ppTSJdKSRkMLvXzPYBm4DtwNeS9PkJMN7MLjjCcb4FXBQ/XdQtZlYO3A7c4O57481lwN4uXfcCQ7pxyEpgKEGgHAfMBq43s/O7W5NIMgoJGcwudfchwEzgJGBU1w7u3gx8Pf5hyQ7i7juAHwI3dudFzawYuB942t2/lbApRnAtIVE5sK8bh90f/3yju+939+eBhcCF3alJJBWFhAx67v44cBvwvRRdfkHwV/qHjnCY7wK1BBelUzKzQuBegtNUn+6yeRUwNaHv8UAhsPpIx4x7Pv5ZyzpLWikkRAL/CZwfv05wCHdvI7jm8OVUO7t7A/AfwJdS9TGzfOAugr/6P+7uHV263EFw2uocMyslmJnc4+774vvnmlkRkAfkmFlR/Jid1y/+DFxrZoVmdjLwYeCBow9dJDWFhAgHTxn9itRvZ70T2HqUw/wAaD/C9ncBHwTeBzTE79GImdk58RpWAZ8hCIvtBNcirk7Y/wqCgFkAnBP/+n8Stn8UmADsAh4ErnP3R49Ss8gRmR46JCIiqWgmISIiKSkkREQkJYWEiIikpJAQEZGU8qIuIN1GjRrlEydO7NW+jY2NlJaWpregiGgsmWegjAM0lkzU13HU19fvdPfRXdsHXEhMnDiRFStW9GrfpUuXMnPmzPQWFBGNJfMMlHGAxpKJ+joOM9uQrF2nm0REJCWFhIiIpKSQEBGRlBQSIiKSkkJCRERSUkiIiEhKCom4+g17eGBtC/Ub9kRdiohIxgg9JMxshJktMbNGM9tgZpen6PfjhKWUY2bWHH/UZNrVb9jDR259irtfbWXeT59WUIiIxEUxk7iF4OHuFcA8YEGyZwO7+2fcvazzg2A9/8X9UdDT63bR2u44cKC1g8UrNvXHy4iIZJ1QQyL+tK1ZBA9Dibn7MuA+goepdGe/X/ZHXWcdP5Ki/JyDDzBeuHwTn7m9ng27Gvvj5UREskaoDx0ys+nAk+5enNB2DTDD3S86wn4fJ3h85CRPUrCZzQfmA1RUVFQvXLiwx7Wt2dPOym37OXlMEWsaOnhwXSttHXD+hDwumlRAab4d/SAZJBaLUVZWFnUZaTFQxjJQxgEaSybq6zhqa2vr3b3msA3uHtoHwSMXt3VpuxJYepT9HgWu785rVFdXe2/V1dUd/PqNvfv93xY/5xO/8oBPu+ER/+WTr3lrW3uvjx22xLFku4EyloEyDneNJRP1dRzACk/yOzXsaxIxoLxLWzmQ8oK0mVUBMwiePxyaMeVFfGf2VO7/7Ls5cewQvvq7VXzgB3+m7pXtYZYhIhKpsENiNZBnZlMS2qYCq46wz8cJTlGt69fKUjht3FDuvPIsbr2imrb2Dj75i+V8/Od/5ZVt/fJGKxGRjBJqSLh7I3APcKOZlZrZ2cAlwO1H2O3jwG0hlJeSmfG+U8fy+y/M4LoPnsJzG/dwwQ/+xLVLXmBnrDnK0kRE+lUUb4G9GigGthO8rfUqd19lZuPj90OM7+xoZu8EKumnt772VEFeDp9693E8/m+1fPydE1m4fBO1313Kjx9fS3Nbe9TliYikXegh4e673f1Sdy919/Hu/pt4+0YP7onYmND3qXi/jDq3M7y0gOsvPpVHPv8e3n7cCL798Mu89+bHeeiFrZ0X2kVEBgQty9EHk8eU8bNPnMmvP/UOSgvyuPqOZ5j7k6dYuakh6tJERNJCIZEG754yigf/+Ry+ddnpvLazkUtueYIv/vY5tu7dH3VpIiJ9opBIk9wc46NvH0/dNTO5euYkHnhhK7XfW8rNf1hNU0tb1OWJiPSKQiLNhhTl86UPnMSjX5zBe0+u4L8efZWZ313K4hWb6OjQ9QoRyS4KiX5SNaKEH15+Bndf9S6OHVbMv931PBffsoy/rNsVdWkiIt2mkOhn1ROGc89V7+IHH5nG7lgLH771aS0eKCJZQyERgpwc45Jp43j0X2fyr+efwJ9e3cF7b36cbz74Env3t0ZdnohISgqJEBUX5PK586aw9JqZfGj6OH667DVmfreOXz21nrb2jqjLExE5jEIiAlo8UESyhUIiQlo8UEQynUIiYlo8UEQymUIiQ2jxQBHJRAqJDKPFA0UkkygkMpQWDxSRTKCQyHBaPFBEoqSQyAJaPFBEoqKQyCLJFg+s/d5S7qrfrMUDRaRfKCSyUOLigccMLeaaxSu1eKCI9AuFRBZLtXjgg8+/zgNrW6jfsCfqEkUky4UeEmY2wsyWmFmjmW0ws8uP0Pd4M3vAzPaZ2U4z+06YtWaDrosH1r2ynX/6zbPc/Wor8376tIJCRPokipnELUALUAHMAxaY2aldO5lZAfAH4DFgLFAJ/DrEOrNK5+KBn3r3cQA40NrWwdM6BSUifRBqSJhZKTALuM7dY+6+DLgPuCJJ908Ar7v7ze7e6O4H3P35EMvNSuedXEF+jgGQm5vDWcePjLgiEclmFuZdvGY2HXjS3YsT2q4BZrj7RV36/hzIB0YBZwIvAp9z9xeSHHc+MB+goqKieuHChb2qLxaLUVZW1qt9M8kLO9v4fv0Bpo/J43PTi6Iup88Gys9loIwDNJZM1Ndx1NbW1rt7Tdf2vD5V1XNlwN4ubXuBIUn6VgK1wMXAo8C/AL8zs5PcvSWxo7vfCtwKUFNT4zNnzuxVcUuXLqW3+2aSmcATW/6Xl/YYZ519DkX5uVGX1CcD5ecyUMYBGksm6q9xhH1NIgaUd2krB5Ktjb0fWObuD8dD4XvASODk/i1xYHhPZT5vHmjj9y+9EXUpIpLFwg6J1UCemU1JaJsKrErS93mC66/SCyeNyGHcsGIWr9gUdSkiksVCDQl3bwTuAW40s1IzOxu4BLg9SfdfA2eZ2XvNLBf4PLAT+FtY9WazHDNmV1eybM1OtjRonScR6Z0o3gJ7NVAMbAfuBK5y91VmNt7MYmY2HsDdXwE+BvwY2EMQJhd3vR4hqc2ursQd7q7fHHUpIpKlwr5wjbvvBi5N0r6R4MJ2Yts9BDMP6YWqESWcPXkki+s38dnayeTE3xorItJdWpZjgJtTXcWm3fv5y2u7oy5FRLKQQmKA+8BpYxlSlKcL2CLSKwqJAa4oP5eLpx7LQy9u5c0DrVGXIyJZRiExCMypqeJAawcPPr816lJEJMsoJAaBqZVDOaGijEU65SQiPaSQGATMjDnVVTy7sYE125Pd3C4ikpxCYpC4dPo48nKMxSt0z4SIdJ9CYpAYPaSQc08aw93PbKG1vSPqckQkSygkBpE5NVXsjDXz+Cs7oi5FRLKEQmIQmXniaEaVFeoCtoh0m0JiEMnPzWHWGeN47OXt7Iw1R12OiGQBhcQgM6emkrYO595nt0RdiohkAYXEIDN5zBCmjx/Gb5dvIsxH14pIdlJIDEJza6p4dXuMlZu7PklWRORQColB6INvO4ai/Bwt+iciR6WQGISGFOVz4WnHcN9zr7O/pT3qckQkgykkBqk5NVXsa27jkVXboi5FRDKYQmKQesdxI6gaUcziep1yEpHUFBKDVE5OsOjfE2t2sWl3U9TliEiGCj0kzGyEmS0xs0Yz22Bml6fo9wkzazezWMLHzHCrHdhmVVdiBnfVa9E/EUkuipnELUALUAHMAxaY2akp+j7l7mUJH0vDKnIwGDesmHdPHsVd9Zvp6NA9EyJyuFBDwsxKgVnAde4ec/dlwH3AFWHWIW+ZU1PFlob9PLVuV9SliEgGsjDvujWz6cCT7l6c0HYNMMPdL+rS9xMEs479wG7gduBb7t6W5LjzgfkAFRUV1QsXLuxVfbFYjLKysl7tm2m6O5aWdufzdU1MHZ3Lp6cWhVBZzw2Un8tAGQdoLJmor+Oora2td/eawza4e2gfwDnAti5tVwJLk/Q9HjiOYLZzOvAS8O9He43q6mrvrbq6ul7vm2l6Mpb/u+QFP+Hah7yhqaX/CuqDgfJzGSjjcNdYMlFfxwGs8CS/U8O+JhEDyru0lQOHPVPT3de5+2vu3uHuLwA3ArNDqHHQmVtTRXNbB/evfD3qUkQkw4QdEquBPDObktA2FVjVjX0dsH6papA7bVw5J40dwmK9y0lEugg1JNy9EbgHuNHMSs3sbOASgusNhzCzC8ysIv71ScB1wO/CrHewMDPm1FSxclMDr2w7bFInIoNYFG+BvRooBrYDdwJXufsqMxsfvxdifLzfecDzZtYIPEQQLjdFUO+gcOm0Y8nPNS36JyKHyAv7Bd19N3BpkvaNQFnC99cA14RX2eA2sqyQ806qYMmzW/jyBSeRn6ub8UVEy3JIgrlnVrKrsYXHXt4edSkikiEUEnLQe6aMZsyQQp1yEpGDFBJyUF5uDpedUUndKzvYvu9A1OWISAZQSMgh5tRU0t7hLHlmS9SliEgGUEjIISaNLqN6wnAWrdjUeee7iAxiCgk5zNyaStbuaOTZTQ1RlyIiEVNIyGH+7m3HUpyfqwvYIqKQkMOVFeZx4enHcP/KrexvaY+6HBGJkEJCkppbU0msuY2HX9wadSkiEiGFhCT19uNGMHFkCYt0yklkUFNISFJmxuzqSp5et5uNu5qiLkdEIqKQkJRmVVdiBnfVazYhMlgpJCSlY4YW854po7mrfjPtHbpnQmQwUkjIEc2pqeT1vQd4cu3OqEsRkQgoJOSIzj+lgmEl+SxaoafWiQxGCgk5osK8XC6dNo5HVm1jb1Nr1OWISMgUEnJUs6sraWnr4L6VWvRPZLBJe0iY2X+b2f1J2svN7HozOzmh7Qtm9ryZKawy2GnjhnLKMeU65SQyCKX1l7OZTQI+DdyQZHMN8DVgpJktiT+7+gvAeODvj3Lcx8zMzSz0x61KYE5NJS9s2cvftr4ZdSkiEqJ0/wX/eWClu69Ism060Ax8FmgBKoDLgWLg2lQHNLN5RPAsbjnUpdPGUZCbw2LNJkQGlW6FhJlNNrNWM7uhS/sCM9tnZjVmVgh8DPhNkv3/BnwPKAQ+DMwFbnP3ZcAfgUlm9q4k+w0lmH18qYfjkjQbXlrA+adUcO9zW2hp64i6HBEJiXX3wTJmtgCYBxzv7jvN7KsEM4C/c/c/mtkMYClwZteZhJmdCSwENgFnATOBre6+wcz+DbgJ+Ja7f7XLfrcAa4AlwGtAvru3JaltPjAfoKKionrhwoXdHP6hYrEYZWVlvdo30/THWJ7f0cbN9c18dlohNWPDm9wNlJ/LQBkHaCyZqK/jqK2trXf3msM2uHu3PoCxQCPwXeBTQDswN2H7l4EOoCDJvgUEp5r+C9jWZduVQAPw+y7tNcBzBKeaJgIO5B2tzurqau+turq6Xu+bafpjLG3tHf6Ob/7RP/mLv6b92EcyUH4uA2Uc7hpLJurrOIAVnuR3arevSbj7NuA/gc8BPwH+2d0XJXQ5FnjT3VuS7H5qPChWAuVdtpUD++P7AxB/t9OPgH/xJDMHiUZujjGrehxLX9nOG28eiLocEQlBTy9cv0pwXeEpd7+ly7YigtlCMmcQzAQeBPLMbErCtqnAboIL2J3KCWYSvzWzbcDyePtmMzunhzVLGs2urqLD4Z5ndM+EyGDQ7ZAws3MJZhBPAWeb2dQuXXYBw1PsPh1YG5+N3APcaGalZnY2cAlBSCQuDrSXYGYxLf5xYby9GvhLd2uW9DtuVClvnziCxSs2dZ4WFJEBrLvvbjoDuBf4KcFF540EF5sTvQzkm1llkkOcArwU//pqglnDduBO4CpgNMEsIWZm4+OnyLZ1fgA74vu+keJ0loRoTk0l63Y2Ur9hT9SliEg/O2pImNlk4GHg98Dn4r+kbwAuNLP3JHT9U/zz25McpgGYambvB04APuXupe4+Hngo3vawu5e5+8auO7v7enc3XZ/IDBeefgwlBbm6Z0JkEDhiSJjZWIJw+Bswz9073yD/K4KZw7c7+7r7euCvwEVJDvVV4A2C2chTwMkJ2/6O4Oa6Jb0ZgISvtDCPD77tGB54/nUam5XbIgPZEUMifrrneHef6e7NCe3t7n6yu3e9AW4BcJmZlXQ5zovu/g53L47PCJYlbP4YsNjdd/V1MBKeuTVVNLa089ALW6MuRUT6UbqX5bgd2EJw3eGozGwaUEvytZ4kg1VPGM7xo0pZXK9TTiIDWVpDwt3bgX8Amrq5y1jgk+6+Jp11SP8zM2bXVPLX13bz2s7GqMsRkX6S9iW63f1pd/9RN/v+r7vfme4aJByzzqgkx+Cu+k1RlyIi/UTPcZBeqygvYsYJo7m7fgvtHbpnQmQgUkhIn8ytqWLbmwf486s7jt5ZRLKOQkL65LyTKxhekq97JkQGKIWE9ElBXg6XTh/HH156gz2NuhleZKBRSEifzamuoqW9g989p0X/RAYahYT02SnHlnPauHLdMyEyACkkJC3m1lSx6vU3eXHL3qhLEZE0UkhIWlw89VgK8nK4S7MJkQFFISFpMaykgPedUsG9z22hua096nJEJE0UEpI2c2uqaGhq5Y8vbY+6FBFJE4WEpM3Zk0dx7NAiFq3QMh0iA4VCQtImN8eYVV3Jn1/dwda9+6MuR0TSQCEhaTW7upIOh3ue0T0TIgOBQkLSasLIUt5x3AgWr9iEuxb9E8l2oYeEmY0wsyVm1mhmG8zs8hT9PmJmr5jZXjPbbma/NLPysOuVnptbU8X6XU0sX78n6lJEpI+imEncQvBM6wpgHrDAzE5N0u8J4Gx3HwocD+QB3witSum1C04fS1lhni5giwwAoYaEmZUCs4Dr3D0Wf9b1fcAVXfu6+yZ335nQ1A5MDqdS6YuSgjw++LZjePD5rcSa26IuR0T6wMI8b2xm04En3b04oe0aYIa7X5Sk/7uBB4Fygkeifsjdf5+k33xgPkBFRUX1woULe1VfLBajrKysV/tmmqjHsmZPO9/4ywH+4bQC3lOZ36djRT2WdBko4wCNJRP1dRy1tbX17l5z2AZ3D+0DOAfY1qXtSmDpUfYbB1wPnHC016iurvbeqqur6/W+mSbqsXR0dPi536vzWT96os/Hinos6TJQxuGusWSivo4DWOFJfqeGfU0iRjArSFQO7DvSTu6+BfhfoHdTBAmdmTGnpooVG/awbkcs6nJEpJfCDonVQJ6ZTUlomwqs6sa+ecCkfqlK+sVl08eRm2NaQlwki4UaEu7eCNwD3GhmpWZ2NnAJcHvXvmY2z8zGW2AC8E3g0TDrlb4ZU15E7Ymjubt+M23tHVGXIyK9EMVbYK8GioHtwJ3AVe6+Kh4IMTMbH+93CvAkwSmqJ4BXCK5fSBaZXV3F9n3N/PnVnUfvLCIZJy/sF3T33cClSdo3AmUJ318LXBteZdIfzj1pDCNLC1i0YhO1J42JuhwR6SEtyyH9qiAvhw9NH8cf//YGuxtboi5HRHpIISH9bk5NFa3tzr3PatE/kWyjkJB+d+LYIUytHMoiLfonknUUEhKK2TVVvLxtHy9ueTPqUkSkBxQSEoqLpx5LYV4Oi+u16J9INlFISCiGFufzgdPGcu+zWzjQ2h51OSLSTQoJCc2c6irePNDG7196I+pSRKSbFBISmndNGsm4YcUs1nMmRLKGQkJCk5NjzK6uZNmanWxp2B91OSLSDQoJCdXs6krc4W4t+ieSFRQSEqqqESW8a9JI7qrfTEeH7pkQyXQKCQnd3JoqNu5u4i+v7Y66FBE5CoWEhO79p45lSGGe7pkQyQIKCQldcUEuF007lode2Mq+A61RlyMiR6CQkEjMraniQGsHDzy/NepSROQIFBISiamVQ5kypkz3TIhkOIWERMLMmFtTxTMbG1izfV/U5YhICgoJicyl08eRm2MsXqF7JkQylUJCIjN6SCHnnjSGu5/ZQmt7R9TliEgSoYeEmY0wsyVm1mhmG8zs8hT9/t7M6s3sTTPbbGbfMbPQn8kt/WtuTRU7Y808/sqOqEsRkSSimEncArQAFcA8YIGZnZqkXwnweWAU8A7gPOCakGqUkMw8cTSjygpYpAvYIhkp1JAws1JgFnCdu8fcfRlwH3BF177uvsDd/+zuLe6+BbgDODvMeqX/5efmcNkZlTz28nZ2xpqjLkdEurAwnzlsZtOBJ929OKHtGmCGu190lH3vBV52968k2TYfmA9QUVFRvXDhwl7VF4vFKCsr69W+mSabxrIl1sG1y/bzkRML+MBx+Ydtz6axHMlAGQdoLJmor+Oora2td/eawza4e2gfwDnAti5tVwJLj7LfJ4HNwKijvUZ1dbX3Vl1dXa/3zTTZNpZLfrjMz795qXd0dBy2LdvGkspAGYe7xpKJ+joOYIUn+Z0a9jWJGFDepa0cSPlGeTO7FPg2cIG77+y/0iRKc2uqWP1GjOc37426FBFJEHZIrAbyzGxKQttUYFWyzmb2AeB/gIvc/YUQ6pOIfHDqMRTl5+gCtkiGCTUk3L0RuAe40cxKzexs4BLg9q59zexcgovVs9z9r2HWKeErL8rngtOO4b6Vr3OgtT3qckQkLoq3wF4NFAPbgTuBq9x9lZmNN7OYmY2P97sOGAo8FG+PmdnDEdQrIZlTU8m+A208smpb1KWISFzoN6e5+27g0iTtG4GyhO9rQyxLMsBZx42kakQxi1Zs4pJp46IuR0TQshySQXJyjNlnVPHk2l1s2t0UdTkigkJCMsys6mAGcfczWvRPJBMoJCSjVA4v4exJo1i8YjMdHeHd6CkiySkkJOPMqalkS8N+nl63K+pSRAY9hYRknPefOpbyojzdMyGSARQSknGK8nO5eNqxPPziNvbub426HJFBTSEhGWluTRXNbR088PzrUZciMqgpJCQjnT5uKCeNHcIvnljPA2tbqN+wJ+qSRAYlPelNMpKZcdbxI7jtyQ2s2Q73rHmSM8YP55hhxZQV5lJSkEdpQS6lhXmUFOYltOVRWhi0lxYGfUoK8ijI099DIr2hkJCMVV781rMlOhw27WliV2MLjc1tNLW009jSRncfh1KQm0NJYe7BECkpyKOsMI+Sgtzg88FtiW1vBVFi+JQUBH1zcqzbY6nfsIcH1rYw5Lg9VE8Y3tP/FCKRUUhIxppxwhhu/dM6Wlo7KMjP4Ufzqg/5BdvR4RxoayfW3EZTcxAajQc/J7a10djSHnxubqeppS3Yp6WdnbFmGluCvrHmNprbOrpdX3F+54ylM3Tis5mEwCktzGVPUyuLlm+ivcP53bqnuOHiU3n7cSMZXpLP0OJ88nI1y5HMpZCQjFU9YTh3/ONZ3PnH5Xz0vWce9hd4To5RUpBHSUEeDEnPa7a1d9DYEgRJY3M8WFreCpdD24LwaWpuIxbf3tDUwpaGzrZge3vCTYGt7c7/WfLiIa85pCiPYSX5DC8pYGhx8HlYST7DivMZFv96eEkBQ+OfhxXnU16cT24PZjIivaWQkIxWPWE4+yYVhHaKJi83h6HFOQwtPvwxqr3h7jy9bhef+MVyWto6yM/L4csfOJFRZYU0NLXS0NTKnqYW9u4PPjc0tbJpdxMN+1vZu7815ek0s2B59WEl8SApzmd4/OuhCV93bh9eks+w4gKGFPXsNJmIQkKkH5kZ75w0it9cmXpGlEp7h7PvwFtB0rC/lYZ4kOxpamVvUwt7mloPtr+2s5GGphbePNCW8pg5BkMTZijDirvMUuKnwIZ3mcEMKczDLAgXXV8ZXBQSIiHozYwoN8fiv8wLmEhpt/dra+/gzQNtB2cmbwVLMGNJ/HpHrJlXt8doaGol1pw6XHJzjGHF+RTm57B17wHc4d61T/G586Zw/skVHD+6lKL83G7XKNlDISEywOTl5jCitIARpQU92q+1vYOGplb27n9rttIZMA37g1lL/fo9vO4HAGjrcL7/h9V8/w+rMYOq4SVMHlPGpNGlTB5TFv+6jGElPatDju4734Ezz4TaIzx1p64Oli+HL32pb6+lkBARAPJzcxg9pJDRQwpT9qnfsId5P306eMdZXg43XXY6+bk5rNkeY82OGGu3x1i2ZictCe8SG1VWwKTRb4VGZ4AcM7To4Cks6Zkzz4S5c2HRouRBUVf31va+UkiISLcd7R1nEFxL2byniTXbY6zdEQsCZHuM+1e+fsj1kpKC3ENCo3MGMmFkKfl6W/AR1dYGAZAsKBID4kgzje4KPSTMbATwM+B9wE7g3939N0n6nQb8B1ANjHR3/ckhkgGOdn0lN8eYMLKUCSNLOe/kioPt7s7OWMshs461O2I8vW4XS57dcrBfXo4xYWTJIQEyeUwZx48uo6xQf9d26hoUZukPCIhmJnEL0AJUANOAB81spbuv6tKvFVgE/Ai4N8wCRST9zOzg6ax3Thp5yLZYc9vB0OiceazZEePRl7cfcp/JMUOLDp62mjSmjMnxIBlVVjAoT10lBsUFF0zk4YfTGxAQckiYWSkwCzjN3WPAMjO7D7gC+EpiX3d/BXjFzCaHWaOIhK+sMI+pVcOYWjXskPaWtg427m48GBxrdwRfL1qxiaaW9oP9hhbnH3LBvDNIKoeXDPibDmtr4aqr4Otfn8h116U3ICD8mcQJQLu7r05oWwnMCLkOEckCBXk5TB4zhMljDr2lvqPD2frmAdYmzDrWbI/x2MvbWbTireejF+blcNyo0kNmHZPHlHHcqOAtuwPhno+6OliwAK64Yj0LFkyktja9QWHe3RXS0vFiZucAi919bELblcA8d5+ZYp/JwKtHuiZhZvOB+QAVFRXVCxcu7FV9sViMsrKyXu2baTSWzDNQxgGZPZZYi7O1sYPXYx3B50Zna6yDnfudzt92BgwtgL0tAE5+jvGlM4uYPDy77vV49tlh3HDDKXztay8xZcpmXn218uD306c39OhYtbW19e5e07U97JlEDCjv0lYO7OvLQd39VuBWgJqaGp85c2avjrN06VJ6u2+m0Vgyz0AZB2TnWA60trNuR+PBWccjL26j4Y19gNHu0DxsAjNnZs/Z7bo6uOkmWLIEamunsXRpA1/4wjSmTYO5c6el7dpE2O8zWw3kmdmUhLapQNeL1iIiaVWUn8spx5Zz8dRj+eL5J3DTZadTlJ9DDpCfl8NZx4886jEyxZHexZR4Mbuuru+vFWpIuHsjcA9wo5mVmtnZwCXA7V37WqAIKIh/X2Rmqe/yERHpgc57Pi6bks8d/3hWVl2TWL78yO9i6gyK5cv7/lpRvAX2auDnwHZgF3CVu68ys/HAS8Ap7r4RmAC8lrDffmADMDHcckVkoAp7leF06c5SG+m6gB16SLj7buDSJO0bgbKE79cTXF8SEZGI6N53ERFJSSEhIiIpKSRERCQlhYSIiKSkkBARkZQUEiIikpJCQkREUlJIiIhISgoJERFJSSEhIiIpKSRERCQlhYSIiKSkkBARkZQUEiIikpJCQkQkm91xB0ycyIxzz4WJE4Pv0yiKhw6JiEg63HEHzJ8PTU3Bw3c2bAi+B5g3Ly0voZmEiEi2uvZaaGo6tK2pKWhPE4WEiEi22rixZ+29oJAQEclW48f3rL0XQg8JMxthZkvMrNHMNpjZ5Ufo+wUz22Zme83s52ZWGGatIiIZ7ZvfhJKSQ9tKSoL2NIliJnEL0AJUAPOABWZ2atdOZvZ+4CvAecBE4HjghvDKFBHJcPPmwa23woQJuBlMmBB8n6aL1hBySJhZKTALuM7dY+6+DLgPuCJJ978Hfubuq9x9D/B14BOhFSsikg3mzYP163n8scdg/fq0BgSAuXtaD3jEFzObDjzp7sUJbdcAM9z9oi59VwI3uftv49+PAnYAo9x9V5e+84H5ABUVFdULFy7sVX2xWIyysrJe7ZtpNJbMM1DGARpLJurrOGpra+vdvaZre9j3SZQBe7u07QWGdKNv59dDgENCwt1vBW4FqKmp8ZkzZ/aquKVLl9LbfTONxpJ5Bso4QGPJRP01jrCvScSA8i5t5cC+bvTt/DpZXxER6Qdhh8RqIM/MpiS0TQVWJem7Kr4tsd8bXU81iYhI/wk1JNy9EbgHuNHMSs3sbOAS4PYk3X8FfMrMTjGz4cD/BW4LrVgREQn3wjUE90kAPwfOJ7i28BV3/42ZjQdeAk5x943xvl8EvgwUA3cDn3H35qMcfwewoZfljQJ29nLfTKOxZJ6BMg7QWDJRX8cxwd1Hd20MPSQymZmtSHZ1PxtpLJlnoIwDNJZM1F/j0LIcIiKSkkJCRERSUkgc6taoC0gjjSXzDJRxgMaSifplHLomISIiKWkmISIiKSkkREQkJYWEiIikpJCgZw9CymRm9lkzW2FmzWZ2W9T19IWZFZrZz+I/j31m9qyZXRB1Xb1hZr82s61m9qaZrTazf4y6pr4ysylmdsDMfh11Lb1lZkvjY4jFP16JuqbeMrOPmNnf4r/D1prZOek6dtirwGaqxAchTQMeNLOV7p5sTalM9jrwDeD9BHepZ7M8YBMwA9gIXAgsMrPT3X19lIX1wreAT7l7s5mdBCw1s2fdvT7qwvrgFmB51EWkwWfd/adRF9EXZnY+8P+ADwN/BY5J5/EH/Uyihw9Cymjufo+730uXpdSzkbs3uvv17r7e3Tvc/QHgNaA66tp6Kv7grM7lZDz+MSnCkvrEzD4CNACPRlyKBG4AbnT3p+P/r2xx9y3pOvigDwngBKDd3VcntK0EDnukqkTHzCoIflbZNrsDwMx+ZGZNwMvAVuChiEvqFTMrB24E/jXqWtLkW2a208yeMLOZURfTU2aWC9QAo81sjZltNrMfmlnaziQoJHr2ICSJgJnlA3cAv3T3l6Oupzfc/WqCf1PnEKyEfMSFKjPY1wkeK7wp6kLS4MvA8cA4ghvR7jezbJvhVQD5wGyCf1vTgOkEq2anhUKiZw9CkpCZWQ7BUvItwGcjLqdP3L09fjqzErgq6np6ysymAe8Fvh9xKWnh7n9x933u3uzuvwSeILj2lU32xz//t7tvdfedwM2kcRy6cJ3wICR3fzXelupBSBIiMzPgZwR/LV3o7q0Rl5QueWTnNYmZwERgY/CjoQzINbNT3P2MCOtKFwcs6iJ6wt33mNlmgtr7xaCfSfTwQUgZzczyzKwIyCX4n7fIzLL5D4EFwMnARe6+/2idM5GZjYm/PbHMzHLN7P3AR4HHoq6tF24lCLdp8Y8fAw8SvJsuq5jZMDN7f+f/I2Y2D3gP8EjUtfXCL4DPxf+tDQc+DzyQroNn8y+QdLqa4EFI2wneGXRVFr79FYLzkF9L+P5jBO98uD6SavrAzCYAnyY4d78t/pcrwKfd/Y7ICus5Jzi19GOCP8o2AJ93999FWlUvuHsT0NT5vZnFgAPuviO6qnotn+Dt4icB7QRvKLjU3bPxXomvEzxwaDVwAFgEfDNdB9cCfyIiktKgP90kIiKpKSRERCQlhYSIiKSkkBARkZQUEiIikpJCQkREUlJIiIhISgoJkRCYWbmZXW9mJ0ddi0hPKCREwlFDcDd8ftSFiPSEQkIkHNMJlhh5KepCRHpCy3KI9DMz+xvBGkGJ7nb32VHUI9ITCgmRfmZmZwILCZafvynevNXdN0RXlUj3aBVYkf63kuBBQ//t7k9HXYxIT+iahEj/OxUoAJ6JuhCRnlJIiPS/MwieK/FcxHWI9JhCQqT/TQfWuvubURci0lMKCZH+dwp666tkKV24Ful/DcAZ8edb7wVedfdd0ZYk0j2aSYj0v68CbwD3Ak8BWppDsobukxARkZQ0kxARkZQUEiIikpJCQkREUlJIiIhISgoJERFJSSEhIiIpKSRERCQlhYSIiKT0/wERqx0jhaN0UAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred = model.predict(X_2016)\n",
    "\n",
    "X_2016 = X_2016.reshape((156, 6))\n",
    "plot_series(X_2016[0, :], y_2016[0], y_pred[0])\n",
    "plt.title(\"RNN 2016\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "v5CYCojaf0W2",
    "outputId": "1fabb473-3993-4459-e074-659a3b802c25"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.10422927 0.42613715 0.41934484 0.7666554  0.40108806 0.6274026\n",
      " 0.60078126 0.40481657 0.81077975 0.79583424 0.41675395 0.68867713\n",
      " 0.25960892 0.64377457 0.4570753  0.7841839  0.45137733 0.2204315\n",
      " 0.3734222  0.38092822 0.45570034 0.5073963  0.5414985  0.51984173\n",
      " 0.14987189 0.         0.38362974 0.24434954 0.26089066 0.78539747\n",
      " 0.06697798 0.1510331  0.6119862  0.5301866  0.4806283  0.5910849\n",
      " 0.31550056 0.59758145 0.5295455  0.7017407  0.82490593 0.36650866\n",
      " 0.529931   0.5138437  0.48552555 0.4137531  0.55078405 0.65591043\n",
      " 0.39750212 0.1562131  0.47474843 0.790662   0.7648403  0.5074294\n",
      " 0.4238041  0.7846368  0.31229275 0.652746   0.556963   0.4279688\n",
      " 0.15944248 0.14374512 0.47905964 0.24685568 0.33779103 0.60456055\n",
      " 0.84430665 0.29232174 0.40356523 0.4413256  0.8463617  0.76605564\n",
      " 0.7370836  0.45095664 0.7743848  0.42804474 0.5227768  0.27265638\n",
      " 0.41185898 0.7197556  0.61823505 0.52154976 0.16124886 0.42277616\n",
      " 0.9959672  0.6253523  0.92828757 0.09296143 0.02965438 0.5599709\n",
      " 0.55010086 0.16932422 0.708702   0.2738275  0.55781585 0.54210764\n",
      " 0.37075967 0.99999994 0.40764993 0.5084098  0.37162954 0.07690835\n",
      " 0.44120115 0.19117993 0.7983056  0.7770241  0.32255548 0.10063225\n",
      " 0.32748562 0.46040422 0.86407477 0.64260787 0.2559169  0.61847144\n",
      " 0.34949595 0.4655612  0.48917156 0.38077754 0.59658927 0.66959447\n",
      " 0.8318034  0.55568093 0.16204768 0.79081684 0.28940374 0.66882294\n",
      " 0.24438745 0.4778282  0.6260759  0.1010021  0.83095115 0.6820902\n",
      " 0.47760767 0.71321434 0.4169746  0.2179355  0.48068112 0.8170933\n",
      " 0.8894833  0.20226163 0.4838155  0.25425357 0.17369443 0.6377284\n",
      " 0.4184788  0.5760291  0.16033918 0.32831496 0.7693743  0.7823927\n",
      " 0.6420817  0.36104494 0.32862812 0.40203303 0.24570662 0.26639587]\n"
     ]
    }
   ],
   "source": [
    "print(y_2016)\n",
    "y_2016_pred = y_pred.reshape(156)\n",
    "# y_2016_pred=[]\n",
    "# for y in y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "nvrwUXpngLB9",
    "outputId": "7b5cdf72-00ab-4a73-f33a-fa2bbc30a0f2"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pais</th>\n",
       "      <th>2016</th>\n",
       "      <th>2016 predio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>0.550065</td>\n",
       "      <td>0.100304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Albania</td>\n",
       "      <td>2.248919</td>\n",
       "      <td>2.174607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Algeria</td>\n",
       "      <td>2.213073</td>\n",
       "      <td>2.285013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Andorra</td>\n",
       "      <td>4.045989</td>\n",
       "      <td>3.777092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Angola</td>\n",
       "      <td>2.116724</td>\n",
       "      <td>2.321886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>Uzbekistan</td>\n",
       "      <td>1.905398</td>\n",
       "      <td>1.745205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>Vietnam</td>\n",
       "      <td>1.734320</td>\n",
       "      <td>1.443496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>West Bank and Gaza</td>\n",
       "      <td>2.121711</td>\n",
       "      <td>1.981182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>Zambia</td>\n",
       "      <td>1.296705</td>\n",
       "      <td>1.216831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>1.405892</td>\n",
       "      <td>1.273355</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>156 rows  3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Pais      2016  2016 predio\n",
       "0           Afghanistan  0.550065       0.100304\n",
       "1               Albania  2.248919       2.174607\n",
       "2               Algeria  2.213073       2.285013\n",
       "3               Andorra  4.045989       3.777092\n",
       "4                Angola  2.116724       2.321886\n",
       "..                  ...       ...            ...\n",
       "151          Uzbekistan  1.905398       1.745205\n",
       "152             Vietnam  1.734320       1.443496\n",
       "153  West Bank and Gaza  2.121711       1.981182\n",
       "154              Zambia  1.296705       1.216831\n",
       "155            Zimbabwe  1.405892       1.273355\n",
       "\n",
       "[156 rows x 3 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = {'Pais': pais_lista ,\n",
    "        '2016':[(item * maximo) for item in y_2016] ,\n",
    "         '2016 predio':[(item * maximo) for item in y_2016_pred],\n",
    "        }\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Juntando os modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country</th>\n",
       "      <th>GDP Prediction</th>\n",
       "      <th>Real GDP</th>\n",
       "      <th>Pais</th>\n",
       "      <th>2016 predio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>India</td>\n",
       "      <td>3.122303</td>\n",
       "      <td>3.462398</td>\n",
       "      <td>India</td>\n",
       "      <td>1.219773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Turkey</td>\n",
       "      <td>3.558721</td>\n",
       "      <td>3.826075</td>\n",
       "      <td>Turkey</td>\n",
       "      <td>2.992531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ireland</td>\n",
       "      <td>4.218635</td>\n",
       "      <td>4.471292</td>\n",
       "      <td>Ireland</td>\n",
       "      <td>4.034623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Kazakhstan</td>\n",
       "      <td>3.268962</td>\n",
       "      <td>3.799341</td>\n",
       "      <td>Kazakhstan</td>\n",
       "      <td>2.909946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Mauritania</td>\n",
       "      <td>2.987634</td>\n",
       "      <td>3.255273</td>\n",
       "      <td>Mauritania</td>\n",
       "      <td>1.335699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>Trinidad and Tobago</td>\n",
       "      <td>3.232352</td>\n",
       "      <td>3.977724</td>\n",
       "      <td>Trinidad and Tobago</td>\n",
       "      <td>3.485309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>Estonia</td>\n",
       "      <td>3.772504</td>\n",
       "      <td>4.089905</td>\n",
       "      <td>Estonia</td>\n",
       "      <td>3.302630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>Mexico</td>\n",
       "      <td>3.295478</td>\n",
       "      <td>3.954243</td>\n",
       "      <td>Mexico</td>\n",
       "      <td>3.097705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>Niger</td>\n",
       "      <td>3.011446</td>\n",
       "      <td>2.903090</td>\n",
       "      <td>Niger</td>\n",
       "      <td>0.094010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>Germany</td>\n",
       "      <td>4.215853</td>\n",
       "      <td>4.440909</td>\n",
       "      <td>Germany</td>\n",
       "      <td>3.832419</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>126 rows  5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Country  GDP Prediction  Real GDP                 Pais  \\\n",
       "0                  India        3.122303  3.462398                India   \n",
       "1                 Turkey        3.558721  3.826075               Turkey   \n",
       "2                Ireland        4.218635  4.471292              Ireland   \n",
       "3             Kazakhstan        3.268962  3.799341           Kazakhstan   \n",
       "4             Mauritania        2.987634  3.255273           Mauritania   \n",
       "..                   ...             ...       ...                  ...   \n",
       "121  Trinidad and Tobago        3.232352  3.977724  Trinidad and Tobago   \n",
       "122              Estonia        3.772504  4.089905              Estonia   \n",
       "123               Mexico        3.295478  3.954243               Mexico   \n",
       "124                Niger        3.011446  2.903090                Niger   \n",
       "125              Germany        4.215853  4.440909              Germany   \n",
       "\n",
       "     2016 predio  \n",
       "0         1.219773  \n",
       "1         2.992531  \n",
       "2         4.034623  \n",
       "3         2.909946  \n",
       "4         1.335699  \n",
       "..             ...  \n",
       "121       3.485309  \n",
       "122       3.302630  \n",
       "123       3.097705  \n",
       "124       0.094010  \n",
       "125       3.832419  \n",
       "\n",
       "[126 rows x 5 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stacked_base = gnn_predictions[['Country','GDP Prediction','Real GDP']].merge(df[['Pais','2016 predio']], left_on='Country',right_on = \"Pais\", how='inner')\n",
    "\n",
    "stacked_base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    stacked_base.drop(['Country','Pais','Real GDP'], axis=1),\n",
    "    stacked_base['Real GDP'],\n",
    "    test_size = 0.2,\n",
    "    random_state=RANDOM_SEED,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(n_estimators=150, random_state=42)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc_clf = RandomForestRegressor(random_state=RANDOM_SEED, n_estimators=150)\n",
    "rfc_clf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr = cross_val_score(rfc_clf, x_train, y_train, cv=3, scoring='neg_mean_squared_error')\n",
    "tst = cross_val_score(rfc_clf, x_test, y_test, cv=3, scoring='neg_mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model mse on train: 0.02961936503467662\n",
      "Model mse on test: 0.03731408535310173\n"
     ]
    }
   ],
   "source": [
    "print(f\"Model mse on train: {-1*tr.mean()}\\nModel mse on test: {-1*tst.mean()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regresso random forest: RMSE = 0.13\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "rfc_clf.fit(x_train, y_train)\n",
    "\n",
    "y_pred = rfc_clf.predict(x_test)\n",
    "forest_rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "print('Regresso random forest: RMSE = {:.2f}'.format(forest_rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "f08154012ddadd8e950e6e9e035c7a7b32c136e7647e9b7c77e02eb723a8bedb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
